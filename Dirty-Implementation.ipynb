{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, BayesianRidge, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"AggregatedData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Convert Weekday column to Uppercase because of format mismatch </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Weekday'] = data['Weekday'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11589 entries, 0 to 11588\n",
      "Data columns (total 12 columns):\n",
      "ATM Name                        11589 non-null object\n",
      "Transaction Date                11589 non-null object\n",
      "No Of Withdrawals               11589 non-null int64\n",
      "No Of XYZ Card Withdrawals      11589 non-null int64\n",
      "No Of Other Card Withdrawals    11589 non-null int64\n",
      "Total amount Withdrawn          11589 non-null int64\n",
      "Amount withdrawn XYZ Card       11589 non-null int64\n",
      "Amount withdrawn Other Card     11589 non-null int64\n",
      "Weekday                         11589 non-null object\n",
      "Festival Religion               11589 non-null object\n",
      "Working Day                     11589 non-null object\n",
      "Holiday Sequence                11589 non-null object\n",
      "dtypes: int64(6), object(6)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Convert Transaction Date column to Date Time object </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime \n",
    "data['Transaction Date'] = pd.to_datetime(data['Transaction Date']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATM Name</th>\n",
       "      <th>Transaction Date</th>\n",
       "      <th>No Of Withdrawals</th>\n",
       "      <th>No Of XYZ Card Withdrawals</th>\n",
       "      <th>No Of Other Card Withdrawals</th>\n",
       "      <th>Total amount Withdrawn</th>\n",
       "      <th>Amount withdrawn XYZ Card</th>\n",
       "      <th>Amount withdrawn Other Card</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Festival Religion</th>\n",
       "      <th>Working Day</th>\n",
       "      <th>Holiday Sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Big Street ATM</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>123800</td>\n",
       "      <td>41700</td>\n",
       "      <td>82100</td>\n",
       "      <td>SATURDAY</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>WHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mount Road ATM</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>253</td>\n",
       "      <td>67</td>\n",
       "      <td>186</td>\n",
       "      <td>767900</td>\n",
       "      <td>270900</td>\n",
       "      <td>497000</td>\n",
       "      <td>SATURDAY</td>\n",
       "      <td>C</td>\n",
       "      <td>H</td>\n",
       "      <td>WHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Airport ATM</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>98</td>\n",
       "      <td>56</td>\n",
       "      <td>42</td>\n",
       "      <td>503400</td>\n",
       "      <td>347700</td>\n",
       "      <td>155700</td>\n",
       "      <td>SATURDAY</td>\n",
       "      <td>C</td>\n",
       "      <td>H</td>\n",
       "      <td>WHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KK Nagar ATM</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>265</td>\n",
       "      <td>159</td>\n",
       "      <td>106</td>\n",
       "      <td>945300</td>\n",
       "      <td>532600</td>\n",
       "      <td>412700</td>\n",
       "      <td>SATURDAY</td>\n",
       "      <td>C</td>\n",
       "      <td>H</td>\n",
       "      <td>WHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Christ College ATM</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>74</td>\n",
       "      <td>25</td>\n",
       "      <td>49</td>\n",
       "      <td>287700</td>\n",
       "      <td>148200</td>\n",
       "      <td>139500</td>\n",
       "      <td>SATURDAY</td>\n",
       "      <td>C</td>\n",
       "      <td>H</td>\n",
       "      <td>WHH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ATM Name Transaction Date  No Of Withdrawals  \\\n",
       "0      Big Street ATM       2011-01-01                 50   \n",
       "1      Mount Road ATM       2011-01-01                253   \n",
       "2         Airport ATM       2011-01-01                 98   \n",
       "3        KK Nagar ATM       2011-01-01                265   \n",
       "4  Christ College ATM       2011-01-01                 74   \n",
       "\n",
       "   No Of XYZ Card Withdrawals  No Of Other Card Withdrawals  \\\n",
       "0                          20                            30   \n",
       "1                          67                           186   \n",
       "2                          56                            42   \n",
       "3                         159                           106   \n",
       "4                          25                            49   \n",
       "\n",
       "   Total amount Withdrawn  Amount withdrawn XYZ Card  \\\n",
       "0                  123800                      41700   \n",
       "1                  767900                     270900   \n",
       "2                  503400                     347700   \n",
       "3                  945300                     532600   \n",
       "4                  287700                     148200   \n",
       "\n",
       "   Amount withdrawn Other Card   Weekday Festival Religion Working Day  \\\n",
       "0                        82100  SATURDAY                 H           H   \n",
       "1                       497000  SATURDAY                 C           H   \n",
       "2                       155700  SATURDAY                 C           H   \n",
       "3                       412700  SATURDAY                 C           H   \n",
       "4                       139500  SATURDAY                 C           H   \n",
       "\n",
       "  Holiday Sequence  \n",
       "0              WHH  \n",
       "1              WHH  \n",
       "2              WHH  \n",
       "3              WHH  \n",
       "4              WHH  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Removing the XYZ and Other Card Withdrawn Amounts columns too because I think they will end up biasing the model too much because the Total Amount Withdrawn column is just the sum of these two columns </h3>\n",
    "<h4> Actually the number of withdrawals should be removed too, because in a real-time scenario, we cannot really have that value but I'm keeping it in for now </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data.drop(['Transaction Date', 'Amount withdrawn Other Card',\n",
    "               'Amount withdrawn XYZ Card', 'No Of Withdrawals', 'No Of XYZ Card Withdrawals',\n",
    "       'No Of Other Card Withdrawals'], axis = 1)\n",
    "\n",
    "# y = data['Total amount Withdrawn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Converting Transaction Date to separate columns, otherwise model won't accept it </h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['Month'] = data['Transaction Date'].dt.month\n",
    "new_data['Day'] = data['Transaction Date'].dt.day\n",
    "new_data['Year'] = data['Transaction Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ATM Name', 'Total amount Withdrawn', 'Weekday', 'Festival Religion',\n",
       "       'Working Day', 'Holiday Sequence', 'Month', 'Day', 'Year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Converting Categorical Columns to Boolean Columns using pd.get_dummies() </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_list = ['ATM Name', 'Weekday', 'Festival Religion', 'Working Day', 'Holiday Sequence', 'Month', 'Day', 'Year']\n",
    "numeric_features_list = []\n",
    "testing_summary = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all categorical columns to Dummy Data (One-Hot Encoding I think)\n",
    "# drop_first = True to avoid the first column of each dummy column's result\n",
    "# So if column = Gender and has two unique values Male and Female, get_dummies on this column creates two new columns\n",
    "# male and female, if person male that column is 1 and the other is 0 and same for female column, but we only just need\n",
    "# one of these columns, male or female, if male is 0 it guarantees person is female, for that reason drop_first=True\n",
    "def convert_categorical_to_numerical(data, column_list):\n",
    "    return pd.get_dummies(data, columns=column_list, drop_first=True)\n",
    "\n",
    "# numeric_data = pd.get_dummies(new_data, columns=categorical_features_list, drop_first=True)\n",
    "numeric_data = convert_categorical_to_numerical(new_data, categorical_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total amount Withdrawn</th>\n",
       "      <th>ATM Name_Big Street ATM</th>\n",
       "      <th>ATM Name_Christ College ATM</th>\n",
       "      <th>ATM Name_KK Nagar ATM</th>\n",
       "      <th>ATM Name_Mount Road ATM</th>\n",
       "      <th>Weekday_MONDAY</th>\n",
       "      <th>Weekday_SATURDAY</th>\n",
       "      <th>Weekday_SUNDAY</th>\n",
       "      <th>Weekday_THURSDAY</th>\n",
       "      <th>Weekday_TUESDAY</th>\n",
       "      <th>...</th>\n",
       "      <th>Day_28</th>\n",
       "      <th>Day_29</th>\n",
       "      <th>Day_30</th>\n",
       "      <th>Day_31</th>\n",
       "      <th>Year_2012</th>\n",
       "      <th>Year_2013</th>\n",
       "      <th>Year_2014</th>\n",
       "      <th>Year_2015</th>\n",
       "      <th>Year_2016</th>\n",
       "      <th>Year_2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123800</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>767900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>503400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>945300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>287700</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total amount Withdrawn  ATM Name_Big Street ATM  \\\n",
       "0                  123800                        1   \n",
       "1                  767900                        0   \n",
       "2                  503400                        0   \n",
       "3                  945300                        0   \n",
       "4                  287700                        0   \n",
       "\n",
       "   ATM Name_Christ College ATM  ATM Name_KK Nagar ATM  \\\n",
       "0                            0                      0   \n",
       "1                            0                      0   \n",
       "2                            0                      0   \n",
       "3                            0                      1   \n",
       "4                            1                      0   \n",
       "\n",
       "   ATM Name_Mount Road ATM  Weekday_MONDAY  Weekday_SATURDAY  Weekday_SUNDAY  \\\n",
       "0                        0               0                 1               0   \n",
       "1                        1               0                 1               0   \n",
       "2                        0               0                 1               0   \n",
       "3                        0               0                 1               0   \n",
       "4                        0               0                 1               0   \n",
       "\n",
       "   Weekday_THURSDAY  Weekday_TUESDAY  ...  Day_28  Day_29  Day_30  Day_31  \\\n",
       "0                 0                0  ...       0       0       0       0   \n",
       "1                 0                0  ...       0       0       0       0   \n",
       "2                 0                0  ...       0       0       0       0   \n",
       "3                 0                0  ...       0       0       0       0   \n",
       "4                 0                0  ...       0       0       0       0   \n",
       "\n",
       "   Year_2012  Year_2013  Year_2014  Year_2015  Year_2016  Year_2017  \n",
       "0          0          0          0          0          0          0  \n",
       "1          0          0          0          0          0          0  \n",
       "2          0          0          0          0          0          0  \n",
       "3          0          0          0          0          0          0  \n",
       "4          0          0          0          0          0          0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Train Test Split followed by Scaling all Columns </h3>\n",
    "<h3> Since all columns are non-numeric, we don't really need scaling, so I commented it out for now </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = numeric_data.drop('Total amount Withdrawn', axis=1)\n",
    "y = numeric_data['Total amount Withdrawn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "# Note that we fit the scaler on X_train only and not X, otherwise test data will get biased on means and std of test data\n",
    "# Instead it should use train data mean and std\n",
    "# scaler = StandardScaler().fit(X_train)\n",
    "# scaled_X_train = pd.DataFrame(data=scaler.transform(X_train), columns=X.columns)\n",
    "# scaled_X_test = pd.DataFrame(data=scaler.transform(X_test), columns=X.columns)\n",
    "\n",
    "# scaled_X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> KNN Implementation & Error Rate Visualization </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1 Model Trained and Tested\n",
      "k=2 Model Trained and Tested\n",
      "k=3 Model Trained and Tested\n",
      "k=4 Model Trained and Tested\n",
      "k=5 Model Trained and Tested\n",
      "k=6 Model Trained and Tested\n",
      "k=7 Model Trained and Tested\n",
      "k=8 Model Trained and Tested\n",
      "k=9 Model Trained and Tested\n",
      "k=10 Model Trained and Tested\n",
      "k=11 Model Trained and Tested\n",
      "k=12 Model Trained and Tested\n",
      "k=13 Model Trained and Tested\n",
      "k=14 Model Trained and Tested\n",
      "k=15 Model Trained and Tested\n",
      "k=16 Model Trained and Tested\n",
      "k=17 Model Trained and Tested\n",
      "k=18 Model Trained and Tested\n",
      "k=19 Model Trained and Tested\n",
      "k=20 Model Trained and Tested\n",
      "k=21 Model Trained and Tested\n",
      "k=22 Model Trained and Tested\n",
      "k=23 Model Trained and Tested\n",
      "k=24 Model Trained and Tested\n",
      "k=25 Model Trained and Tested\n",
      "k=26 Model Trained and Tested\n",
      "k=27 Model Trained and Tested\n",
      "k=28 Model Trained and Tested\n",
      "k=29 Model Trained and Tested\n",
      "k=30 Model Trained and Tested\n",
      "k=31 Model Trained and Tested\n",
      "k=32 Model Trained and Tested\n",
      "k=33 Model Trained and Tested\n",
      "k=34 Model Trained and Tested\n",
      "k=35 Model Trained and Tested\n",
      "k=36 Model Trained and Tested\n",
      "k=37 Model Trained and Tested\n",
      "k=38 Model Trained and Tested\n",
      "k=39 Model Trained and Tested\n",
      "k=40 Model Trained and Tested\n",
      "k=41 Model Trained and Tested\n",
      "k=42 Model Trained and Tested\n",
      "k=43 Model Trained and Tested\n",
      "k=44 Model Trained and Tested\n",
      "k=45 Model Trained and Tested\n",
      "k=46 Model Trained and Tested\n",
      "k=47 Model Trained and Tested\n",
      "k=48 Model Trained and Tested\n",
      "k=49 Model Trained and Tested\n",
      "k=50 Model Trained and Tested\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "error_rate = []\n",
    "for k in range(1, 40):\n",
    "    knn = KNeighborsRegressor(n_neighbors=k, n_jobs=-1)\n",
    "    knn.fit(X_train, y_train)\n",
    "    predictions = knn.predict(X_test)\n",
    "    error_rate.append(np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "    print(\"k={} Model Trained and Tested\".format(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19294fcf7c0>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,51), error_rate, linestyle='--', marker='o', markerfacecolor='red', color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K: 37\n",
      "Best RMSE: 243180.0491744677\n"
     ]
    }
   ],
   "source": [
    "print(\"Best K:\", error_rate.index(min(error_rate)))\n",
    "print(\"Best RMSE:\", min(error_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Best RMSE: 243180.0491744677 </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Running Each Regression Model to get summary of all RMSEs </h2>\n",
    "<h3> Models tested </h3>\n",
    "<ul>\n",
    "    <li> KNN </li>\n",
    "    <li> Linear Regression </li>\n",
    "    <li> Ridge </li>\n",
    "    <li> Elasticnet </li>\n",
    "    <li> Lasso </li>\n",
    "    <li> Bayesian Ridge </li>\n",
    "    <li> Support Vector Regression </li>\n",
    "    <li> Random Forest Regression </li>\n",
    "    <li> Decision Tree Regression </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'K-Nearest Neighbours': KNeighborsRegressor(n_neighbors=37, n_jobs=-1), 'Vanilla Linear Regression': LinearRegression(), \n",
    "          'Ridge Linear Regression': Ridge(), 'Elasticnet Linear Regression': ElasticNet(), \n",
    "          'Lasso Linear Regression': Lasso(max_iter=1100), 'Bayesian Ridge Linear Regression': BayesianRidge(), \n",
    "          'Support Vector Regression': SVR(), 'Random Forest Regression': RandomForestRegressor(), \n",
    "          'Decision Tree Regression': DecisionTreeRegressor()}\n",
    "\n",
    "atm_names = new_data['ATM Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse_model_list(models, X_train, y_train, X_test, y_test):\n",
    "    print(\"RMSEs for each model\")\n",
    "    testing_scores = dict()\n",
    "    for model_name in models:\n",
    "        model = models[model_name]\n",
    "        model.fit(X_train, y_train)\n",
    "        model_predictions = model.predict(X_test)\n",
    "        model_rmse = np.sqrt(mean_squared_error(y_test, model_predictions))\n",
    "        model_testing_score = model.score(X_test, y_test)\n",
    "        model_training_score = model.score(X_train, y_train)\n",
    "        print(\"For\", model_name)\n",
    "        print(\"\\tTesting RMSE = {}\".format(model_rmse))\n",
    "        print(\"\\tTraining Score =\", model_training_score)\n",
    "        print(\"\\tTesting Score =\", model_testing_score)\n",
    "        \n",
    "        # Storing the results in a dictionary, so stuff can be easily compared later\n",
    "        testing_scores[model_name] = dict()\n",
    "        testing_scores[model_name]['Training Score'] = model_training_score\n",
    "        testing_scores[model_name]['Testing Score'] = model_testing_score\n",
    "        testing_scores[model_name]['RMSE'] = model_rmse\n",
    "    \n",
    "    return testing_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSEs for each model\n",
      "For K-Nearest Neighbours\n",
      "\tTesting RMSE = 243308.4815900565\n",
      "\tTraining Score = 0.45697266653028884\n",
      "\tTesting Score = 0.4469533394817221\n",
      "For Vanilla Linear Regression\n",
      "\tTesting RMSE = 251419.81922358868\n",
      "\tTraining Score = 0.4013361571445507\n",
      "\tTesting Score = 0.409464110262857\n",
      "For Ridge Linear Regression\n",
      "\tTesting RMSE = 251386.47604234665\n",
      "\tTraining Score = 0.4013043683235682\n",
      "\tTesting Score = 0.4096207330748531\n",
      "For Elasticnet Linear Regression\n",
      "\tTesting RMSE = 299840.48379522713\n",
      "\tTraining Score = 0.1599098376804099\n",
      "\tTesting Score = 0.16009954359397116\n",
      "For Lasso Linear Regression\n",
      "\tTesting RMSE = 251415.86960634057\n",
      "\tTraining Score = 0.4013359783757806\n",
      "\tTesting Score = 0.40948266387110405\n",
      "For Bayesian Ridge Linear Regression\n",
      "\tTesting RMSE = 251396.25827460986\n",
      "\tTraining Score = 0.4006642870319033\n",
      "\tTesting Score = 0.40957478518163776\n",
      "For Support Vector Regression\n",
      "\tTesting RMSE = 330051.3590919249\n",
      "\tTraining Score = -0.023764153336445215\n",
      "\tTesting Score = -0.01767786439476282\n",
      "For Random Forest Regression\n",
      "\tTesting RMSE = 206606.11951902052\n",
      "\tTraining Score = 0.9389306830314473\n",
      "\tTesting Score = 0.6012197520412734\n",
      "For Decision Tree Regression\n",
      "\tTesting RMSE = 258864.64985155227\n",
      "\tTraining Score = 1.0\n",
      "\tTesting Score = 0.3739734197065788\n"
     ]
    }
   ],
   "source": [
    "testing_summary['All ATMs Trained with Train Test Split'] = compute_rmse_model_list(models, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> The scores and RMSEs computed by the above function are stored in the dictionary in the following format </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> After observing the testing and training scores, I think its clear that Decision Tree overfits, but I dont think that was ever that high on our sought after models list, so that's good, other than that everything is not ideal but atleast no overfitting </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Using only 2017 data as test data and everything else as training data </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total amount Withdrawn</th>\n",
       "      <th>ATM Name_Big Street ATM</th>\n",
       "      <th>ATM Name_Christ College ATM</th>\n",
       "      <th>ATM Name_KK Nagar ATM</th>\n",
       "      <th>ATM Name_Mount Road ATM</th>\n",
       "      <th>Weekday_MONDAY</th>\n",
       "      <th>Weekday_SATURDAY</th>\n",
       "      <th>Weekday_SUNDAY</th>\n",
       "      <th>Weekday_THURSDAY</th>\n",
       "      <th>Weekday_TUESDAY</th>\n",
       "      <th>...</th>\n",
       "      <th>Day_28</th>\n",
       "      <th>Day_29</th>\n",
       "      <th>Day_30</th>\n",
       "      <th>Day_31</th>\n",
       "      <th>Year_2012</th>\n",
       "      <th>Year_2013</th>\n",
       "      <th>Year_2014</th>\n",
       "      <th>Year_2015</th>\n",
       "      <th>Year_2016</th>\n",
       "      <th>Year_2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123800</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>767900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>503400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>945300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>287700</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11584</th>\n",
       "      <td>468800</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11585</th>\n",
       "      <td>305100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11586</th>\n",
       "      <td>709900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11587</th>\n",
       "      <td>408700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11588</th>\n",
       "      <td>700400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11589 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Total amount Withdrawn  ATM Name_Big Street ATM  \\\n",
       "0                      123800                        1   \n",
       "1                      767900                        0   \n",
       "2                      503400                        0   \n",
       "3                      945300                        0   \n",
       "4                      287700                        0   \n",
       "...                       ...                      ...   \n",
       "11584                  468800                        1   \n",
       "11585                  305100                        0   \n",
       "11586                  709900                        0   \n",
       "11587                  408700                        0   \n",
       "11588                  700400                        0   \n",
       "\n",
       "       ATM Name_Christ College ATM  ATM Name_KK Nagar ATM  \\\n",
       "0                                0                      0   \n",
       "1                                0                      0   \n",
       "2                                0                      0   \n",
       "3                                0                      1   \n",
       "4                                1                      0   \n",
       "...                            ...                    ...   \n",
       "11584                            0                      0   \n",
       "11585                            0                      0   \n",
       "11586                            0                      0   \n",
       "11587                            0                      1   \n",
       "11588                            1                      0   \n",
       "\n",
       "       ATM Name_Mount Road ATM  Weekday_MONDAY  Weekday_SATURDAY  \\\n",
       "0                            0               0                 1   \n",
       "1                            1               0                 1   \n",
       "2                            0               0                 1   \n",
       "3                            0               0                 1   \n",
       "4                            0               0                 1   \n",
       "...                        ...             ...               ...   \n",
       "11584                        0               0                 0   \n",
       "11585                        1               0                 0   \n",
       "11586                        0               0                 0   \n",
       "11587                        0               0                 0   \n",
       "11588                        0               0                 0   \n",
       "\n",
       "       Weekday_SUNDAY  Weekday_THURSDAY  Weekday_TUESDAY  ...  Day_28  Day_29  \\\n",
       "0                   0                 0                0  ...       0       0   \n",
       "1                   0                 0                0  ...       0       0   \n",
       "2                   0                 0                0  ...       0       0   \n",
       "3                   0                 0                0  ...       0       0   \n",
       "4                   0                 0                0  ...       0       0   \n",
       "...               ...               ...              ...  ...     ...     ...   \n",
       "11584               0                 0                0  ...       0       1   \n",
       "11585               0                 0                0  ...       0       1   \n",
       "11586               0                 0                0  ...       0       1   \n",
       "11587               0                 0                0  ...       0       1   \n",
       "11588               0                 0                0  ...       0       1   \n",
       "\n",
       "       Day_30  Day_31  Year_2012  Year_2013  Year_2014  Year_2015  Year_2016  \\\n",
       "0           0       0          0          0          0          0          0   \n",
       "1           0       0          0          0          0          0          0   \n",
       "2           0       0          0          0          0          0          0   \n",
       "3           0       0          0          0          0          0          0   \n",
       "4           0       0          0          0          0          0          0   \n",
       "...       ...     ...        ...        ...        ...        ...        ...   \n",
       "11584       0       0          0          0          0          0          0   \n",
       "11585       0       0          0          0          0          0          0   \n",
       "11586       0       0          0          0          0          0          0   \n",
       "11587       0       0          0          0          0          0          0   \n",
       "11588       0       0          0          0          0          0          0   \n",
       "\n",
       "       Year_2017  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "...          ...  \n",
       "11584          1  \n",
       "11585          1  \n",
       "11586          1  \n",
       "11587          1  \n",
       "11588          1  \n",
       "\n",
       "[11589 rows x 70 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10434\n",
      "1155\n"
     ]
    }
   ],
   "source": [
    "train_data = numeric_data[numeric_data['Year_2017'] == 0]\n",
    "test_data = numeric_data[numeric_data['Year_2017'] == 1]\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "\n",
    "X_train = train_data.drop('Total amount Withdrawn', axis=1)\n",
    "y_train = train_data['Total amount Withdrawn']\n",
    "\n",
    "X_test = test_data.drop('Total amount Withdrawn', axis=1)\n",
    "y_test = test_data['Total amount Withdrawn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSEs for each model\n",
      "For K-Nearest Neighbours\n",
      "\tTesting RMSE = 370654.38876929344\n",
      "\tTraining Score = 0.49334898232826474\n",
      "\tTesting Score = -0.2036759694108361\n",
      "For Vanilla Linear Regression\n",
      "\tTesting RMSE = 351236.1852653552\n",
      "\tTraining Score = 0.4535210215154458\n",
      "\tTesting Score = -0.08086088361456811\n",
      "For Ridge Linear Regression\n",
      "\tTesting RMSE = 350930.3772714196\n",
      "\tTraining Score = 0.4534927053204132\n",
      "\tTesting Score = -0.07897957400080258\n",
      "For Elasticnet Linear Regression\n",
      "\tTesting RMSE = 343651.78719365434\n",
      "\tTraining Score = 0.18540431599596496\n",
      "\tTesting Score = -0.03468585104161148\n",
      "For Lasso Linear Regression\n",
      "\tTesting RMSE = 351207.1555167714\n",
      "\tTraining Score = 0.4535207164047764\n",
      "\tTesting Score = -0.08068222421466187\n",
      "For Bayesian Ridge Linear Regression\n",
      "\tTesting RMSE = 349989.46216254827\n",
      "\tTraining Score = 0.4530724819355578\n",
      "\tTesting Score = -0.07320140697245625\n",
      "For Support Vector Regression\n",
      "\tTesting RMSE = 339522.5629301751\n",
      "\tTraining Score = -0.025059950311879797\n",
      "\tTesting Score = -0.00997024184255646\n",
      "For Random Forest Regression\n",
      "\tTesting RMSE = 400647.72479138186\n",
      "\tTraining Score = 0.9443151597170375\n",
      "\tTesting Score = -0.40636049422891585\n",
      "For Decision Tree Regression\n",
      "\tTesting RMSE = 415090.50076680846\n",
      "\tTraining Score = 1.0\n",
      "\tTesting Score = -0.509582616818163\n"
     ]
    }
   ],
   "source": [
    "testing_summary['All ATMs Trained with 2017 Test Data'] = compute_rmse_model_list(models, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Random Forest and Decision Tree overfit here but everything else is trash for both training and testing, idk what can be done about this </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Finding out the total amount withdrawn per month per year </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATM Name</th>\n",
       "      <th>Total amount Withdrawn</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Festival Religion</th>\n",
       "      <th>Working Day</th>\n",
       "      <th>Holiday Sequence</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Big Street ATM</td>\n",
       "      <td>123800</td>\n",
       "      <td>SATURDAY</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>WHH</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mount Road ATM</td>\n",
       "      <td>767900</td>\n",
       "      <td>SATURDAY</td>\n",
       "      <td>C</td>\n",
       "      <td>H</td>\n",
       "      <td>WHH</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Airport ATM</td>\n",
       "      <td>503400</td>\n",
       "      <td>SATURDAY</td>\n",
       "      <td>C</td>\n",
       "      <td>H</td>\n",
       "      <td>WHH</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KK Nagar ATM</td>\n",
       "      <td>945300</td>\n",
       "      <td>SATURDAY</td>\n",
       "      <td>C</td>\n",
       "      <td>H</td>\n",
       "      <td>WHH</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Christ College ATM</td>\n",
       "      <td>287700</td>\n",
       "      <td>SATURDAY</td>\n",
       "      <td>C</td>\n",
       "      <td>H</td>\n",
       "      <td>WHH</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11584</th>\n",
       "      <td>Big Street ATM</td>\n",
       "      <td>468800</td>\n",
       "      <td>FRIDAY</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>WHH</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11585</th>\n",
       "      <td>Mount Road ATM</td>\n",
       "      <td>305100</td>\n",
       "      <td>FRIDAY</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>WHH</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11586</th>\n",
       "      <td>Airport ATM</td>\n",
       "      <td>709900</td>\n",
       "      <td>FRIDAY</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>WHH</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11587</th>\n",
       "      <td>KK Nagar ATM</td>\n",
       "      <td>408700</td>\n",
       "      <td>FRIDAY</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>WHH</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11588</th>\n",
       "      <td>Christ College ATM</td>\n",
       "      <td>700400</td>\n",
       "      <td>FRIDAY</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>WHH</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11589 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ATM Name  Total amount Withdrawn   Weekday Festival Religion  \\\n",
       "0          Big Street ATM                  123800  SATURDAY                 H   \n",
       "1          Mount Road ATM                  767900  SATURDAY                 C   \n",
       "2             Airport ATM                  503400  SATURDAY                 C   \n",
       "3            KK Nagar ATM                  945300  SATURDAY                 C   \n",
       "4      Christ College ATM                  287700  SATURDAY                 C   \n",
       "...                   ...                     ...       ...               ...   \n",
       "11584      Big Street ATM                  468800    FRIDAY                 H   \n",
       "11585      Mount Road ATM                  305100    FRIDAY                 H   \n",
       "11586         Airport ATM                  709900    FRIDAY                 H   \n",
       "11587        KK Nagar ATM                  408700    FRIDAY                 H   \n",
       "11588  Christ College ATM                  700400    FRIDAY                 H   \n",
       "\n",
       "      Working Day Holiday Sequence  Month  Day  Year  \n",
       "0               H              WHH      1    1  2011  \n",
       "1               H              WHH      1    1  2011  \n",
       "2               H              WHH      1    1  2011  \n",
       "3               H              WHH      1    1  2011  \n",
       "4               H              WHH      1    1  2011  \n",
       "...           ...              ...    ...  ...   ...  \n",
       "11584           H              WHH      9   29  2017  \n",
       "11585           H              WHH      9   29  2017  \n",
       "11586           H              WHH      9   29  2017  \n",
       "11587           H              WHH      9   29  2017  \n",
       "11588           H              WHH      9   29  2017  \n",
       "\n",
       "[11589 rows x 9 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes like 15-20 seconds to compute\n",
    "total_amt_per_mon_per_yr = {}\n",
    "for year in new_data['Year'].unique():\n",
    "    for month in new_data['Month'].unique():\n",
    "        total_amt_per_mon_per_yr[(year, month)] = sum(new_data[new_data.apply(lambda x: x['Year'] == year\n",
    "                            and x['Month'] == month, axis=1)]['Total amount Withdrawn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> total_amt_per_mon_per_yr is basically a dictionary whose key is a tuple (year, month) and its value contains the total amount withdrawn in the month of the year specified in the key, so (2011, 1): 65360200, means that 65360200 was withdrawn in total in the month of January 2011 </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Uncomment this if you want to see what the dictionary is like but its a big list and takes up space so I commented it out\n",
    "# pprint(total_amt_per_mon_per_yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Amount Withdrawn: 6053002800\n",
      "Average Amount Withdrawn: 72059557.14285715\n"
     ]
    }
   ],
   "source": [
    "total_amount_withdrawn = sum(total_amt_per_mon_per_yr.values())\n",
    "avg_amount_withdrawn = sum(total_amt_per_mon_per_yr.values()) / len(total_amt_per_mon_per_yr.values())\n",
    "print(\"Total Amount Withdrawn:\", total_amount_withdrawn)\n",
    "print(\"Average Amount Withdrawn:\", avg_amount_withdrawn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Figuring out Outlier Months </h3>\n",
    "<p> So my logic is that I take the total amount withdrawn in each month (of each year ofc) and then check its difference from the average amount withdrawn per month per year, and there's a tolerance percent variable (currently 0.7), so if the difference (positive or negative) is greater than 70% of the avg_amount_withdrawn, then that month of that year is an outlier </p>\n",
    "<p> I think something similar can be done with days in a month as well </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2016, 11)\n",
      "(2016, 12)\n",
      "(2017, 10)\n",
      "(2017, 11)\n",
      "(2017, 12)\n"
     ]
    }
   ],
   "source": [
    "tolerance_percent = 0.7\n",
    "\n",
    "for key in total_amt_per_mon_per_yr:\n",
    "    amount = total_amt_per_mon_per_yr[key]\n",
    "    if abs(amount - avg_amount_withdrawn) > avg_amount_withdrawn * tolerance_percent:\n",
    "        print(key)\n",
    "        # print(total_amt_per_mon_per_yr[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Removing outlier months from 2017 in test set </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10434\n",
      "1053\n"
     ]
    }
   ],
   "source": [
    "train_data = numeric_data[numeric_data['Year_2017'] == 0]\n",
    "test_data = numeric_data[numeric_data.apply(lambda x: x['Year_2017'] == 1\n",
    "                            and x['Month_10'] != 1 and x['Month_11'] != 1 and x['Month_12'] != 1, axis=1)]\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "\n",
    "X_train = train_data.drop('Total amount Withdrawn', axis=1)\n",
    "y_train = train_data['Total amount Withdrawn']\n",
    "\n",
    "X_test = test_data.drop('Total amount Withdrawn', axis=1)\n",
    "y_test = test_data['Total amount Withdrawn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSEs for each model\n",
      "For K-Nearest Neighbours\n",
      "\tTesting RMSE = 372340.49206527043\n",
      "\tTraining Score = 0.49334898232826474\n",
      "\tTesting Score = -0.2018997476884299\n",
      "For Vanilla Linear Regression\n",
      "\tTesting RMSE = 351707.4107674948\n",
      "\tTraining Score = 0.4535210215154458\n",
      "\tTesting Score = -0.07238503792997997\n",
      "For Ridge Linear Regression\n",
      "\tTesting RMSE = 351434.1312815757\n",
      "\tTraining Score = 0.4534927053204132\n",
      "\tTesting Score = -0.07071918178027703\n",
      "For Elasticnet Linear Regression\n",
      "\tTesting RMSE = 345648.1068296639\n",
      "\tTraining Score = 0.18540431599596496\n",
      "\tTesting Score = -0.03575269583521212\n",
      "For Lasso Linear Regression\n",
      "\tTesting RMSE = 351681.79185469187\n",
      "\tTraining Score = 0.4535207164047764\n",
      "\tTesting Score = -0.07222881524409619\n",
      "For Bayesian Ridge Linear Regression\n",
      "\tTesting RMSE = 350577.01082009525\n",
      "\tTraining Score = 0.4530724819355578\n",
      "\tTesting Score = -0.06550274948102763\n",
      "For Support Vector Regression\n",
      "\tTesting RMSE = 341483.98469625093\n",
      "\tTraining Score = -0.025059950311879797\n",
      "\tTesting Score = -0.010947000905629833\n",
      "For Random Forest Regression\n",
      "\tTesting RMSE = 400781.0743700633\n",
      "\tTraining Score = 0.9441106189079738\n",
      "\tTesting Score = -0.3925221680637721\n",
      "For Decision Tree Regression\n",
      "\tTesting RMSE = 418249.2452803565\n",
      "\tTraining Score = 1.0\n",
      "\tTesting Score = -0.516554559966816\n"
     ]
    }
   ],
   "source": [
    "# testing_summary_all_atms_with_2017_non_outlier_month_data = compute_rmse_model_list(models, X_train, y_train, X_test, y_test)\n",
    "testing_summary['All ATMs Trained with 2017 Test Data (No Outlier Months)'] = compute_rmse_model_list(models, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'All ATMs Trained with 2017 Test Data': {'Bayesian Ridge Linear Regression': {'RMSE': 349989.46216254827,\n",
      "                                                                               'Testing Score': -0.07320140697245625,\n",
      "                                                                               'Training Score': 0.4530724819355578},\n",
      "                                          'Decision Tree Regression': {'RMSE': 415090.50076680846,\n",
      "                                                                       'Testing Score': -0.509582616818163,\n",
      "                                                                       'Training Score': 1.0},\n",
      "                                          'Elasticnet Linear Regression': {'RMSE': 343651.78719365434,\n",
      "                                                                           'Testing Score': -0.03468585104161148,\n",
      "                                                                           'Training Score': 0.18540431599596496},\n",
      "                                          'K-Nearest Neighbours': {'RMSE': 370654.38876929344,\n",
      "                                                                   'Testing Score': -0.2036759694108361,\n",
      "                                                                   'Training Score': 0.49334898232826474},\n",
      "                                          'Lasso Linear Regression': {'RMSE': 351207.1555167714,\n",
      "                                                                      'Testing Score': -0.08068222421466187,\n",
      "                                                                      'Training Score': 0.4535207164047764},\n",
      "                                          'Random Forest Regression': {'RMSE': 400647.72479138186,\n",
      "                                                                       'Testing Score': -0.40636049422891585,\n",
      "                                                                       'Training Score': 0.9443151597170375},\n",
      "                                          'Ridge Linear Regression': {'RMSE': 350930.3772714196,\n",
      "                                                                      'Testing Score': -0.07897957400080258,\n",
      "                                                                      'Training Score': 0.4534927053204132},\n",
      "                                          'Support Vector Regression': {'RMSE': 339522.5629301751,\n",
      "                                                                        'Testing Score': -0.00997024184255646,\n",
      "                                                                        'Training Score': -0.025059950311879797},\n",
      "                                          'Vanilla Linear Regression': {'RMSE': 351236.1852653552,\n",
      "                                                                        'Testing Score': -0.08086088361456811,\n",
      "                                                                        'Training Score': 0.4535210215154458}},\n",
      " 'All ATMs Trained with 2017 Test Data (No Outlier Months)': {'Bayesian Ridge Linear Regression': {'RMSE': 350577.01082009525,\n",
      "                                                                                                   'Testing Score': -0.06550274948102763,\n",
      "                                                                                                   'Training Score': 0.4530724819355578},\n",
      "                                                              'Decision Tree Regression': {'RMSE': 418249.2452803565,\n",
      "                                                                                           'Testing Score': -0.516554559966816,\n",
      "                                                                                           'Training Score': 1.0},\n",
      "                                                              'Elasticnet Linear Regression': {'RMSE': 345648.1068296639,\n",
      "                                                                                               'Testing Score': -0.03575269583521212,\n",
      "                                                                                               'Training Score': 0.18540431599596496},\n",
      "                                                              'K-Nearest Neighbours': {'RMSE': 372340.49206527043,\n",
      "                                                                                       'Testing Score': -0.2018997476884299,\n",
      "                                                                                       'Training Score': 0.49334898232826474},\n",
      "                                                              'Lasso Linear Regression': {'RMSE': 351681.79185469187,\n",
      "                                                                                          'Testing Score': -0.07222881524409619,\n",
      "                                                                                          'Training Score': 0.4535207164047764},\n",
      "                                                              'Random Forest Regression': {'RMSE': 400781.0743700633,\n",
      "                                                                                           'Testing Score': -0.3925221680637721,\n",
      "                                                                                           'Training Score': 0.9441106189079738},\n",
      "                                                              'Ridge Linear Regression': {'RMSE': 351434.1312815757,\n",
      "                                                                                          'Testing Score': -0.07071918178027703,\n",
      "                                                                                          'Training Score': 0.4534927053204132},\n",
      "                                                              'Support Vector Regression': {'RMSE': 341483.98469625093,\n",
      "                                                                                            'Testing Score': -0.010947000905629833,\n",
      "                                                                                            'Training Score': -0.025059950311879797},\n",
      "                                                              'Vanilla Linear Regression': {'RMSE': 351707.4107674948,\n",
      "                                                                                            'Testing Score': -0.07238503792997997,\n",
      "                                                                                            'Training Score': 0.4535210215154458}},\n",
      " 'All ATMs Trained with Train Test Split': {'Bayesian Ridge Linear Regression': {'RMSE': 251396.25827460986,\n",
      "                                                                                 'Testing Score': 0.40957478518163776,\n",
      "                                                                                 'Training Score': 0.4006642870319033},\n",
      "                                            'Decision Tree Regression': {'RMSE': 258864.64985155227,\n",
      "                                                                         'Testing Score': 0.3739734197065788,\n",
      "                                                                         'Training Score': 1.0},\n",
      "                                            'Elasticnet Linear Regression': {'RMSE': 299840.48379522713,\n",
      "                                                                             'Testing Score': 0.16009954359397116,\n",
      "                                                                             'Training Score': 0.1599098376804099},\n",
      "                                            'K-Nearest Neighbours': {'RMSE': 243308.4815900565,\n",
      "                                                                     'Testing Score': 0.4469533394817221,\n",
      "                                                                     'Training Score': 0.45697266653028884},\n",
      "                                            'Lasso Linear Regression': {'RMSE': 251415.86960634057,\n",
      "                                                                        'Testing Score': 0.40948266387110405,\n",
      "                                                                        'Training Score': 0.4013359783757806},\n",
      "                                            'Random Forest Regression': {'RMSE': 206606.11951902052,\n",
      "                                                                         'Testing Score': 0.6012197520412734,\n",
      "                                                                         'Training Score': 0.9389306830314473},\n",
      "                                            'Ridge Linear Regression': {'RMSE': 251386.47604234665,\n",
      "                                                                        'Testing Score': 0.4096207330748531,\n",
      "                                                                        'Training Score': 0.4013043683235682},\n",
      "                                            'Support Vector Regression': {'RMSE': 330051.3590919249,\n",
      "                                                                          'Testing Score': -0.01767786439476282,\n",
      "                                                                          'Training Score': -0.023764153336445215},\n",
      "                                            'Vanilla Linear Regression': {'RMSE': 251419.81922358868,\n",
      "                                                                          'Testing Score': 0.409464110262857,\n",
      "                                                                          'Training Score': 0.4013361571445507}}}\n"
     ]
    }
   ],
   "source": [
    "pprint(testing_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> A slight improvement but pretty insignificant sadly </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Figuring out Outlier Days with 75% difference from the average amount withdrawn per day as the tolerance</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_amount_withdrawn_per_day = sum(new_data['Total amount Withdrawn']) / len(new_data['Total amount Withdrawn'])\n",
    "tolerance_percent = 0.75\n",
    "\n",
    "outlier_day_data = new_data[new_data.apply(lambda x: abs(avg_amount_withdrawn_per_day - x['Total amount Withdrawn']) > \n",
    "                            avg_amount_withdrawn_per_day * tolerance_percent, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATM Name</th>\n",
       "      <th>Total amount Withdrawn</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Festival Religion</th>\n",
       "      <th>Working Day</th>\n",
       "      <th>Holiday Sequence</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Big Street ATM</td>\n",
       "      <td>123800</td>\n",
       "      <td>SATURDAY</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>WHH</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KK Nagar ATM</td>\n",
       "      <td>945300</td>\n",
       "      <td>SATURDAY</td>\n",
       "      <td>C</td>\n",
       "      <td>H</td>\n",
       "      <td>WHH</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Big Street ATM</td>\n",
       "      <td>52800</td>\n",
       "      <td>SUNDAY</td>\n",
       "      <td>NH</td>\n",
       "      <td>H</td>\n",
       "      <td>HHW</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Big Street ATM</td>\n",
       "      <td>88100</td>\n",
       "      <td>MONDAY</td>\n",
       "      <td>NH</td>\n",
       "      <td>W</td>\n",
       "      <td>WWW</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KK Nagar ATM</td>\n",
       "      <td>1333100</td>\n",
       "      <td>MONDAY</td>\n",
       "      <td>NH</td>\n",
       "      <td>W</td>\n",
       "      <td>WWW</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11558</th>\n",
       "      <td>Christ College ATM</td>\n",
       "      <td>1253100</td>\n",
       "      <td>SATURDAY</td>\n",
       "      <td>NH</td>\n",
       "      <td>H</td>\n",
       "      <td>WHH</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11567</th>\n",
       "      <td>KK Nagar ATM</td>\n",
       "      <td>1175200</td>\n",
       "      <td>MONDAY</td>\n",
       "      <td>NH</td>\n",
       "      <td>W</td>\n",
       "      <td>HWW</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11577</th>\n",
       "      <td>KK Nagar ATM</td>\n",
       "      <td>997800</td>\n",
       "      <td>WEDNESDAY</td>\n",
       "      <td>NH</td>\n",
       "      <td>W</td>\n",
       "      <td>WWW</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11582</th>\n",
       "      <td>KK Nagar ATM</td>\n",
       "      <td>1154900</td>\n",
       "      <td>THURSDAY</td>\n",
       "      <td>NH</td>\n",
       "      <td>W</td>\n",
       "      <td>WWH</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11583</th>\n",
       "      <td>Christ College ATM</td>\n",
       "      <td>1120300</td>\n",
       "      <td>THURSDAY</td>\n",
       "      <td>NH</td>\n",
       "      <td>W</td>\n",
       "      <td>WWH</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2204 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ATM Name  Total amount Withdrawn    Weekday  \\\n",
       "0          Big Street ATM                  123800   SATURDAY   \n",
       "3            KK Nagar ATM                  945300   SATURDAY   \n",
       "5          Big Street ATM                   52800     SUNDAY   \n",
       "10         Big Street ATM                   88100     MONDAY   \n",
       "13           KK Nagar ATM                 1333100     MONDAY   \n",
       "...                   ...                     ...        ...   \n",
       "11558  Christ College ATM                 1253100   SATURDAY   \n",
       "11567        KK Nagar ATM                 1175200     MONDAY   \n",
       "11577        KK Nagar ATM                  997800  WEDNESDAY   \n",
       "11582        KK Nagar ATM                 1154900   THURSDAY   \n",
       "11583  Christ College ATM                 1120300   THURSDAY   \n",
       "\n",
       "      Festival Religion Working Day Holiday Sequence  Month  Day  Year  \n",
       "0                     H           H              WHH      1    1  2011  \n",
       "3                     C           H              WHH      1    1  2011  \n",
       "5                    NH           H              HHW      2    1  2011  \n",
       "10                   NH           W              WWW      3    1  2011  \n",
       "13                   NH           W              WWW      3    1  2011  \n",
       "...                 ...         ...              ...    ...  ...   ...  \n",
       "11558                NH           H              WHH      9   23  2017  \n",
       "11567                NH           W              HWW      9   25  2017  \n",
       "11577                NH           W              WWW      9   27  2017  \n",
       "11582                NH           W              WWH      9   28  2017  \n",
       "11583                NH           W              WWH      9   28  2017  \n",
       "\n",
       "[2204 rows x 9 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_day_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kinda useless, prints a really big list that's all\n",
    "# for idx, row in outlier_day_data.iterrows():\n",
    "#     print(\"{}, {}, {}\".format(row['Year'], row['Month'], row['Day']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> I used value_counts() on Month, Day and Year of the outlier df but it contains data of multiple ATMs, so I split them to figure out the actual numbers </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For ATM: Big Street ATM\n",
      "11    42\n",
      "3     42\n",
      "4     40\n",
      "1     40\n",
      "7     38\n",
      "8     34\n",
      "2     34\n",
      "6     31\n",
      "5     27\n",
      "12    25\n",
      "10    22\n",
      "9     20\n",
      "Name: Month, dtype: int64 \n",
      "\n",
      "For ATM: KK Nagar ATM\n",
      "1     95\n",
      "5     85\n",
      "8     84\n",
      "10    83\n",
      "7     83\n",
      "11    82\n",
      "3     82\n",
      "6     78\n",
      "4     77\n",
      "2     76\n",
      "9     74\n",
      "12    69\n",
      "Name: Month, dtype: int64 \n",
      "\n",
      "For ATM: Christ College ATM\n",
      "5     38\n",
      "1     35\n",
      "4     34\n",
      "3     33\n",
      "10    29\n",
      "8     26\n",
      "7     26\n",
      "6     26\n",
      "2     24\n",
      "11    16\n",
      "9     15\n",
      "12    10\n",
      "Name: Month, dtype: int64 \n",
      "\n",
      "For ATM: Airport ATM\n",
      "1     23\n",
      "7     22\n",
      "5     19\n",
      "3     18\n",
      "6     17\n",
      "2     17\n",
      "11    16\n",
      "10    16\n",
      "4     15\n",
      "9     14\n",
      "8     14\n",
      "12    11\n",
      "Name: Month, dtype: int64 \n",
      "\n",
      "For ATM: Mount Road ATM\n",
      "6     40\n",
      "4     39\n",
      "5     36\n",
      "3     36\n",
      "1     34\n",
      "8     26\n",
      "7     25\n",
      "11    24\n",
      "10    22\n",
      "2     20\n",
      "9     14\n",
      "12    11\n",
      "Name: Month, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for atm in outlier_day_data['ATM Name'].unique():\n",
    "    print(\"For ATM:\", atm)\n",
    "    print(outlier_day_data[outlier_day_data['ATM Name'] == atm]['Month'].value_counts(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Basically KK Nagar ATM has vastly large number of outlier days as compared to the others and Airport ATM is the best in this regard </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Bank: Big Street ATM\n",
      "2011    243\n",
      "2012     78\n",
      "2016     30\n",
      "2017     24\n",
      "2014      8\n",
      "2015      7\n",
      "2013      5\n",
      "Name: Year, dtype: int64 \n",
      "\n",
      "For Bank: KK Nagar ATM\n",
      "2013    260\n",
      "2014    258\n",
      "2012    157\n",
      "2016     86\n",
      "2017     85\n",
      "2015     69\n",
      "2011     53\n",
      "Name: Year, dtype: int64 \n",
      "\n",
      "For Bank: Christ College ATM\n",
      "2017    92\n",
      "2014    75\n",
      "2016    69\n",
      "2015    34\n",
      "2013    19\n",
      "2012    12\n",
      "2011    11\n",
      "Name: Year, dtype: int64 \n",
      "\n",
      "For Bank: Airport ATM\n",
      "2016    68\n",
      "2017    54\n",
      "2015    35\n",
      "2014    17\n",
      "2013    14\n",
      "2012    11\n",
      "2011     3\n",
      "Name: Year, dtype: int64 \n",
      "\n",
      "For Bank: Mount Road ATM\n",
      "2016    106\n",
      "2015     54\n",
      "2014     54\n",
      "2017     50\n",
      "2012     30\n",
      "2013     24\n",
      "2011      9\n",
      "Name: Year, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for atm in outlier_day_data['ATM Name'].unique():\n",
    "    print(\"For ATM:\", atm)\n",
    "    print(outlier_day_data[outlier_day_data['ATM Name'] == atm]['Year'].value_counts(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> For handling outliers, something from the following cell could be used later </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_outlier_data = outlier_day_data[outlier_day_data['ATM Name'] == 'Airport ATM'].drop('ATM Name', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Training all models for each ATM separately and the results might shock you! </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training_per_atm(atm_name):\n",
    "    models = {'K-Nearest Neighbours': KNeighborsRegressor(n_neighbors=37, n_jobs=-1), 'Vanilla Linear Regression': LinearRegression(), \n",
    "          'Ridge Linear Regression': Ridge(), 'Elasticnet Linear Regression': ElasticNet(), \n",
    "          'Lasso Linear Regression': Lasso(max_iter=1100), 'Bayesian Ridge Linear Regression': BayesianRidge(), \n",
    "          'Support Vector Regression': SVR(), 'Random Forest Regression': RandomForestRegressor(), \n",
    "          'Decision Tree Regression': DecisionTreeRegressor()}\n",
    "    \n",
    "    categorical_features_list = ['Weekday', 'Festival Religion', 'Working Day', 'Holiday Sequence', 'Month', 'Day', 'Year']\n",
    "    \n",
    "    curr_atm_data = new_data[new_data['ATM Name'] == atm_name].drop('ATM Name', axis=1)\n",
    "    numeric_curr_atm_data = convert_categorical_to_numerical(curr_atm_data, categorical_features_list)\n",
    "    \n",
    "    train_data = numeric_curr_atm_data[numeric_curr_atm_data['Year_2017'] == 0]\n",
    "    test_data = numeric_curr_atm_data[numeric_curr_atm_data['Year_2017'] == 1]\n",
    "    \n",
    "    ''' Finding Outlier Months for each bank separately\n",
    "    print(\"\\nOutlier Months for bank {} are as follows,\".format(bank_name))\n",
    "    total_amt_per_mon_per_yr = {}\n",
    "    for year in curr_bank_data['Year'].unique():\n",
    "       for month in curr_bank_data['Month'].unique():\n",
    "           total_amt_per_mon_per_yr[(year, month)] = sum(curr_bank_data[curr_bank_data.apply(lambda x: x['Year'] == year\n",
    "                               and x['Month'] == month, axis=1)]['Total amount Withdrawn'])\n",
    "\n",
    "    total_amount_withdrawn = sum(total_amt_per_mon_per_yr.values())\n",
    "    avg_amount_withdrawn = sum(total_amt_per_mon_per_yr.values()) / len(total_amt_per_mon_per_yr.values())\n",
    "    # print(\"Total Amount Withdrawn:\", total_amount_withdrawn)\n",
    "    # print(\"Average Amount Withdrawn:\", avg_amount_withdrawn)\n",
    "\n",
    "    tolerance_percent = 0.7\n",
    "\n",
    "    for key in total_amt_per_mon_per_yr:\n",
    "        amount = total_amt_per_mon_per_yr[key]\n",
    "        if abs(amount - avg_amount_withdrawn) > avg_amount_withdrawn * tolerance_percent:\n",
    "            print(key)\n",
    "    '''\n",
    "    \n",
    "    # This takes 2016 data as test data and ignores 2017 data completely\n",
    "    # train_data = numeric_curr_bank_data[numeric_curr_bank_data.apply(lambda x: x['Year_2017'] == 0 and \n",
    "    #                                                                 x['Year_2016'] == 0, axis=1)]\n",
    "    # test_data = numeric_curr_bank_data[numeric_curr_bank_data['Year_2016'] == 1]\n",
    "    # Conclusions: For some reason, Airport ATM accuracy increases slightly somehow but everything else gets rekt\n",
    "    \n",
    "    \n",
    "    print(\"\\nFor ATM:\", atm_name)\n",
    "    print(\"Number of training rows:\",len(train_data))\n",
    "    print(\"Number of testing rows:\", len(test_data))\n",
    "    print()\n",
    "\n",
    "    X_train = train_data.drop('Total amount Withdrawn', axis=1)\n",
    "    y_train = train_data['Total amount Withdrawn']\n",
    "\n",
    "    X_test = test_data.drop('Total amount Withdrawn', axis=1)\n",
    "    y_test = test_data['Total amount Withdrawn']\n",
    "    \n",
    "    testing_dict_curr_atm = compute_rmse_model_list(models, X_train, y_train, X_test, y_test)\n",
    "    return testing_dict_curr_atm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For ATM: Big Street ATM\n",
      "Number of training rows: 2117\n",
      "Number of testing rows: 237\n",
      "\n",
      "RMSEs for each model\n",
      "For K-Nearest Neighbours\n",
      "\tTesting RMSE = 181461.59767223545\n",
      "\tTraining Score = 0.28999562819250424\n",
      "\tTesting Score = -0.36556725432459025\n",
      "For Vanilla Linear Regression\n",
      "\tTesting RMSE = 276512.2844681913\n",
      "\tTraining Score = 0.5444464813526175\n",
      "\tTesting Score = -2.1708266083172028\n",
      "For Ridge Linear Regression\n",
      "\tTesting RMSE = 273587.69620255945\n",
      "\tTraining Score = 0.5442115519020725\n",
      "\tTesting Score = -2.104107536431348\n",
      "For Elasticnet Linear Regression\n",
      "\tTesting RMSE = 160736.02690753856\n",
      "\tTraining Score = 0.13017936078590775\n",
      "\tTesting Score = -0.07144551642773656\n",
      "For Lasso Linear Regression\n",
      "\tTesting RMSE = 276469.1320024553\n",
      "\tTraining Score = 0.5444461398934355\n",
      "\tTesting Score = -2.169837008089656\n",
      "For Bayesian Ridge Linear Regression\n",
      "\tTesting RMSE = 270701.1207086409\n",
      "\tTraining Score = 0.5436357614309526\n",
      "\tTesting Score = -2.038951303826138\n",
      "For Support Vector Regression\n",
      "\tTesting RMSE = 158495.8194715498\n",
      "\tTraining Score = -0.0014462945200466315\n",
      "\tTesting Score = -0.04178777477528839\n",
      "For Random Forest Regression\n",
      "\tTesting RMSE = 274273.17824777367\n",
      "\tTraining Score = 0.9293449865946493\n",
      "\tTesting Score = -2.1196818890616456\n",
      "For Decision Tree Regression\n",
      "\tTesting RMSE = 276197.1078868555\n",
      "\tTraining Score = 1.0\n",
      "\tTesting Score = -2.163602330835488\n",
      "\n",
      "For ATM: Mount Road ATM\n",
      "Number of training rows: 2021\n",
      "Number of testing rows: 235\n",
      "\n",
      "RMSEs for each model\n",
      "For K-Nearest Neighbours\n",
      "\tTesting RMSE = 343922.66193841596\n",
      "\tTraining Score = 0.3529602657639054\n",
      "\tTesting Score = -2.4281120216633076\n",
      "For Vanilla Linear Regression\n",
      "\tTesting RMSE = 322167.22468273697\n",
      "\tTraining Score = 0.5181025322944846\n",
      "\tTesting Score = -2.0081267367669327\n",
      "For Ridge Linear Regression\n",
      "\tTesting RMSE = 323206.278030127\n",
      "\tTraining Score = 0.5169168741625048\n",
      "\tTesting Score = -2.0275616405234143\n",
      "For Elasticnet Linear Regression\n",
      "\tTesting RMSE = 325292.86913239764\n",
      "\tTraining Score = 0.15649508138830026\n",
      "\tTesting Score = -2.0667791651930627\n",
      "For Lasso Linear Regression\n",
      "\tTesting RMSE = 322203.5496961272\n",
      "\tTraining Score = 0.5181017969667947\n",
      "\tTesting Score = -2.0088051198912362\n",
      "For Bayesian Ridge Linear Regression\n",
      "\tTesting RMSE = 324014.4789707869\n",
      "\tTraining Score = 0.5135989086530637\n",
      "\tTesting Score = -2.0427218501556643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jasvin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:474: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 318209236896.22656, tolerance: 12393046096.022762\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Support Vector Regression\n",
      "\tTesting RMSE = 322190.0963087881\n",
      "\tTraining Score = -0.00016256288294114185\n",
      "\tTesting Score = -2.0085538639651888\n",
      "For Random Forest Regression\n",
      "\tTesting RMSE = 330544.2287369519\n",
      "\tTraining Score = 0.92114860858848\n",
      "\tTesting Score = -2.166595393698463\n",
      "For Decision Tree Regression\n",
      "\tTesting RMSE = 358425.8769628607\n",
      "\tTraining Score = 1.0\n",
      "\tTesting Score = -2.7233351562821104\n",
      "\n",
      "For ATM: Airport ATM\n",
      "Number of training rows: 2058\n",
      "Number of testing rows: 195\n",
      "\n",
      "RMSEs for each model\n",
      "For K-Nearest Neighbours\n",
      "\tTesting RMSE = 280998.75391993637\n",
      "\tTraining Score = 0.21011877894017894\n",
      "\tTesting Score = -0.320081646974691\n",
      "For Vanilla Linear Regression\n",
      "\tTesting RMSE = 270419.38396096433\n",
      "\tTraining Score = 0.32222981007075846\n",
      "\tTesting Score = -0.2225528522966016\n",
      "For Ridge Linear Regression\n",
      "\tTesting RMSE = 270340.7285163081\n",
      "\tTraining Score = 0.3217569895030462\n",
      "\tTesting Score = -0.22184176086544904\n",
      "For Elasticnet Linear Regression\n",
      "\tTesting RMSE = 274810.90552300756\n",
      "\tTraining Score = 0.09953188228525989\n",
      "\tTesting Score = -0.26258298215092557\n",
      "For Lasso Linear Regression\n",
      "\tTesting RMSE = 270427.41003619053\n",
      "\tTraining Score = 0.3222292592137085\n",
      "\tTesting Score = -0.22262542436323265\n",
      "For Bayesian Ridge Linear Regression\n",
      "\tTesting RMSE = 270597.6230639246\n",
      "\tTraining Score = 0.3157519731139333\n",
      "\tTesting Score = -0.2241650040142349\n",
      "For Support Vector Regression\n",
      "\tTesting RMSE = 277099.6585735705\n",
      "\tTraining Score = -0.00025917436172195885\n",
      "\tTesting Score = -0.2837013158547954\n",
      "For Random Forest Regression\n",
      "\tTesting RMSE = 276623.51197413163\n",
      "\tTraining Score = 0.8900447730755308\n",
      "\tTesting Score = -0.27929348024637335\n",
      "For Decision Tree Regression\n",
      "\tTesting RMSE = 282460.81107805343\n",
      "\tTraining Score = 1.0\n",
      "\tTesting Score = -0.3338543477481968\n",
      "\n",
      "For ATM: KK Nagar ATM\n",
      "Number of training rows: 2123\n",
      "Number of testing rows: 248\n",
      "\n",
      "RMSEs for each model\n",
      "For K-Nearest Neighbours\n",
      "\tTesting RMSE = 509357.0695052921\n",
      "\tTraining Score = 0.4036695621588333\n",
      "\tTesting Score = -0.8766772926341135\n",
      "For Vanilla Linear Regression\n",
      "\tTesting RMSE = 457547.2389128469\n",
      "\tTraining Score = 0.5157346139328643\n",
      "\tTesting Score = -0.5143170094807608\n",
      "For Ridge Linear Regression\n",
      "\tTesting RMSE = 452583.4106613807\n",
      "\tTraining Score = 0.5146716060699499\n",
      "\tTesting Score = -0.4816382614965147\n",
      "For Elasticnet Linear Regression\n",
      "\tTesting RMSE = 505898.64455021545\n",
      "\tTraining Score = 0.18357797183729763\n",
      "\tTesting Score = -0.8512793392665452\n",
      "For Lasso Linear Regression\n",
      "\tTesting RMSE = 457459.42343176226\n",
      "\tTraining Score = 0.5157343902470022\n",
      "\tTesting Score = -0.5137357898638595\n",
      "For"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jasvin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:474: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4886918595366.969, tolerance: 40041415972.54263\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bayesian Ridge Linear Regression\n",
      "\tTesting RMSE = 449447.70286618423\n",
      "\tTraining Score = 0.5109456907699065\n",
      "\tTesting Score = -0.46117843124706037\n",
      "For Support Vector Regression\n",
      "\tTesting RMSE = 476342.10707451584\n",
      "\tTraining Score = -0.010162086368770362\n",
      "\tTesting Score = -0.641280726160238\n",
      "For Random Forest Regression\n",
      "\tTesting RMSE = 447467.79503584607\n",
      "\tTraining Score = 0.9290283152322312\n",
      "\tTesting Score = -0.4483332148724828\n",
      "For Decision Tree Regression\n",
      "\tTesting RMSE = 483736.2540349255\n",
      "\tTraining Score = 1.0\n",
      "\tTesting Score = -0.6926306356122631\n",
      "\n",
      "For ATM: Christ College ATM\n",
      "Number of training rows: 2115\n",
      "Number of testing rows: 240\n",
      "\n",
      "RMSEs for each model\n",
      "For K-Nearest Neighbours\n",
      "\tTesting RMSE = 454068.21878890437\n",
      "\tTraining Score = 0.2887955781878394\n",
      "\tTesting Score = -0.48406666444966473\n",
      "For Vanilla Linear Regression\n",
      "\tTesting RMSE = 563369.5987146889\n",
      "\tTraining Score = 0.4884805976915243\n",
      "\tTesting Score = -1.2845360365183236\n",
      "For Ridge Linear Regression\n",
      "\tTesting RMSE = 559635.1538683609\n",
      "\tTraining Score = 0.487886260442293\n",
      "\tTesting Score = -1.254349113835958\n",
      "For Elasticnet Linear Regression\n",
      "\tTesting RMSE = 437212.60466702207\n",
      "\tTraining Score = 0.15157031881129213\n",
      "\tTesting Score = -0.37593065437858364\n",
      "For"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jasvin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:474: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 303677188912.1094, tolerance: 13354579722.531445\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Lasso Linear Regression\n",
      "\tTesting RMSE = 563333.8566610938\n",
      "\tTraining Score = 0.4884802021606778\n",
      "\tTesting Score = -1.2842461684834077\n",
      "For Bayesian Ridge Linear Regression\n",
      "\tTesting RMSE = 554222.9690183143\n",
      "\tTraining Score = 0.48620201491936166\n",
      "\tTesting Score = -1.2109567113667454\n",
      "For Support Vector Regression\n",
      "\tTesting RMSE = 464427.1776615809\n",
      "\tTraining Score = -0.01517727140145797\n",
      "\tTesting Score = -0.552553057061139\n",
      "For Random Forest Regression\n",
      "\tTesting RMSE = 570985.7485264153\n",
      "\tTraining Score = 0.9142838939241426\n",
      "\tTesting Score = -1.3467224913815858\n",
      "For Decision Tree Regression\n",
      "\tTesting RMSE = 578297.9511390877\n",
      "\tTraining Score = 1.0\n",
      "\tTesting Score = -1.4072129200603452\n"
     ]
    }
   ],
   "source": [
    "for atm_name in new_data['ATM Name'].unique():\n",
    "    testing_dict_curr_atm = model_training_per_atm(atm_name)\n",
    "    testing_summary[atm_name + ' trained with 2017 Data'] = testing_dict_curr_atm\n",
    "    \n",
    "# Note: Bayesian Ridge Linear Regression does not converge for the Mount Road and KK Nagar models and increasing n_iter\n",
    "# to even 5000 (default is 350) didn't change that at all, so that's sad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Airport ATM trained with 2017 Data': {'Bayesian Ridge Linear Regression': {'RMSE': 270597.6230639246,\n",
      "                                                                             'Testing Score': -0.2241650040142349,\n",
      "                                                                             'Training Score': 0.3157519731139333},\n",
      "                                        'Decision Tree Regression': {'RMSE': 282460.81107805343,\n",
      "                                                                     'Testing Score': -0.3338543477481968,\n",
      "                                                                     'Training Score': 1.0},\n",
      "                                        'Elasticnet Linear Regression': {'RMSE': 274810.90552300756,\n",
      "                                                                         'Testing Score': -0.26258298215092557,\n",
      "                                                                         'Training Score': 0.09953188228525989},\n",
      "                                        'K-Nearest Neighbours': {'RMSE': 280998.75391993637,\n",
      "                                                                 'Testing Score': -0.320081646974691,\n",
      "                                                                 'Training Score': 0.21011877894017894},\n",
      "                                        'Lasso Linear Regression': {'RMSE': 270427.41003619053,\n",
      "                                                                    'Testing Score': -0.22262542436323265,\n",
      "                                                                    'Training Score': 0.3222292592137085},\n",
      "                                        'Random Forest Regression': {'RMSE': 276623.51197413163,\n",
      "                                                                     'Testing Score': -0.27929348024637335,\n",
      "                                                                     'Training Score': 0.8900447730755308},\n",
      "                                        'Ridge Linear Regression': {'RMSE': 270340.7285163081,\n",
      "                                                                    'Testing Score': -0.22184176086544904,\n",
      "                                                                    'Training Score': 0.3217569895030462},\n",
      "                                        'Support Vector Regression': {'RMSE': 277099.6585735705,\n",
      "                                                                      'Testing Score': -0.2837013158547954,\n",
      "                                                                      'Training Score': -0.00025917436172195885},\n",
      "                                        'Vanilla Linear Regression': {'RMSE': 270419.38396096433,\n",
      "                                                                      'Testing Score': -0.2225528522966016,\n",
      "                                                                      'Training Score': 0.32222981007075846}},\n",
      " 'All ATMs Trained with 2017 Test Data': {'Bayesian Ridge Linear Regression': {'RMSE': 349989.46216254827,\n",
      "                                                                               'Testing Score': -0.07320140697245625,\n",
      "                                                                               'Training Score': 0.4530724819355578},\n",
      "                                          'Decision Tree Regression': {'RMSE': 415090.50076680846,\n",
      "                                                                       'Testing Score': -0.509582616818163,\n",
      "                                                                       'Training Score': 1.0},\n",
      "                                          'Elasticnet Linear Regression': {'RMSE': 343651.78719365434,\n",
      "                                                                           'Testing Score': -0.03468585104161148,\n",
      "                                                                           'Training Score': 0.18540431599596496},\n",
      "                                          'K-Nearest Neighbours': {'RMSE': 370654.38876929344,\n",
      "                                                                   'Testing Score': -0.2036759694108361,\n",
      "                                                                   'Training Score': 0.49334898232826474},\n",
      "                                          'Lasso Linear Regression': {'RMSE': 351207.1555167714,\n",
      "                                                                      'Testing Score': -0.08068222421466187,\n",
      "                                                                      'Training Score': 0.4535207164047764},\n",
      "                                          'Random Forest Regression': {'RMSE': 400647.72479138186,\n",
      "                                                                       'Testing Score': -0.40636049422891585,\n",
      "                                                                       'Training Score': 0.9443151597170375},\n",
      "                                          'Ridge Linear Regression': {'RMSE': 350930.3772714196,\n",
      "                                                                      'Testing Score': -0.07897957400080258,\n",
      "                                                                      'Training Score': 0.4534927053204132},\n",
      "                                          'Support Vector Regression': {'RMSE': 339522.5629301751,\n",
      "                                                                        'Testing Score': -0.00997024184255646,\n",
      "                                                                        'Training Score': -0.025059950311879797},\n",
      "                                          'Vanilla Linear Regression': {'RMSE': 351236.1852653552,\n",
      "                                                                        'Testing Score': -0.08086088361456811,\n",
      "                                                                        'Training Score': 0.4535210215154458}},\n",
      " 'All ATMs Trained with 2017 Test Data (No Outlier Months)': {'Bayesian Ridge Linear Regression': {'RMSE': 350577.01082009525,\n",
      "                                                                                                   'Testing Score': -0.06550274948102763,\n",
      "                                                                                                   'Training Score': 0.4530724819355578},\n",
      "                                                              'Decision Tree Regression': {'RMSE': 418249.2452803565,\n",
      "                                                                                           'Testing Score': -0.516554559966816,\n",
      "                                                                                           'Training Score': 1.0},\n",
      "                                                              'Elasticnet Linear Regression': {'RMSE': 345648.1068296639,\n",
      "                                                                                               'Testing Score': -0.03575269583521212,\n",
      "                                                                                               'Training Score': 0.18540431599596496},\n",
      "                                                              'K-Nearest Neighbours': {'RMSE': 372340.49206527043,\n",
      "                                                                                       'Testing Score': -0.2018997476884299,\n",
      "                                                                                       'Training Score': 0.49334898232826474},\n",
      "                                                              'Lasso Linear Regression': {'RMSE': 351681.79185469187,\n",
      "                                                                                          'Testing Score': -0.07222881524409619,\n",
      "                                                                                          'Training Score': 0.4535207164047764},\n",
      "                                                              'Random Forest Regression': {'RMSE': 400781.0743700633,\n",
      "                                                                                           'Testing Score': -0.3925221680637721,\n",
      "                                                                                           'Training Score': 0.9441106189079738},\n",
      "                                                              'Ridge Linear Regression': {'RMSE': 351434.1312815757,\n",
      "                                                                                          'Testing Score': -0.07071918178027703,\n",
      "                                                                                          'Training Score': 0.4534927053204132},\n",
      "                                                              'Support Vector Regression': {'RMSE': 341483.98469625093,\n",
      "                                                                                            'Testing Score': -0.010947000905629833,\n",
      "                                                                                            'Training Score': -0.025059950311879797},\n",
      "                                                              'Vanilla Linear Regression': {'RMSE': 351707.4107674948,\n",
      "                                                                                            'Testing Score': -0.07238503792997997,\n",
      "                                                                                            'Training Score': 0.4535210215154458}},\n",
      " 'All ATMs Trained with Train Test Split': {'Bayesian Ridge Linear Regression': {'RMSE': 251396.25827460986,\n",
      "                                                                                 'Testing Score': 0.40957478518163776,\n",
      "                                                                                 'Training Score': 0.4006642870319033},\n",
      "                                            'Decision Tree Regression': {'RMSE': 258864.64985155227,\n",
      "                                                                         'Testing Score': 0.3739734197065788,\n",
      "                                                                         'Training Score': 1.0},\n",
      "                                            'Elasticnet Linear Regression': {'RMSE': 299840.48379522713,\n",
      "                                                                             'Testing Score': 0.16009954359397116,\n",
      "                                                                             'Training Score': 0.1599098376804099},\n",
      "                                            'K-Nearest Neighbours': {'RMSE': 243308.4815900565,\n",
      "                                                                     'Testing Score': 0.4469533394817221,\n",
      "                                                                     'Training Score': 0.45697266653028884},\n",
      "                                            'Lasso Linear Regression': {'RMSE': 251415.86960634057,\n",
      "                                                                        'Testing Score': 0.40948266387110405,\n",
      "                                                                        'Training Score': 0.4013359783757806},\n",
      "                                            'Random Forest Regression': {'RMSE': 206606.11951902052,\n",
      "                                                                         'Testing Score': 0.6012197520412734,\n",
      "                                                                         'Training Score': 0.9389306830314473},\n",
      "                                            'Ridge Linear Regression': {'RMSE': 251386.47604234665,\n",
      "                                                                        'Testing Score': 0.4096207330748531,\n",
      "                                                                        'Training Score': 0.4013043683235682},\n",
      "                                            'Support Vector Regression': {'RMSE': 330051.3590919249,\n",
      "                                                                          'Testing Score': -0.01767786439476282,\n",
      "                                                                          'Training Score': -0.023764153336445215},\n",
      "                                            'Vanilla Linear Regression': {'RMSE': 251419.81922358868,\n",
      "                                                                          'Testing Score': 0.409464110262857,\n",
      "                                                                          'Training Score': 0.4013361571445507}},\n",
      " 'Big Street ATM trained with 2017 Data': {'Bayesian Ridge Linear Regression': {'RMSE': 270701.1207086409,\n",
      "                                                                                'Testing Score': -2.038951303826138,\n",
      "                                                                                'Training Score': 0.5436357614309526},\n",
      "                                           'Decision Tree Regression': {'RMSE': 276197.1078868555,\n",
      "                                                                        'Testing Score': -2.163602330835488,\n",
      "                                                                        'Training Score': 1.0},\n",
      "                                           'Elasticnet Linear Regression': {'RMSE': 160736.02690753856,\n",
      "                                                                            'Testing Score': -0.07144551642773656,\n",
      "                                                                            'Training Score': 0.13017936078590775},\n",
      "                                           'K-Nearest Neighbours': {'RMSE': 181461.59767223545,\n",
      "                                                                    'Testing Score': -0.36556725432459025,\n",
      "                                                                    'Training Score': 0.28999562819250424},\n",
      "                                           'Lasso Linear Regression': {'RMSE': 276469.1320024553,\n",
      "                                                                       'Testing Score': -2.169837008089656,\n",
      "                                                                       'Training Score': 0.5444461398934355},\n",
      "                                           'Random Forest Regression': {'RMSE': 274273.17824777367,\n",
      "                                                                        'Testing Score': -2.1196818890616456,\n",
      "                                                                        'Training Score': 0.9293449865946493},\n",
      "                                           'Ridge Linear Regression': {'RMSE': 273587.69620255945,\n",
      "                                                                       'Testing Score': -2.104107536431348,\n",
      "                                                                       'Training Score': 0.5442115519020725},\n",
      "                                           'Support Vector Regression': {'RMSE': 158495.8194715498,\n",
      "                                                                         'Testing Score': -0.04178777477528839,\n",
      "                                                                         'Training Score': -0.0014462945200466315},\n",
      "                                           'Vanilla Linear Regression': {'RMSE': 276512.2844681913,\n",
      "                                                                         'Testing Score': -2.1708266083172028,\n",
      "                                                                         'Training Score': 0.5444464813526175}},\n",
      " 'Christ College ATM trained with 2017 Data': {'Bayesian Ridge Linear Regression': {'RMSE': 554222.9690183143,\n",
      "                                                                                    'Testing Score': -1.2109567113667454,\n",
      "                                                                                    'Training Score': 0.48620201491936166},\n",
      "                                               'Decision Tree Regression': {'RMSE': 578297.9511390877,\n",
      "                                                                            'Testing Score': -1.4072129200603452,\n",
      "                                                                            'Training Score': 1.0},\n",
      "                                               'Elasticnet Linear Regression': {'RMSE': 437212.60466702207,\n",
      "                                                                                'Testing Score': -0.37593065437858364,\n",
      "                                                                                'Training Score': 0.15157031881129213},\n",
      "                                               'K-Nearest Neighbours': {'RMSE': 454068.21878890437,\n",
      "                                                                        'Testing Score': -0.48406666444966473,\n",
      "                                                                        'Training Score': 0.2887955781878394},\n",
      "                                               'Lasso Linear Regression': {'RMSE': 563333.8566610938,\n",
      "                                                                           'Testing Score': -1.2842461684834077,\n",
      "                                                                           'Training Score': 0.4884802021606778},\n",
      "                                               'Random Forest Regression': {'RMSE': 570985.7485264153,\n",
      "                                                                            'Testing Score': -1.3467224913815858,\n",
      "                                                                            'Training Score': 0.9142838939241426},\n",
      "                                               'Ridge Linear Regression': {'RMSE': 559635.1538683609,\n",
      "                                                                           'Testing Score': -1.254349113835958,\n",
      "                                                                           'Training Score': 0.487886260442293},\n",
      "                                               'Support Vector Regression': {'RMSE': 464427.1776615809,\n",
      "                                                                             'Testing Score': -0.552553057061139,\n",
      "                                                                             'Training Score': -0.01517727140145797},\n",
      "                                               'Vanilla Linear Regression': {'RMSE': 563369.5987146889,\n",
      "                                                                             'Testing Score': -1.2845360365183236,\n",
      "                                                                             'Training Score': 0.4884805976915243}},\n",
      " 'KK Nagar ATM trained with 2017 Data': {'Bayesian Ridge Linear Regression': {'RMSE': 449447.70286618423,\n",
      "                                                                              'Testing Score': -0.46117843124706037,\n",
      "                                                                              'Training Score': 0.5109456907699065},\n",
      "                                         'Decision Tree Regression': {'RMSE': 483736.2540349255,\n",
      "                                                                      'Testing Score': -0.6926306356122631,\n",
      "                                                                      'Training Score': 1.0},\n",
      "                                         'Elasticnet Linear Regression': {'RMSE': 505898.64455021545,\n",
      "                                                                          'Testing Score': -0.8512793392665452,\n",
      "                                                                          'Training Score': 0.18357797183729763},\n",
      "                                         'K-Nearest Neighbours': {'RMSE': 509357.0695052921,\n",
      "                                                                  'Testing Score': -0.8766772926341135,\n",
      "                                                                  'Training Score': 0.4036695621588333},\n",
      "                                         'Lasso Linear Regression': {'RMSE': 457459.42343176226,\n",
      "                                                                     'Testing Score': -0.5137357898638595,\n",
      "                                                                     'Training Score': 0.5157343902470022},\n",
      "                                         'Random Forest Regression': {'RMSE': 447467.79503584607,\n",
      "                                                                      'Testing Score': -0.4483332148724828,\n",
      "                                                                      'Training Score': 0.9290283152322312},\n",
      "                                         'Ridge Linear Regression': {'RMSE': 452583.4106613807,\n",
      "                                                                     'Testing Score': -0.4816382614965147,\n",
      "                                                                     'Training Score': 0.5146716060699499},\n",
      "                                         'Support Vector Regression': {'RMSE': 476342.10707451584,\n",
      "                                                                       'Testing Score': -0.641280726160238,\n",
      "                                                                       'Training Score': -0.010162086368770362},\n",
      "                                         'Vanilla Linear Regression': {'RMSE': 457547.2389128469,\n",
      "                                                                       'Testing Score': -0.5143170094807608,\n",
      "                                                                       'Training Score': 0.5157346139328643}},\n",
      " 'Mount Road ATM trained with 2017 Data': {'Bayesian Ridge Linear Regression': {'RMSE': 324014.4789707869,\n",
      "                                                                                'Testing Score': -2.0427218501556643,\n",
      "                                                                                'Training Score': 0.5135989086530637},\n",
      "                                           'Decision Tree Regression': {'RMSE': 358425.8769628607,\n",
      "                                                                        'Testing Score': -2.7233351562821104,\n",
      "                                                                        'Training Score': 1.0},\n",
      "                                           'Elasticnet Linear Regression': {'RMSE': 325292.86913239764,\n",
      "                                                                            'Testing Score': -2.0667791651930627,\n",
      "                                                                            'Training Score': 0.15649508138830026},\n",
      "                                           'K-Nearest Neighbours': {'RMSE': 343922.66193841596,\n",
      "                                                                    'Testing Score': -2.4281120216633076,\n",
      "                                                                    'Training Score': 0.3529602657639054},\n",
      "                                           'Lasso Linear Regression': {'RMSE': 322203.5496961272,\n",
      "                                                                       'Testing Score': -2.0088051198912362,\n",
      "                                                                       'Training Score': 0.5181017969667947},\n",
      "                                           'Random Forest Regression': {'RMSE': 330544.2287369519,\n",
      "                                                                        'Testing Score': -2.166595393698463,\n",
      "                                                                        'Training Score': 0.92114860858848},\n",
      "                                           'Ridge Linear Regression': {'RMSE': 323206.278030127,\n",
      "                                                                       'Testing Score': -2.0275616405234143,\n",
      "                                                                       'Training Score': 0.5169168741625048},\n",
      "                                           'Support Vector Regression': {'RMSE': 322190.0963087881,\n",
      "                                                                         'Testing Score': -2.0085538639651888,\n",
      "                                                                         'Training Score': -0.00016256288294114185},\n",
      "                                           'Vanilla Linear Regression': {'RMSE': 322167.22468273697,\n",
      "                                                                         'Testing Score': -2.0081267367669327,\n",
      "                                                                         'Training Score': 0.5181025322944846}}}\n"
     ]
    }
   ],
   "source": [
    "pprint(testing_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> I know the output is a bit long, but read it for cool insights and damn Big Street ATM is the OP right now, SVR got 1 lakh 58 thousand RMSE on it </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Upto this point, removing outlier months from test set has had no effect, be it for the model with all ATMs or for individual ATMs, infact it made the RMSE worse at times, so I think we can stop pursuing the outlier month part for now </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Hyperparameter Tuning </h2>\n",
    "<p> Right now, just focused on SVR as it performs the best consistently </p>\n",
    "<p> Note that the function below this cell takes the bank_name and the random search or grid search object and does all the tasks of converting to numeric data, train test split using 2017 data and then does Cross Validation and then computes the RMSE on the best estimator found after hyperparameter search </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Works for both RandomizedSearchCV() object and GridSearchCV() object\n",
    "def model_training_hyperparam_per_atm(atm_name, param_cv_obj):\n",
    "    categorical_features_list = ['Weekday', 'Festival Religion', 'Working Day', 'Holiday Sequence', 'Month', 'Day', 'Year']\n",
    "    \n",
    "    curr_atm_data = new_data[new_data['ATM Name'] == atm_name].drop('ATM Name', axis=1)\n",
    "    numeric_curr_atm_data = convert_categorical_to_numerical(curr_atm_data, categorical_features_list)\n",
    "    \n",
    "    train_data = numeric_curr_atm_data[numeric_curr_bank_data['Year_2017'] == 0]\n",
    "    test_data = numeric_curr_atm_data[numeric_curr_atm_data['Year_2017'] == 1]\n",
    "    \n",
    "    X_train = train_data.drop('Total amount Withdrawn', axis=1)\n",
    "    y_train = train_data['Total amount Withdrawn']\n",
    "\n",
    "    X_test = test_data.drop('Total amount Withdrawn', axis=1)\n",
    "    y_test = test_data['Total amount Withdrawn']\n",
    "    \n",
    "    param_cv_obj.fit(X_train, y_train)\n",
    "    print(\"Best Parameters:\\n\", param_cv_obj.best_params_)\n",
    "    print(\"\\nBest Score:\", param_cv_obj.best_score_)\n",
    "    \n",
    "    best_model = param_cv_obj.best_estimator_\n",
    "    model_predictions = best_model.predict(X_test)\n",
    "    model_rmse = np.sqrt(mean_squared_error(y_test, model_predictions))\n",
    "    \n",
    "    print(\"Test RMSE:\", model_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "random_grid_svr = {'C': list(np.logspace(np.log10(0.001), np.log10(1000), num=50)),\n",
    "                         'epsilon': list(np.logspace(np.log10(0.001), np.log10(1000), num=50))}\n",
    "\n",
    "random_cv_svr = RandomizedSearchCV(SVR(), random_grid_svr, n_iter=50, verbose=5, n_jobs=-1)\n",
    "grid_cv_svr = GridSearchCV(SVR(), random_grid_svr, verbose=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> SVR Randomized Search for all ATMs individually </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Random Search with SVR on Big Street ATM \n",
      "\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   34.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'epsilon': 0.09102981779915217, 'C': 1000.0}\n",
      "\n",
      "Best Score: -3.7124562844354996\n",
      "Test RMSE: 158667.22328326612\n",
      "\n",
      "Performing Random Search with SVR on Mount Road ATM \n",
      "\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   30.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'epsilon': 8.286427728546842, 'C': 754.3120063354608}\n",
      "\n",
      "Best Score: -0.17360611533618792\n",
      "Test RMSE: 321900.5095177688\n",
      "\n",
      "Performing Random Search with SVR on Airport ATM \n",
      "\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   29.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'epsilon': 44.98432668969444, 'C': 754.3120063354608}\n",
      "\n",
      "Best Score: -0.3636847590282068\n",
      "Test RMSE: 275640.7992790201\n",
      "\n",
      "Performing Random Search with SVR on KK Nagar ATM \n",
      "\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   32.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'epsilon': 0.004094915062380427, 'C': 1000.0}\n",
      "\n",
      "Best Score: -0.5388856431758656\n",
      "Test RMSE: 478463.1040340031\n",
      "\n",
      "Performing Random Search with SVR on Christ College ATM \n",
      "\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   19.5s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   31.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'epsilon': 79.06043210907701, 'C': 754.3120063354608}\n",
      "\n",
      "Best Score: -0.8125141511904909\n",
      "Test RMSE: 460281.29039404966\n"
     ]
    }
   ],
   "source": [
    "for atm_name in atm_names:\n",
    "    print(\"\\nPerforming Random Search with SVR on\", atm_name, \"\\n\")\n",
    "    model_training_hyperparam_per_bank(atm_name, random_cv_svr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Training Model on All ATMs but using Test Data from individual ATMs </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_atm_model_training_with_different_test_atms():\n",
    "    models = {'K-Nearest Neighbours': KNeighborsRegressor(n_neighbors=37, n_jobs=-1), 'Vanilla Linear Regression': LinearRegression(), \n",
    "          'Ridge Linear Regression': Ridge(), 'Elasticnet Linear Regression': ElasticNet(), \n",
    "          'Lasso Linear Regression': Lasso(max_iter=1100), 'Bayesian Ridge Linear Regression': BayesianRidge(), \n",
    "          'Support Vector Regression': SVR(), 'Random Forest Regression': RandomForestRegressor(), \n",
    "          'Decision Tree Regression': DecisionTreeRegressor()}\n",
    "    \n",
    "    categorical_features_list = ['ATM Name', 'Weekday', 'Festival Religion', 'Working Day', 'Holiday Sequence', 'Month', 'Day', 'Year']\n",
    "    atm_names = new_data['ATM Name'].unique()\n",
    "    \n",
    "    numeric_data = convert_categorical_to_numerical(new_data, categorical_features_list)\n",
    "    \n",
    "    train_data = numeric_data[numeric_data['Year_2017'] == 0]\n",
    "    test_data = numeric_data[numeric_data['Year_2017'] == 1]\n",
    "    \n",
    "    for atm_name in atm_names:\n",
    "        print(\"\\nFor ATM:\", atm_name)\n",
    "    \n",
    "        train_data = numeric_data[numeric_data['Year_2017'] == 0]\n",
    "        test_data = numeric_data[numeric_data['Year_2017'] == 1]\n",
    "        \n",
    "        X_train = train_data.drop('Total amount Withdrawn', axis=1)\n",
    "        y_train = train_data['Total amount Withdrawn']\n",
    "        \n",
    "        # I know this is sad jugaad, but its honest work and yeah Airport ATM column gets dropped in pd.get_dummies\n",
    "        # so I'm just using that knowledge to hardcode column names here\n",
    "        if atm_name != 'Airport ATM':\n",
    "            curr_atm_test_data = test_data[test_data['ATM Name_' + atm_name] == 1]\n",
    "        else:\n",
    "            curr_atm_test_data = test_data[test_data.apply(\n",
    "                lambda x: x['ATM Name_Big Street ATM'] == 0 and x['ATM Name_Mount Road ATM'] == 0\n",
    "                        and x['ATM Name_KK Nagar ATM'] == 0 and x['ATM Name_Christ College ATM'] == 0, axis=1)]\n",
    "        \n",
    "        X_test = curr_atm_test_data.drop('Total amount Withdrawn', axis=1)\n",
    "        y_test = curr_atm_test_data['Total amount Withdrawn']\n",
    "\n",
    "        compute_rmse_model_list(models, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Tbh idk what to make of this result, its weird. In some ways, the trash ATMs are performing trash but some models are performing quite well on Mount Road ATM which didn't happen with the individual model, so I guess KK and Christ College are the ones that we need to destroy </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For ATM: Big Street ATM\n",
      "RMSEs for each model\n",
      "For K-Nearest Neighbours\n",
      "\tTesting RMSE = 162048.53448888898\n",
      "\tTraining Score = 0.49334898232826474\n",
      "\tTesting Score = -0.08901496813590071\n",
      "For Vanilla Linear Regression\n",
      "\tTesting RMSE = 220189.09903158885\n",
      "\tTraining Score = 0.4535210215154458\n",
      "\tTesting Score = -1.0106443707888442\n",
      "For Ridge Linear Regression\n",
      "\tTesting RMSE = 219576.6116433178\n",
      "\tTraining Score = 0.4534927053204132\n",
      "\tTesting Score = -0.999474139962197\n",
      "For Elasticnet Linear Regression\n",
      "\tTesting RMSE = 195328.06172366143\n",
      "\tTraining Score = 0.18540431599596496\n",
      "\tTesting Score = -0.5822420217548594\n",
      "For Lasso Linear Regression\n",
      "\tTesting RMSE = 220144.91294633946\n",
      "\tTraining Score = 0.4535207164047764\n",
      "\tTesting Score = -1.009837486253661\n",
      "For Bayesian Ridge Linear Regression\n",
      "\tTesting RMSE = 217227.5114218556\n",
      "\tTraining Score = 0.4530724819355578\n",
      "\tTesting Score = -0.9569209709453393\n",
      "For Support Vector Regression\n",
      "\tTesting RMSE = 206787.19561842582\n",
      "\tTraining Score = -0.025059950311879797\n",
      "\tTesting Score = -0.7733355500489617\n",
      "For Random Forest Regression\n",
      "\tTesting RMSE = 273876.34248254454\n",
      "\tTraining Score = 0.9446444637335443\n",
      "\tTesting Score = -2.11066091407364\n",
      "For Decision Tree Regression\n",
      "\tTesting RMSE = 274835.1284826983\n",
      "\tTraining Score = 1.0\n",
      "\tTesting Score = -2.1324786337178177\n",
      "\n",
      "For ATM: Mount Road ATM\n",
      "RMSEs for each model\n",
      "For K-Nearest Neighbours\n",
      "\tTesting RMSE = 341323.50938629085\n",
      "\tTraining Score = 0.49334898232826474\n",
      "\tTesting Score = -2.3764927578971555\n",
      "For Vanilla Linear Regression\n",
      "\tTesting RMSE = 236570.54001943703\n",
      "\tTraining Score = 0.4535210215154458\n",
      "\tTesting Score = -0.6220145307364235\n",
      "For Ridge Linear Regression\n",
      "\tTesting RMSE = 236961.05756491687\n",
      "\tTraining Score = 0.4534927053204132\n",
      "\tTesting Score = -0.6273740141682007\n",
      "For Elasticnet Linear Regression\n",
      "\tTesting RMSE = 312034.4424627046\n",
      "\tTraining Score = 0.18540431599596496\n",
      "\tTesting Score = -1.8218796424350097\n",
      "For Lasso Linear Regression\n",
      "\tTesting RMSE = 236594.5273647494\n",
      "\tTraining Score = 0.4535207164047764\n",
      "\tTesting Score = -0.6223434795159231\n",
      "For Bayesian Ridge Linear Regression\n",
      "\tTesting RMSE = 238385.57808473273\n",
      "\tTraining Score = 0.4530724819355578\n",
      "\tTesting Score = -0.6469991446076486\n",
      "For Support Vector Regression\n",
      "\tTesting RMSE = 275867.47688101244\n",
      "\tTraining Score = -0.025059950311879797\n",
      "\tTesting Score = -1.2056389555573643\n",
      "For Random Forest Regression\n",
      "\tTesting RMSE = 328979.3681478547\n",
      "\tTraining Score = 0.9444721280379424\n",
      "\tTesting Score = -2.136683809870424\n",
      "For Decision Tree Regression\n",
      "\tTesting RMSE = 349636.43901824893\n",
      "\tTraining Score = 1.0\n",
      "\tTesting Score = -2.542964450955756\n",
      "\n",
      "For ATM: Airport ATM\n",
      "RMSEs for each model\n",
      "For K-Nearest Neighbours\n",
      "\tTesting RMSE = 303785.07636450836\n",
      "\tTraining Score = 0.49334898232826474\n",
      "\tTesting Score = -0.5428541575712273\n",
      "For Vanilla Linear Regression\n",
      "\tTesting RMSE = 252359.49924401764\n",
      "\tTraining Score = 0.4535210215154458\n",
      "\tTesting Score = -0.06470996540650775\n",
      "For Ridge Linear Regression\n",
      "\tTesting RMSE = 252118.7299887666\n",
      "\tTraining Score = 0.4534927053204132\n",
      "\tTesting Score = -0.0626793135924899\n",
      "For Elasticnet Linear Regression\n",
      "\tTesting RMSE = 313296.0445372798\n",
      "\tTraining Score = 0.18540431599596496\n",
      "\tTesting Score = -0.6409744859826878\n",
      "For Lasso Linear Regression\n",
      "\tTesting RMSE = 252330.61534224072\n",
      "\tTraining Score = 0.4535207164047764\n",
      "\tTesting Score = -0.06446625579199394\n",
      "For Bayesian Ridge Linear Regression\n",
      "\tTesting RMSE = 251502.5319476182\n",
      "\tTraining Score = 0.4530724819355578\n",
      "\tTesting Score = -0.05749111758275638\n",
      "For Support Vector Regression\n",
      "\tTesting RMSE = 287767.69983870786\n",
      "\tTraining Score = -0.025059950311879797\n",
      "\tTesting Score = -0.3844462392916834\n",
      "For Random Forest Regression\n",
      "\tTesting RMSE = 265614.24027611245\n",
      "\tTraining Score = 0.944210938638895\n",
      "\tTesting Score = -0.17949122710366172\n",
      "For Decision Tree Regression\n",
      "\tTesting RMSE = 289148.5089991132\n",
      "\tTraining Score = 1.0\n",
      "\tTesting Score = -0.39776422073655526\n",
      "\n",
      "For ATM: KK Nagar ATM\n",
      "RMSEs for each model\n",
      "For K-Nearest Neighbours\n",
      "\tTesting RMSE = 483858.6272859811\n",
      "\tTraining Score = 0.49334898232826474\n",
      "\tTesting Score = -0.6934871309098674\n",
      "For Vanilla Linear Regression\n",
      "\tTesting RMSE = 442596.9434823288\n",
      "\tTraining Score = 0.4535210215154458\n",
      "\tTesting Score = -0.41697355001215874\n",
      "For Ridge Linear Regression\n",
      "\tTesting RMSE = 442118.99181056663\n",
      "\tTraining Score = 0.4534927053204132\n",
      "\tTesting Score = -0.41391487906842395\n",
      "For Elasticnet Linear Regression\n",
      "\tTesting RMSE = 393383.6149721097\n",
      "\tTraining Score = 0.18540431599596496\n",
      "\tTesting Score = -0.11937977701927016\n",
      "For Lasso Linear Regression\n",
      "\tTesting RMSE = 442540.0455353829\n",
      "\tTraining Score = 0.4535207164047764\n",
      "\tTesting Score = -0.4166092560203838\n",
      "For Bayesian Ridge Linear Regression\n",
      "\tTesting RMSE = 440965.6127933868\n",
      "\tTraining Score = 0.4530724819355578\n",
      "\tTesting Score = -0.4065473936927726\n",
      "For Support Vector Regression\n",
      "\tTesting RMSE = 371827.96052269085\n",
      "\tTraining Score = -0.025059950311879797\n",
      "\tTesting Score = -6.68042135216762e-05\n",
      "For Random Forest Regression\n",
      "\tTesting RMSE = 447148.7064896227\n",
      "\tTraining Score = 0.9442298672098346\n",
      "\tTesting Score = -0.4462683433123915\n",
      "For Decision Tree Regression\n",
      "\tTesting RMSE = 484197.8957180028\n",
      "\tTraining Score = 1.0\n",
      "\tTesting Score = -0.6958628171924439\n",
      "\n",
      "For ATM: Christ College ATM\n",
      "RMSEs for each model\n",
      "For K-Nearest Neighbours\n",
      "\tTesting RMSE = 451943.18730955\n",
      "\tTraining Score = 0.49334898232826474\n",
      "\tTesting Score = -0.47020835573986974\n",
      "For Vanilla Linear Regression\n",
      "\tTesting RMSE = 486682.67388472543\n",
      "\tTraining Score = 0.4535210215154458\n",
      "\tTesting Score = -0.704915932624363\n",
      "For Ridge Linear Regression\n",
      "\tTesting RMSE = 486258.36253772915\n",
      "\tTraining Score = 0.4534927053204132\n",
      "\tTesting Score = -0.7019443872535712\n",
      "For Elasticnet Linear Regression\n",
      "\tTesting RMSE = 442342.60857288766\n",
      "\tTraining Score = 0.18540431599596496\n",
      "\tTesting Score = -0.4084088580734455\n",
      "For Lasso Linear Regression\n",
      "\tTesting RMSE = 486655.80756614386\n",
      "\tTraining Score = 0.4535207164047764\n",
      "\tTesting Score = -0.7047277050470191\n",
      "For Bayesian Ridge Linear Regression\n",
      "\tTesting RMSE = 484693.9080350461\n",
      "\tTraining Score = 0.4530724819355578\n",
      "\tTesting Score = -0.6910105647942222\n",
      "For Support Vector Regression\n",
      "\tTesting RMSE = 477359.37118390424\n",
      "\tTraining Score = -0.025059950311879797\n",
      "\tTesting Score = -0.6402200028779519\n",
      "For Random Forest Regression\n",
      "\tTesting RMSE = 570743.4454219594\n",
      "\tTraining Score = 0.9439841849511784\n",
      "\tTesting Score = -1.344731207020354\n",
      "For Decision Tree Regression\n",
      "\tTesting RMSE = 579175.594487544\n",
      "\tTraining Score = 1.0\n",
      "\tTesting Score = -1.4145249900213552\n"
     ]
    }
   ],
   "source": [
    "all_atm_model_training_with_different_test_atms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Storing Testing Summary of all Training before the Hyperparameter Stuff into a JSON file </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open('testing_summary.json', 'w') as file:\n",
    "#     json_string = json.dumps(testing_summary, default=lambda o: o.__dict__, indent=4)\n",
    "#     file.write(json_string)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
