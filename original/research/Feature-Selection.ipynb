{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [Function for Hyperparameter Tuning and Computing Feature Importance](#hyperparameter-tuning)\n",
    "2. [Generating Rainfall Status Column](#rainfall-status)\n",
    "3. [Running Some Models to Measure Importance of Rainfall Status](#rainfall-models)\n",
    "4. [Finding Correlation in Original ATM Data and Running Models by Dropping Correlated Columns](#atm-correlation)\n",
    "5. [Amount Withdrawn as a Categorical Column](#categorical-output)\n",
    "6. [Chi-Squared Test on Categorical Data](#chi-squared)\n",
    "7. [Recursive Feature Elimination](#rfe)\n",
    "8. [Chi-Squared Test on Categorical Data](#chi-squared)\n",
    "9. [Hyperparameter Tuning on Categorical Models](#categorical-hyperparameter-tuning)\n",
    "10. [Running Models using Sequential Train-Test Split](#sequential-train-test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparatory imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, BayesianRidge, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, accuracy_score, balanced_accuracy_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, validation_curve, cross_val_score, train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.inspection import permutation_importance\n",
    "from regressors import stats # useful for determing p-values of each feature\n",
    "from sklearn.feature_selection import chi2, RFE\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing and cleaning\n",
    "<p> Weather Data columns that were dropped beforehand because of high correlation include, maxtempC, HeatIndexC, WindChillC, tempC, WindGustKmph, DewPointC </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_csv('../data/aggregated_atm_data_with_weather_data.csv ')\n",
    "combined_data.drop(['No Of Withdrawals', 'No Of XYZ Card Withdrawals', 'No Of Other Card Withdrawals', \n",
    "                    'Amount withdrawn XYZ Card', 'Amount withdrawn Other Card',\n",
    "                    'maxtempC', 'HeatIndexC', 'WindChillC', 'tempC', 'WindGustKmph', 'DewPointC'], axis=1, inplace=True)\n",
    "\n",
    "combined_data['Transaction Date'] = pd.to_datetime(combined_data['Transaction Date'])\n",
    "combined_data['Day'] = combined_data['Transaction Date'].dt.day\n",
    "combined_data['Month'] = combined_data['Transaction Date'].dt.month\n",
    "combined_data['Year'] = combined_data['Transaction Date'].dt.year\n",
    "combined_data.drop('Transaction Date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Further columns dropped because of complications involving converting time to numeric values and avoiding generation of large number of dummy columns at the same time and just pure irrelevance as well too</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.drop(['moonrise', 'moonset', 'sunrise', 'sunset', 'winddirDegree', 'mintempC'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "atm_names = combined_data['ATM Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_list = ['Weekday', 'Festival Religion', 'Working Day', 'Holiday Sequence', \n",
    "                             'Month', 'Day', 'Year',\n",
    "                            'uvIndex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_categorical_to_numerical(data, column_list):\n",
    "    if 'ATM Name' in column_list:\n",
    "        column_list.remove('ATM Name')\n",
    "        temp_data = pd.get_dummies(data, columns=column_list , drop_first=True)\n",
    "    \n",
    "        # Do drop_first for all columns, except for ATM Name, because it becomes useful for accessing individual ATM test\n",
    "        # data later on\n",
    "        return pd.get_dummies(temp_data, columns=['ATM Name'])\n",
    "    else:\n",
    "        return pd.get_dummies(data, columns=column_list, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"hyperparameter-tuning\"></a>\n",
    "## Hyperparameter Tuning for Regression and evaluating feature importance too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Functions for Training Tree_Models and Linear_Models to handle their different methods of getting feature importance \n",
    "<h3> Handled by sending the tree_model parameter as True to this function if it is Random Forest or Decision Tree and False if it is Linear Model </h3>\n",
    "<h3> If it is neither Linear_Model or Tree, then send nothing for that parameter value and it will still work </h3>\n",
    "<p> Note: Probably have to include another parameter to support Polynomial Regression Models </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1. For Random Forest and Decision Tree </h3>\n",
    "\n",
    "    Prints important features based on permutation_importance() function result\n",
    "    And only displays those features whose importance is atleast twice more than the standard deviation of the \n",
    "    entire importance array\n",
    "<h3> <a href=\"https://scikit-learn.org/stable/modules/permutation_importance.html\"> Permutation Importance </a> </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 2. For Linear_Models (Elasticnet, Bayesian Ridge, Lasso, Ridge, etc.) </h3>\n",
    "\n",
    "    Prints p-values of all features (can be filtered down later)\n",
    "    I used significance level as 5%, so if p-value < 0.05, only then would a feature be considered as important\n",
    "<h3> <a href=\"https://statisticsbyjim.com/regression/interpret-coefficients-p-values-regression/\"> Reference </a> </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> A change that was made later on to the training function below is the Sequential Train-Test split which is quite an important change and its effects will not be visible on most of the models trained here because they were trained using the old Randomized Train-Test Split </h3>\n",
    "<p> Here starting 70% of the rows are considered for training and remaining 30% is left for testing so as to avoid data leakage and make models more practical </p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Works for both RandomizedSearchCV() object and GridSearchCV() object\n",
    "def model_training_hyperparam_per_atm(atm_name, new_data, categorical_features_list, \n",
    "                                      param_cv_obj, tree_model='Invalid'):\n",
    "    \n",
    "    curr_atm_data = new_data[new_data['ATM Name'] == atm_name].drop('ATM Name', axis=1)\n",
    "    numeric_curr_atm_data = convert_categorical_to_numerical(curr_atm_data, categorical_features_list)\n",
    "    \n",
    "    # Dropping Correlated Holiday Sequence columns (only temporarily used)\n",
    "    # numeric_curr_atm_data.drop(['Holiday Sequence_HWW','Holiday Sequence_WHH','Holiday Sequence_HHW'], axis=1,inplace=True)\n",
    "    \n",
    "    # Not using 2016 and 2017 data so that testing can be done better\n",
    "    # numeric_curr_atm_data = numeric_curr_atm_data[numeric_curr_atm_data.apply(lambda x: x['Year_2016'] != 1 and x['Year_2017'] != 1, axis=1)]\n",
    "    \n",
    "    X = numeric_curr_atm_data.drop('Total amount Withdrawn', axis=1)\n",
    "    y = numeric_curr_atm_data['Total amount Withdrawn']\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "        \n",
    "    # Splitting data sequentially as 70% train and 30% test\n",
    "    train_size = int(0.7 * len(X))\n",
    "    X_train = X[:train_size]\n",
    "    y_train = y[:train_size]\n",
    "    X_test = X[train_size:]\n",
    "    y_test = y[train_size:]\n",
    "    \n",
    "    param_cv_obj.fit(X_train, y_train)\n",
    "    print(\"Best Parameters:\\n\", param_cv_obj.best_params_)\n",
    "    print(\"\\nBest CV RMSE:\", -param_cv_obj.best_score_)\n",
    "    \n",
    "    if 'mean_train_score' in param_cv_obj.cv_results_:\n",
    "        # nanmean() is used here instead of mean() because for DecisionTree the mean_train_score actually contains nan\n",
    "        # for some reason, so nanmean() ignores it while computing mean\n",
    "        print(\"Best Training RMSE:\", -np.nanmean(param_cv_obj.cv_results_['mean_train_score']))\n",
    "    \n",
    "    best_model = param_cv_obj.best_estimator_\n",
    "    model_predictions = best_model.predict(X_test)\n",
    "    model_rmse = np.sqrt(mean_squared_error(y_test, model_predictions))\n",
    "    model_mape = mean_absolute_percentage_error(y_test, model_predictions)\n",
    "    \n",
    "    print(\"Test RMSE:\", model_rmse)\n",
    "    print(\"Test MAPE:\", model_mape)\n",
    "    \n",
    "    column_names = X_train.columns\n",
    "    \n",
    "    if tree_model == False:\n",
    "        # p_val_array[1:] because 0-th index is reserved for intercept p-val which is not required for us\n",
    "        try:\n",
    "            p_val_array = stats.coef_pval(best_model, X_train, y_train)\n",
    "            [print(\"{} : {}\".format(x, y)) for x, y in zip(column_names, p_val_array[1:]) if y < 0.05]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    elif tree_model == True:\n",
    "        r = permutation_importance(best_model, X_test, y_test, n_repeats=30, random_state=0)\n",
    "        for i in r.importances_mean.argsort()[::-1]:\n",
    "            if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "                print(f\"{column_names[i]:<8}: \"\n",
    "                      f\"{r.importances_mean[i]:.3f}\"\n",
    "                      f\" +/- {r.importances_std[i]:.3f}\")\n",
    "        \n",
    "    print(\"------------------------------------------------------------------------\\n\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Running Random Forest after dropping all correlated weather features </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For Big Street ATM\n",
      "Using Train-Test Split\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 14.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'n_estimators': 600, 'min_samples_split': 22, 'min_samples_leaf': 1}\n",
      "\n",
      "Best CV RMSE: 109314.54789524553\n",
      "Best Training RMSE: 93625.1221674905\n",
      "Test RMSE: 115701.71721069398\n",
      "Year_2015: 0.498 +/- 0.027\n",
      "Year_2016: 0.480 +/- 0.032\n",
      "Year_2014: 0.426 +/- 0.036\n",
      "Year_2013: 0.269 +/- 0.022\n",
      "Year_2017: 0.191 +/- 0.021\n",
      "Year_2012: 0.106 +/- 0.013\n",
      "Month_11: 0.036 +/- 0.010\n",
      "Day_11  : 0.019 +/- 0.007\n",
      "Day_12  : 0.016 +/- 0.005\n",
      "Day_3   : 0.007 +/- 0.004\n",
      "Day_10  : 0.007 +/- 0.002\n",
      "Month_5 : 0.004 +/- 0.002\n",
      "Day_7   : 0.002 +/- 0.001\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Mount Road ATM\n",
      "Using Train-Test Split\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 12.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'n_estimators': 1400, 'min_samples_split': 25, 'min_samples_leaf': 1}\n",
      "\n",
      "Best CV RMSE: 182399.0352807436\n",
      "Best Training RMSE: 157830.31245451362\n",
      "Test RMSE: 184320.87860949992\n",
      "Year_2016: 0.433 +/- 0.037\n",
      "Year_2017: 0.254 +/- 0.035\n",
      "Holiday Sequence_HHW: 0.054 +/- 0.014\n",
      "Weekday_SUNDAY: 0.047 +/- 0.010\n",
      "Year_2014: 0.039 +/- 0.008\n",
      "Day_4   : 0.032 +/- 0.007\n",
      "moon_illumination: 0.025 +/- 0.006\n",
      "Year_2015: 0.024 +/- 0.004\n",
      "Day_10  : 0.020 +/- 0.008\n",
      "FeelsLikeC: 0.019 +/- 0.005\n",
      "Festival Religion_NH: 0.018 +/- 0.008\n",
      "Year_2012: 0.014 +/- 0.006\n",
      "Day_7   : 0.007 +/- 0.003\n",
      "Day_12  : 0.007 +/- 0.002\n",
      "Month_7 : 0.007 +/- 0.001\n",
      "Day_9   : 0.006 +/- 0.002\n",
      "Day_8   : 0.005 +/- 0.002\n",
      "Holiday Sequence_WHH: 0.004 +/- 0.001\n",
      "Day_30  : 0.002 +/- 0.001\n",
      "Year_2013: 0.002 +/- 0.001\n",
      "Holiday Sequence_WWW: 0.001 +/- 0.001\n",
      "uvIndex_5: 0.001 +/- 0.000\n",
      "Festival Religion_N: 0.000 +/- 0.000\n",
      "Festival Religion_M: 0.000 +/- 0.000\n",
      "uvIndex_8: 0.000 +/- 0.000\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Airport ATM\n",
      "Using Train-Test Split\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 15.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'n_estimators': 800, 'min_samples_split': 32, 'min_samples_leaf': 1}\n",
      "\n",
      "Best CV RMSE: 172611.0344381951\n",
      "Best Training RMSE: 146700.3384219197\n",
      "Test RMSE: 166132.26169151615\n",
      "Year_2016: 0.270 +/- 0.037\n",
      "Year_2017: 0.119 +/- 0.021\n",
      "Year_2013: 0.054 +/- 0.011\n",
      "Weekday_SATURDAY: 0.053 +/- 0.009\n",
      "Year_2012: 0.035 +/- 0.005\n",
      "Day_8   : 0.029 +/- 0.014\n",
      "moon_illumination: 0.028 +/- 0.010\n",
      "Month_9 : 0.017 +/- 0.006\n",
      "humidity: 0.013 +/- 0.006\n",
      "FeelsLikeC: 0.012 +/- 0.006\n",
      "Year_2014: 0.008 +/- 0.002\n",
      "Holiday Sequence_WHH: 0.007 +/- 0.004\n",
      "Year_2015: 0.007 +/- 0.003\n",
      "cloudcover: 0.007 +/- 0.003\n",
      "Day_11  : 0.005 +/- 0.001\n",
      "Day_27  : 0.001 +/- 0.001\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For KK Nagar ATM\n",
      "Using Train-Test Split\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 14.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'n_estimators': 1200, 'min_samples_split': 35, 'min_samples_leaf': 3}\n",
      "\n",
      "Best CV RMSE: 308562.9889931216\n",
      "Best Training RMSE: 276377.2028885728\n",
      "Test RMSE: 294645.7856796624\n",
      "Year_2014: 0.373 +/- 0.035\n",
      "Year_2013: 0.352 +/- 0.044\n",
      "Year_2012: 0.238 +/- 0.029\n",
      "Weekday_SUNDAY: 0.238 +/- 0.038\n",
      "moon_illumination: 0.032 +/- 0.007\n",
      "Year_2015: 0.026 +/- 0.005\n",
      "Year_2017: 0.024 +/- 0.006\n",
      "Year_2016: 0.023 +/- 0.005\n",
      "Day_11  : 0.016 +/- 0.007\n",
      "Festival Religion_NH: 0.015 +/- 0.003\n",
      "Day_6   : 0.014 +/- 0.003\n",
      "FeelsLikeC: 0.013 +/- 0.004\n",
      "Day_12  : 0.013 +/- 0.004\n",
      "Day_2   : 0.008 +/- 0.002\n",
      "Day_31  : 0.003 +/- 0.001\n",
      "Day_7   : 0.002 +/- 0.001\n",
      "Month_4 : 0.001 +/- 0.001\n",
      "Month_7 : 0.001 +/- 0.001\n",
      "Holiday Sequence_HWW: 0.001 +/- 0.001\n",
      "Day_29  : 0.001 +/- 0.000\n",
      "Day_30  : 0.000 +/- 0.000\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Christ College ATM\n",
      "Using Train-Test Split\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 17.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'n_estimators': 2000, 'min_samples_split': 14, 'min_samples_leaf': 2}\n",
      "\n",
      "Best CV RMSE: 212747.75622138512\n",
      "Best Training RMSE: 180204.94309515107\n",
      "Test RMSE: 208389.22232297878\n",
      "Year_2014: 0.367 +/- 0.035\n",
      "Year_2017: 0.308 +/- 0.042\n",
      "Year_2016: 0.178 +/- 0.020\n",
      "Holiday Sequence_HHW: 0.172 +/- 0.049\n",
      "Year_2013: 0.138 +/- 0.012\n",
      "Year_2015: 0.102 +/- 0.012\n",
      "moon_illumination: 0.081 +/- 0.019\n",
      "Year_2012: 0.024 +/- 0.004\n",
      "Festival Religion_NH: 0.023 +/- 0.007\n",
      "Day_10  : 0.018 +/- 0.003\n",
      "Day_8   : 0.018 +/- 0.004\n",
      "Day_9   : 0.010 +/- 0.004\n",
      "Day_2   : 0.007 +/- 0.003\n",
      "Day_12  : 0.005 +/- 0.002\n",
      "Day_11  : 0.005 +/- 0.002\n",
      "Day_14  : 0.000 +/- 0.000\n",
      "Day_25  : 0.000 +/- 0.000\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rforest_param_grid = {'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)], \n",
    "                      'min_samples_split': list(range(1,40)), 'min_samples_leaf': list(range(1,25))}\n",
    "                      \n",
    "random_cv_rforest = RandomizedSearchCV(RandomForestRegressor(), rforest_param_grid, n_iter=25, n_jobs=-1, \n",
    "                                      scoring='neg_root_mean_squared_error', verbose=2, cv=10, return_train_score=True)\n",
    "\n",
    "\n",
    "for atm_name in atm_names:\n",
    "    print(\"\\nFor\", atm_name)\n",
    "    model_training_hyperparam_per_atm(atm_name, combined_data, categorical_features_list, \n",
    "                                      random_cv_rforest, test_split=True, tree_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> I would say this is quite overfitting behaviour, which is why the conclusion was to just use the Precipitation column </h3>\n",
    "<b> <p> Note: moon_illumination and FeelsLikeC are two columns that showed up quite consistently on all ATMs except Big Street, so that is something to consider for the future, once we are back to considering other ATMs as well </p> <b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"rainfall-status\"></a>\n",
    "# Converting Precipitation to Rain Status based on the conditions described in next cell\n",
    "<h4> Source: Wikipedia </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Light rain — when the precipitation rate is < 2.5 mm (0.098 in) per hour\n",
    "    Moderate rain — when the precipitation rate is between 2.5 mm (0.098 in) - 7.6 mm (0.30 in) or 10 mm (0.39 in) per hour\n",
    "    Heavy rain — when the precipitation rate is > 7.6 mm (0.30 in) per hour or between 10 mm (0.39 in) and 50 mm (2.0 in) per hour\n",
    "    Violent rain — when the precipitation rate is > 50 mm (2.0 in) per hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rainfall_status_check(value):\n",
    "    if value == 0:\n",
    "        return \"No Rain\"\n",
    "    elif value < 2.5:\n",
    "        return \"Light Rain\"\n",
    "    elif value <= 7.6:\n",
    "        return \"Moderate Rain\"\n",
    "    elif value <= 50:\n",
    "        return \"Heavy Rain\"\n",
    "    else:\n",
    "        return \"Violent Rain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_csv('../data/aggregated_atm_data_with_weather_data.csv ')\n",
    "combined_data.drop(['No Of Withdrawals', 'No Of XYZ Card Withdrawals', 'No Of Other Card Withdrawals', \n",
    "                    'Amount withdrawn XYZ Card', 'Amount withdrawn Other Card',\n",
    "                    'maxtempC', 'HeatIndexC', 'WindChillC', 'tempC', 'WindGustKmph', 'DewPointC'], axis=1, inplace=True)\n",
    "\n",
    "combined_data['Transaction Date'] = pd.to_datetime(combined_data['Transaction Date'])\n",
    "combined_data['Day'] = combined_data['Transaction Date'].dt.day\n",
    "combined_data['Month'] = combined_data['Transaction Date'].dt.month\n",
    "combined_data['Year'] = combined_data['Transaction Date'].dt.year\n",
    "combined_data.drop('Transaction Date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.drop(['moonrise', 'moonset', 'sunrise', 'sunset', 'winddirDegree', \n",
    "                    'mintempC', 'uvIndex', 'sunHour', 'FeelsLikeC', 'cloudcover',\n",
    "                   'humidity', 'pressure', 'visibility', 'winddirDegree', \n",
    "                    'windspeedKmph', 'moon_illumination'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data['Rainfall_Status'] = combined_data['precipMM'].apply(rainfall_status_check)\n",
    "combined_data.drop('precipMM', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"rainfall-models\"></a>\n",
    "# Running some models and noting observations wrt Rainfall Status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For Big Street ATM\n",
      "Using Train-Test Split\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 18.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'n_estimators': 1000, 'min_samples_split': 39, 'min_samples_leaf': 2}\n",
      "\n",
      "Best CV RMSE: 112816.58935483606\n",
      "Best Training RMSE: 106672.16244204574\n",
      "Test RMSE: 107623.11851981132\n",
      "Year_2016: 0.558 +/- 0.039\n",
      "Year_2015: 0.524 +/- 0.041\n",
      "Year_2014: 0.443 +/- 0.034\n",
      "Year_2013: 0.297 +/- 0.019\n",
      "Year_2017: 0.246 +/- 0.025\n",
      "Year_2012: 0.133 +/- 0.017\n",
      "Month_11: 0.053 +/- 0.018\n",
      "Day_6   : 0.035 +/- 0.006\n",
      "Day_11  : 0.029 +/- 0.006\n",
      "Month_12: 0.017 +/- 0.004\n",
      "Day_12  : 0.015 +/- 0.005\n",
      "Month_7 : 0.012 +/- 0.003\n",
      "Day_8   : 0.008 +/- 0.003\n",
      "Month_10: 0.005 +/- 0.002\n",
      "Month_9 : 0.005 +/- 0.002\n",
      "Day_15  : 0.002 +/- 0.001\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Mount Road ATM\n",
      "Using Train-Test Split\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 10.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'n_estimators': 200, 'min_samples_split': 3, 'min_samples_leaf': 2}\n",
      "\n",
      "Best CV RMSE: 181249.0350285287\n",
      "Best Training RMSE: 174702.06969810874\n",
      "Test RMSE: 188249.73294382586\n",
      "Year_2017: 0.266 +/- 0.038\n",
      "Year_2016: 0.254 +/- 0.032\n",
      "Holiday Sequence_HHW: 0.066 +/- 0.016\n",
      "Weekday_SUNDAY: 0.065 +/- 0.015\n",
      "Year_2014: 0.042 +/- 0.011\n",
      "Day_10  : 0.039 +/- 0.009\n",
      "Festival Religion_NH: 0.036 +/- 0.008\n",
      "Year_2015: 0.035 +/- 0.012\n",
      "Day_4   : 0.031 +/- 0.010\n",
      "Year_2012: 0.022 +/- 0.006\n",
      "Day_11  : 0.021 +/- 0.007\n",
      "Year_2013: 0.018 +/- 0.004\n",
      "Month_11: 0.018 +/- 0.008\n",
      "Day_6   : 0.013 +/- 0.003\n",
      "Day_12  : 0.011 +/- 0.004\n",
      "Day_8   : 0.008 +/- 0.003\n",
      "Day_3   : 0.008 +/- 0.003\n",
      "Day_31  : 0.006 +/- 0.003\n",
      "Day_25  : 0.004 +/- 0.002\n",
      "Holiday Sequence_WHW: 0.002 +/- 0.001\n",
      "Day_14  : 0.001 +/- 0.000\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Airport ATM\n",
      "Using Train-Test Split\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 13.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'n_estimators': 1200, 'min_samples_split': 38, 'min_samples_leaf': 1}\n",
      "\n",
      "Best CV RMSE: 173230.61922801757\n",
      "Best Training RMSE: 162254.069726282\n",
      "Test RMSE: 160181.18813325328\n",
      "Year_2016: 0.263 +/- 0.043\n",
      "Year_2017: 0.168 +/- 0.019\n",
      "Day_8   : 0.073 +/- 0.010\n",
      "Weekday_SATURDAY: 0.054 +/- 0.010\n",
      "Year_2013: 0.051 +/- 0.012\n",
      "Holiday Sequence_WHH: 0.050 +/- 0.009\n",
      "Year_2012: 0.049 +/- 0.006\n",
      "Year_2014: 0.025 +/- 0.009\n",
      "Day_4   : 0.023 +/- 0.007\n",
      "Holiday Sequence_HHW: 0.019 +/- 0.005\n",
      "Day_10  : 0.018 +/- 0.003\n",
      "Month_11: 0.017 +/- 0.007\n",
      "Day_7   : 0.016 +/- 0.006\n",
      "Year_2015: 0.014 +/- 0.003\n",
      "Weekday_SUNDAY: 0.013 +/- 0.006\n",
      "Day_3   : 0.012 +/- 0.004\n",
      "Day_9   : 0.011 +/- 0.004\n",
      "Day_5   : 0.009 +/- 0.003\n",
      "Day_11  : 0.008 +/- 0.002\n",
      "Day_2   : 0.005 +/- 0.002\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For KK Nagar ATM\n",
      "Using Train-Test Split\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 13.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'n_estimators': 1400, 'min_samples_split': 10, 'min_samples_leaf': 3}\n",
      "\n",
      "Best CV RMSE: 302002.80820304784\n",
      "Best Training RMSE: 298619.72650276637\n",
      "Test RMSE: 303636.6591586358\n",
      "Year_2014: 0.391 +/- 0.045\n",
      "Year_2013: 0.234 +/- 0.033\n",
      "Weekday_SUNDAY: 0.219 +/- 0.035\n",
      "Year_2012: 0.202 +/- 0.026\n",
      "Year_2016: 0.055 +/- 0.005\n",
      "Year_2017: 0.053 +/- 0.009\n",
      "Year_2015: 0.037 +/- 0.007\n",
      "Day_11  : 0.030 +/- 0.010\n",
      "Day_6   : 0.025 +/- 0.007\n",
      "Day_12  : 0.020 +/- 0.005\n",
      "Month_12: 0.020 +/- 0.009\n",
      "Day_4   : 0.020 +/- 0.004\n",
      "Month_11: 0.019 +/- 0.005\n",
      "Rainfall_Status_No Rain: 0.015 +/- 0.005\n",
      "Day_2   : 0.015 +/- 0.004\n",
      "Festival Religion_NH: 0.015 +/- 0.004\n",
      "Month_9 : 0.010 +/- 0.002\n",
      "Day_5   : 0.009 +/- 0.002\n",
      "Day_7   : 0.005 +/- 0.002\n",
      "Festival Religion_H: 0.004 +/- 0.001\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Christ College ATM\n",
      "Using Train-Test Split\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 18.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'n_estimators': 2000, 'min_samples_split': 38, 'min_samples_leaf': 1}\n",
      "\n",
      "Best CV RMSE: 211994.60822291044\n",
      "Best Training RMSE: 205249.91545336385\n",
      "Test RMSE: 205222.78361222986\n",
      "Year_2017: 0.391 +/- 0.032\n",
      "Year_2014: 0.280 +/- 0.030\n",
      "Year_2016: 0.230 +/- 0.022\n",
      "Year_2015: 0.116 +/- 0.011\n",
      "Year_2013: 0.087 +/- 0.010\n",
      "Weekday_SUNDAY: 0.064 +/- 0.019\n",
      "Day_9   : 0.053 +/- 0.012\n",
      "Holiday Sequence_HHW: 0.053 +/- 0.018\n",
      "Day_10  : 0.046 +/- 0.011\n",
      "Festival Religion_NH: 0.046 +/- 0.008\n",
      "Year_2012: 0.032 +/- 0.004\n",
      "Day_3   : 0.031 +/- 0.010\n",
      "Day_12  : 0.020 +/- 0.008\n",
      "Day_7   : 0.019 +/- 0.004\n",
      "Day_6   : 0.016 +/- 0.006\n",
      "Day_11  : 0.013 +/- 0.004\n",
      "Month_5 : 0.013 +/- 0.004\n",
      "Day_5   : 0.012 +/- 0.004\n",
      "Month_12: 0.009 +/- 0.004\n",
      "Day_24  : 0.006 +/- 0.002\n",
      "Rainfall_Status_Light Rain: 0.003 +/- 0.001\n",
      "Day_25  : 0.001 +/- 0.000\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rforest_param_grid = {'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)], \n",
    "                      'min_samples_split': list(range(1,40)), 'min_samples_leaf': list(range(1,25))}\n",
    "                      \n",
    "random_cv_rforest = RandomizedSearchCV(RandomForestRegressor(), rforest_param_grid, n_iter=25, n_jobs=-1, \n",
    "                                      scoring='neg_root_mean_squared_error', verbose=2, cv=10, return_train_score=True)\n",
    "\n",
    "\n",
    "for atm_name in atm_names:\n",
    "    print(\"\\nFor\", atm_name)\n",
    "    model_training_hyperparam_per_atm(atm_name, combined_data, categorical_features_list, \n",
    "                                      random_cv_rforest, tree_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Observations </h3>\n",
    "<p> Rainfall_Status_No Rain was considered important for KK Nagar and Light Rain was considered important for Christ College </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For Big Street ATM\n",
      "Using Train-Test Split\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:   35.3s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   36.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 59.636233165946365}\n",
      "\n",
      "Best CV RMSE: 112630.17385915112\n",
      "Best Training RMSE: 108532.55394962615\n",
      "Test RMSE: 122163.08665723335\n",
      "Weekday_MONDAY : 0.010215504696719169\n",
      "Weekday_SATURDAY : 0.00866704255214934\n",
      "Weekday_THURSDAY : 0.00011404167149864364\n",
      "Weekday_TUESDAY : 1.940198419014827e-05\n",
      "Weekday_WEDNESDAY : 0.00037055606897440363\n",
      "Festival Religion_N : 0.04897152560495854\n",
      "Holiday Sequence_HHW : 0.02624602938471088\n",
      "Holiday Sequence_WHW : 0.005615772500587424\n",
      "Month_10 : 0.00888268840845341\n",
      "Month_12 : 0.001875861535828749\n",
      "Day_6 : 0.00018887944996959227\n",
      "Day_8 : 0.00040569757736319545\n",
      "Day_9 : 9.232053499452775e-08\n",
      "Day_11 : 1.3372975548042731e-05\n",
      "Day_12 : 3.777866325926915e-05\n",
      "Day_17 : 0.023746417044392176\n",
      "Day_19 : 0.03697907225608166\n",
      "Day_22 : 0.01752059621659985\n",
      "Day_23 : 0.005602571784383947\n",
      "Day_24 : 0.0005476836561728593\n",
      "Day_25 : 0.030891116407624875\n",
      "Day_27 : 0.008492612562490676\n",
      "Day_31 : 0.01259509885411969\n",
      "Year_2012 : 0.0\n",
      "Year_2013 : 0.0\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 0.0\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 0.0\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Mount Road ATM\n",
      "Using Train-Test Split\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:   44.0s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   46.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 25.595479226995334}\n",
      "\n",
      "Best CV RMSE: 180412.67859863336\n",
      "Best Training RMSE: 173753.3751367989\n",
      "Test RMSE: 171331.6212584216\n",
      "Weekday_SATURDAY : 6.861982093653296e-09\n",
      "Weekday_THURSDAY : 0.01626872430344206\n",
      "Weekday_TUESDAY : 0.027708424691027966\n",
      "Weekday_WEDNESDAY : 0.009905803996809848\n",
      "Working Day_W : 0.04451337629502805\n",
      "Month_2 : 0.00260053840122354\n",
      "Month_3 : 0.0037890498101864623\n",
      "Month_4 : 6.0621888575473903e-05\n",
      "Month_5 : 1.6210051967391337e-08\n",
      "Month_6 : 2.2990720123239328e-06\n",
      "Month_7 : 0.0002438769287840259\n",
      "Month_8 : 0.00025151312256777025\n",
      "Month_9 : 0.00505344489322157\n",
      "Month_10 : 0.0011136481526341502\n",
      "Month_11 : 0.0035270907082214364\n",
      "Day_5 : 0.0010346265960590184\n",
      "Day_6 : 0.005011191149993266\n",
      "Day_8 : 0.03194955657413834\n",
      "Day_10 : 0.018292765136263434\n",
      "Day_12 : 0.03662699593646668\n",
      "Day_13 : 6.267586449837381e-11\n",
      "Day_14 : 1.2034262475424384e-09\n",
      "Day_15 : 2.850608638027552e-12\n",
      "Day_16 : 1.1457501614131615e-13\n",
      "Day_17 : 4.083636317986361e-09\n",
      "Day_18 : 3.842481888227667e-12\n",
      "Day_19 : 1.872718424777986e-09\n",
      "Day_20 : 6.292122378681597e-11\n",
      "Day_21 : 3.45707906745929e-11\n",
      "Day_22 : 2.375877272697835e-14\n",
      "Day_23 : 0.0\n",
      "Day_24 : 1.0474598965970472e-10\n",
      "Day_25 : 4.440892098500626e-16\n",
      "Day_26 : 2.7422508708241367e-13\n",
      "Day_27 : 7.031013549152476e-10\n",
      "Day_28 : 4.440892098500626e-16\n",
      "Day_29 : 1.1524114995609125e-13\n",
      "Day_30 : 1.8351313403774938e-05\n",
      "Year_2012 : 1.7319479184152442e-14\n",
      "Year_2013 : 0.03892718203484513\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 5.3516302500611346e-11\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 0.0\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Airport ATM\n",
      "Using Train-Test Split\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   31.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 14.563484775012444}\n",
      "\n",
      "Best CV RMSE: 175951.8910828563\n",
      "Best Training RMSE: 169021.99819178137\n",
      "Test RMSE: 166343.46801016547\n",
      "Weekday_MONDAY : 0.045546383108879596\n",
      "Weekday_SATURDAY : 1.7042277367096403e-08\n",
      "Weekday_THURSDAY : 0.013242663554440925\n",
      "Weekday_WEDNESDAY : 0.0004475997526185438\n",
      "Festival Religion_NH : 0.006838182166031936\n",
      "Holiday Sequence_HHW : 7.52455520516282e-05\n",
      "Holiday Sequence_WHH : 1.897866365041523e-05\n",
      "Holiday Sequence_WHW : 0.00037425477881947167\n",
      "Holiday Sequence_WWH : 0.009387103742149572\n",
      "Holiday Sequence_WWW : 0.019483412363266117\n",
      "Month_3 : 0.008398183789082525\n",
      "Month_11 : 0.020965934184914436\n",
      "Month_12 : 0.015552466402270593\n",
      "Day_6 : 0.011407730938728378\n",
      "Day_8 : 0.0011028712008140928\n",
      "Day_13 : 0.025161644412145412\n",
      "Day_15 : 0.020782808352020066\n",
      "Day_16 : 0.017516290760142272\n",
      "Day_17 : 0.00018249298877104358\n",
      "Day_18 : 0.010849241854109293\n",
      "Day_19 : 0.0019369398888868794\n",
      "Day_21 : 0.0019799150249175668\n",
      "Day_22 : 0.00010296631204975704\n",
      "Day_23 : 0.005881423903218774\n",
      "Day_24 : 0.00010800323916515531\n",
      "Day_25 : 1.5633537846504453e-06\n",
      "Day_26 : 0.0034993636875946255\n",
      "Day_27 : 0.009176518242349774\n",
      "Day_28 : 0.008258221664590115\n",
      "Day_29 : 0.005967104151840097\n",
      "Year_2012 : 5.5067062021407764e-14\n",
      "Year_2013 : 0.0\n",
      "Year_2014 : 1.0315145442252316e-06\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 1.318944953254686e-13\n",
      "Rainfall_Status_No Rain : 0.012230925472463738\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For KK Nagar ATM\n",
      "Using Train-Test Split\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:   44.8s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   49.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 244.205309454865}\n",
      "\n",
      "Best CV RMSE: 330303.86291344377\n",
      "Best Training RMSE: 317230.2062928679\n",
      "Test RMSE: 282049.6082596437\n",
      "Weekday_SUNDAY : 0.0014201825171547\n",
      "Weekday_THURSDAY : 0.024749735454979715\n",
      "Weekday_WEDNESDAY : 4.705073940258764e-05\n",
      "Festival Religion_H : 0.013258934831487101\n",
      "Month_7 : 0.00014594922622523931\n",
      "Month_8 : 0.02179615822324954\n",
      "Month_9 : 0.0010420858806974298\n",
      "Month_11 : 1.616243123336858e-06\n",
      "Month_12 : 3.0718526485618014e-05\n",
      "Day_6 : 9.122397664085291e-05\n",
      "Day_10 : 0.03487651614282283\n",
      "Day_13 : 0.002930709741018056\n",
      "Day_14 : 0.0041231308111380205\n",
      "Day_15 : 0.035304931734213785\n",
      "Day_16 : 0.0009793143637746304\n",
      "Day_17 : 0.005155359408414828\n",
      "Day_18 : 1.1483229366504588e-05\n",
      "Day_19 : 0.00027242556154938313\n",
      "Day_20 : 0.003241598634743159\n",
      "Day_21 : 0.001666795118229203\n",
      "Day_22 : 2.34915862504792e-05\n",
      "Day_23 : 1.7508529788212712e-06\n",
      "Day_24 : 9.022278908421555e-07\n",
      "Day_25 : 0.0009004944287178684\n",
      "Day_26 : 0.04666362815751657\n",
      "Day_27 : 0.00023558374792176373\n",
      "Day_28 : 0.03306052051749098\n",
      "Day_29 : 0.02117912087926266\n",
      "Year_2012 : 0.0\n",
      "Year_2013 : 0.0\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 0.0\n",
      "Year_2016 : 1.572832974972016e-10\n",
      "Year_2017 : 0.0\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Christ College ATM\n",
      "Using Train-Test Split\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  1.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 323.745754281764}\n",
      "\n",
      "Best CV RMSE: 205793.70928000356\n",
      "Best Training RMSE: 197960.62402210344\n",
      "Test RMSE: 216009.7685643173\n",
      "Weekday_SATURDAY : 6.634668370253394e-10\n",
      "Working Day_W : 0.002645075414979159\n",
      "Month_11 : 0.026469398118280196\n",
      "Month_12 : 7.5735798754639205e-06\n",
      "Day_2 : 0.000444758338861595\n",
      "Day_3 : 6.255280767164528e-05\n",
      "Day_7 : 2.937409574244043e-05\n",
      "Day_9 : 2.2575059599461156e-09\n",
      "Day_10 : 1.8244017452317962e-07\n",
      "Day_11 : 0.026153433888923994\n",
      "Day_12 : 0.01038255225560536\n",
      "Day_16 : 0.026274080049645265\n",
      "Day_18 : 0.0019509079065815893\n",
      "Day_22 : 0.018415620909579822\n",
      "Day_23 : 0.0018193416491383285\n",
      "Day_24 : 0.004183484485745348\n",
      "Day_25 : 0.002587965304453821\n",
      "Day_26 : 0.000989874257422585\n",
      "Day_28 : 0.009934274594911141\n",
      "Day_29 : 0.028373797913520127\n",
      "Year_2012 : 0.0\n",
      "Year_2013 : 0.0\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 0.0\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 0.0\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.2min finished\n"
     ]
    }
   ],
   "source": [
    "lasso_param_grid = {'alpha':np.logspace(-3, 3, num=50)}\n",
    "grid_cv_lasso = GridSearchCV(Lasso(max_iter=2000), lasso_param_grid, verbose=2, n_jobs=-1, \n",
    "                             scoring='neg_root_mean_squared_error', cv=10, return_train_score=True)\n",
    "\n",
    "for atm_name in atm_names:\n",
    "    print(\"\\nFor\", atm_name)\n",
    "    model_training_hyperparam_per_atm(atm_name, combined_data, categorical_features_list, \n",
    "                                      grid_cv_lasso, tree_model=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Observations </h3>\n",
    "<p> No Rain feature was important for Airport ATM </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elasticnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For Big Street ATM\n",
      "Using Train-Test Split\n",
      "Fitting 10 folds for each of 350 candidates, totalling 3500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   42.5s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1029 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1502 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2562 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3500 out of 3500 | elapsed:  4.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 184.20699693267164, 'l1_ratio': 1}\n",
      "\n",
      "Best CV RMSE: 117120.81659016541\n",
      "Best Training RMSE: 133002.48953436076\n",
      "Test RMSE: 105469.894994206\n",
      "Month_10 : 0.036928669650658996\n",
      "Month_12 : 0.0012397494194062997\n",
      "Day_6 : 6.063782082166291e-05\n",
      "Day_8 : 0.007682762774576579\n",
      "Day_9 : 8.186418514632976e-06\n",
      "Day_10 : 0.039221732889387795\n",
      "Day_11 : 0.003945024118934715\n",
      "Day_12 : 0.0005443593273135594\n",
      "Day_23 : 0.02233437663137816\n",
      "Day_24 : 0.004304674976187917\n",
      "Day_31 : 0.030517573858798164\n",
      "Year_2012 : 0.0\n",
      "Year_2013 : 0.0\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 0.0\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 0.0\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Mount Road ATM\n",
      "Using Train-Test Split\n",
      "Fitting 10 folds for each of 350 candidates, totalling 3500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:   53.6s\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1033 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1740 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3436 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3500 out of 3500 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 0.0013257113655901094, 'l1_ratio': 0.9}\n",
      "\n",
      "Best CV RMSE: 178362.6017093229\n",
      "Best Training RMSE: 206656.53595452415\n",
      "Test RMSE: 178703.98665589714\n",
      "Weekday_MONDAY : 0.023517739143683825\n",
      "Weekday_SATURDAY : 5.308377293289368e-09\n",
      "Weekday_THURSDAY : 0.014185025175857291\n",
      "Weekday_WEDNESDAY : 0.016846711782082302\n",
      "Holiday Sequence_WHH : 0.0020911725520949\n",
      "Holiday Sequence_WHW : 0.017210937990383757\n",
      "Month_2 : 0.0022205758245590346\n",
      "Month_3 : 0.00023253933874878285\n",
      "Month_4 : 0.0008901308548059372\n",
      "Month_5 : 5.167542838080408e-09\n",
      "Month_6 : 4.763015653441727e-06\n",
      "Month_7 : 3.247625946656285e-05\n",
      "Month_8 : 1.1746157464909146e-05\n",
      "Month_9 : 0.012041096912965843\n",
      "Month_10 : 2.5853297436873035e-05\n",
      "Month_11 : 0.006620787035289899\n",
      "Day_5 : 0.0017642718581800665\n",
      "Day_6 : 0.013956350302795295\n",
      "Day_10 : 0.01755526843073829\n",
      "Day_12 : 0.041075055423744455\n",
      "Day_13 : 2.7588820117330215e-11\n",
      "Day_14 : 5.37492272911777e-10\n",
      "Day_15 : 1.7763568394002505e-15\n",
      "Day_16 : 1.4210854715202004e-14\n",
      "Day_17 : 1.0553735663165753e-10\n",
      "Day_18 : 9.356737606935894e-12\n",
      "Day_19 : 7.459293971390224e-07\n",
      "Day_20 : 2.641367125022498e-10\n",
      "Day_21 : 6.803446694902959e-13\n",
      "Day_22 : 1.4876988529977098e-14\n",
      "Day_23 : 0.0\n",
      "Day_24 : 2.7977620220553945e-14\n",
      "Day_25 : 1.3367085216486885e-13\n",
      "Day_26 : 5.659916979539048e-13\n",
      "Day_27 : 1.7676304864266967e-11\n",
      "Day_28 : 2.220446049250313e-16\n",
      "Day_29 : 4.440892098500626e-16\n",
      "Day_30 : 3.0269134765337213e-06\n",
      "Year_2012 : 1.1013412404281553e-13\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 3.186303416669034e-07\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 0.0\n",
      "Rainfall_Status_No Rain : 0.010470636601475514\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Airport ATM\n",
      "Using Train-Test Split\n",
      "Fitting 10 folds for each of 350 candidates, totalling 3500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:   48.7s\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1134 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2316 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3500 out of 3500 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 0.016768329368110083, 'l1_ratio': 0.9}\n",
      "\n",
      "Best CV RMSE: 172219.5949347741\n",
      "Best Training RMSE: 180374.2381694476\n",
      "Test RMSE: 176507.27764668778\n",
      "Weekday_SATURDAY : 1.413662831217799e-05\n",
      "Weekday_THURSDAY : 0.010241926205528662\n",
      "Weekday_TUESDAY : 0.004985425289880441\n",
      "Weekday_WEDNESDAY : 0.00010247957732500979\n",
      "Holiday Sequence_HHW : 0.007703852267673117\n",
      "Holiday Sequence_WHH : 0.015415770799978468\n",
      "Month_3 : 0.007442817550058489\n",
      "Day_6 : 0.003403310872143628\n",
      "Day_8 : 6.556516472522311e-05\n",
      "Day_17 : 0.00115958422939344\n",
      "Day_19 : 0.010104968823720473\n",
      "Day_21 : 0.028660805001903045\n",
      "Day_22 : 0.011755105562079482\n",
      "Day_23 : 0.022335631617338203\n",
      "Day_24 : 0.0006813192698471582\n",
      "Day_25 : 0.0011981530390992035\n",
      "Day_26 : 0.00363138973528887\n",
      "Day_27 : 0.037983283239339194\n",
      "Day_28 : 0.02885079216729869\n",
      "Year_2012 : 1.1524114995609125e-13\n",
      "Year_2013 : 0.0\n",
      "Year_2014 : 8.382504845805272e-08\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 4.2521541843143495e-13\n",
      "Rainfall_Status_No Rain : 0.00958458450549693\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For KK Nagar ATM\n",
      "Using Train-Test Split\n",
      "Fitting 10 folds for each of 350 candidates, totalling 3500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:   53.6s\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1066 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2320 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3493 out of 3500 | elapsed:  2.8min remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 3500 out of 3500 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 138.9495494373136, 'l1_ratio': 1}\n",
      "\n",
      "Best CV RMSE: 319415.9474317678\n",
      "Best Training RMSE: 358754.0167849929\n",
      "Test RMSE: 324383.60139011074\n",
      "Weekday_SATURDAY : 0.012890522351922451\n",
      "Weekday_SUNDAY : 0.0038099957239841054\n",
      "Weekday_WEDNESDAY : 8.375859983056344e-05\n",
      "Festival Religion_H : 0.0028545213871280506\n",
      "Month_7 : 0.0018267539172480696\n",
      "Month_8 : 0.03195359532316622\n",
      "Month_9 : 0.0010164530557272844\n",
      "Month_11 : 6.633620331619738e-05\n",
      "Month_12 : 9.744581634119065e-05\n",
      "Day_3 : 0.04272531297450666\n",
      "Day_6 : 5.576301683496432e-05\n",
      "Day_10 : 0.03401890548895481\n",
      "Day_13 : 0.011819678812314383\n",
      "Day_14 : 0.003532594428486968\n",
      "Day_15 : 0.007308278874826879\n",
      "Day_16 : 0.00016491392248108028\n",
      "Day_17 : 0.004668216960773908\n",
      "Day_18 : 4.307503511213895e-06\n",
      "Day_19 : 0.0011511144317895017\n",
      "Day_20 : 5.537431835356266e-05\n",
      "Day_21 : 0.00010409627972784996\n",
      "Day_22 : 2.8486483162337706e-05\n",
      "Day_23 : 3.1523242416398034e-07\n",
      "Day_24 : 4.8731085389164264e-08\n",
      "Day_25 : 9.493381774361431e-05\n",
      "Day_26 : 0.007617449272853349\n",
      "Day_27 : 9.924963551810606e-05\n",
      "Day_28 : 0.015060482191381563\n",
      "Day_29 : 0.01937209916905913\n",
      "Year_2012 : 0.0\n",
      "Year_2013 : 0.0\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 4.440892098500626e-16\n",
      "Year_2016 : 1.2142509220325337e-11\n",
      "Year_2017 : 0.0\n",
      "Rainfall_Status_Light Rain : 0.015672135399687148\n",
      "Rainfall_Status_Moderate Rain : 0.011558683415566762\n",
      "Rainfall_Status_No Rain : 0.012260974984403594\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Christ College ATM\n",
      "Using Train-Test Split\n",
      "Fitting 10 folds for each of 350 candidates, totalling 3500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1190 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2356 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3500 out of 3500 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 79.06043210907701, 'l1_ratio': 1}\n",
      "\n",
      "Best CV RMSE: 205758.14515699263\n",
      "Best Training RMSE: 231558.75738095987\n",
      "Test RMSE: 211465.06693700317\n",
      "Weekday_SATURDAY : 8.999485334726387e-08\n",
      "Weekday_THURSDAY : 0.007677831413104075\n",
      "Weekday_TUESDAY : 0.025859335904005576\n",
      "Weekday_WEDNESDAY : 0.002875754513126827\n",
      "Working Day_W : 0.009671643239418382\n",
      "Month_11 : 0.0036648163722450278\n",
      "Month_12 : 6.577911029204131e-07\n",
      "Day_2 : 0.016430619609968167\n",
      "Day_3 : 0.014933512790510584\n",
      "Day_7 : 0.004765475445811074\n",
      "Day_8 : 0.03435571778403501\n",
      "Day_9 : 3.807258420307491e-06\n",
      "Day_10 : 0.00014007943930849365\n",
      "Day_14 : 0.0005309250604033089\n",
      "Day_15 : 0.012113985735562993\n",
      "Day_16 : 2.8231564217717775e-05\n",
      "Day_17 : 0.0019378956512172696\n",
      "Day_18 : 3.326483555654569e-05\n",
      "Day_19 : 0.0004853547131293823\n",
      "Day_20 : 0.0008686075827897266\n",
      "Day_21 : 0.0003753987480878962\n",
      "Day_22 : 2.910020112878442e-06\n",
      "Day_23 : 5.032558543227594e-07\n",
      "Day_24 : 6.296247967441104e-10\n",
      "Day_25 : 3.2687881845738787e-07\n",
      "Day_26 : 6.610656022587591e-09\n",
      "Day_27 : 0.00038515265426242173\n",
      "Day_28 : 4.914574796011095e-06\n",
      "Day_29 : 0.00033891686714437874\n",
      "Year_2012 : 0.0\n",
      "Year_2013 : 0.0\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 0.0\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 0.0\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "elastic_param_grid = {'l1_ratio': [.1, .5, .7, .9, .95, .99, 1], 'alpha': np.logspace(-3, 3, num=50)}\n",
    "                      \n",
    "grid_cv_elastic = GridSearchCV(ElasticNet(max_iter=10000), elastic_param_grid, n_jobs=-1,\n",
    "                                       scoring='neg_root_mean_squared_error', verbose=2, cv=10, return_train_score=True)\n",
    "\n",
    "for atm_name in atm_names:\n",
    "    print(\"\\nFor\", atm_name)\n",
    "    model_training_hyperparam_per_atm(atm_name, combined_data, categorical_features_list, \n",
    "                                      grid_cv_elastic, tree_model=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Observations </h3>\n",
    "\n",
    "<p> No Rain was important for Mount Road & Airport ATMs and all Rain values were important for KK Nagar </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For Big Street ATM\n",
      "Using Train-Test Split\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 1.151395399326447}\n",
      "\n",
      "Best CV RMSE: 114681.27841416541\n",
      "Best Training RMSE: 117167.78424163599\n",
      "Test RMSE: 113786.5039892505\n",
      "Weekday_MONDAY : 0.0010166890666045703\n",
      "Weekday_SATURDAY : 0.00043965315963800933\n",
      "Weekday_SUNDAY : 0.0013304444136701399\n",
      "Weekday_THURSDAY : 5.729465487824825e-06\n",
      "Weekday_TUESDAY : 5.562616629539718e-07\n",
      "Weekday_WEDNESDAY : 2.79659781265984e-06\n",
      "Holiday Sequence_WHW : 0.011086012994069971\n",
      "Month_10 : 0.0048228635198204195\n",
      "Month_12 : 0.0007968111205745032\n",
      "Day_6 : 0.00017953352204358453\n",
      "Day_8 : 0.002326863190967643\n",
      "Day_9 : 4.539530129576974e-07\n",
      "Day_10 : 0.016556384962532977\n",
      "Day_11 : 8.420229502781318e-05\n",
      "Day_12 : 4.970215652155829e-06\n",
      "Day_17 : 0.006412498128798738\n",
      "Day_19 : 0.044728761371112036\n",
      "Day_22 : 0.03966087896066317\n",
      "Day_23 : 0.00294437737501152\n",
      "Day_24 : 0.0002364395625411575\n",
      "Day_27 : 0.026655015627748968\n",
      "Day_28 : 0.04298192809714596\n",
      "Day_31 : 0.020957185010464174\n",
      "Year_2012 : 0.0\n",
      "Year_2013 : 0.0\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 0.0\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 0.0\n",
      "Rainfall_Status_Light Rain : 0.03146539908576407\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Mount Road ATM\n",
      "Using Train-Test Split\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 0.655128556859551}\n",
      "\n",
      "Best CV RMSE: 176859.31450297261\n",
      "Best Training RMSE: 179356.8331795557\n",
      "Test RMSE: 187888.45284598155\n",
      "Weekday_SATURDAY : 2.995979297981677e-07\n",
      "Working Day_W : 0.04189957779849074\n",
      "Holiday Sequence_WHH : 0.009009594717152014\n",
      "Month_2 : 0.0004659955058994303\n",
      "Month_3 : 0.004662414412291094\n",
      "Month_4 : 2.7497785478614034e-05\n",
      "Month_5 : 6.438085176085906e-09\n",
      "Month_6 : 1.2133434748040628e-06\n",
      "Month_7 : 0.00015388153809303695\n",
      "Month_8 : 0.0002135998147247964\n",
      "Month_9 : 0.001487691520740686\n",
      "Month_10 : 0.0012933714270604302\n",
      "Month_11 : 0.008770358605602269\n",
      "Day_5 : 0.0117190576464139\n",
      "Day_10 : 8.526003625775047e-06\n",
      "Day_13 : 1.4780950492454537e-06\n",
      "Day_14 : 4.7582769147069826e-07\n",
      "Day_15 : 4.1902703529217433e-11\n",
      "Day_16 : 6.38493702354026e-11\n",
      "Day_17 : 4.4515946484580127e-10\n",
      "Day_18 : 2.1834447583302108e-09\n",
      "Day_19 : 5.049694631331647e-07\n",
      "Day_20 : 3.94006867288077e-06\n",
      "Day_21 : 1.9253287852905032e-09\n",
      "Day_22 : 1.627609158560972e-11\n",
      "Day_23 : 2.2355894913062002e-11\n",
      "Day_24 : 8.956948516214425e-10\n",
      "Day_25 : 8.363310044501304e-12\n",
      "Day_26 : 1.835716023634859e-10\n",
      "Day_27 : 3.394506897791416e-11\n",
      "Day_28 : 2.7755575615628914e-14\n",
      "Day_29 : 9.103828801926284e-15\n",
      "Day_30 : 0.0005219307034831644\n",
      "Year_2012 : 5.10702591327572e-15\n",
      "Year_2013 : 0.004523801469117794\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 3.775761037161374e-09\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 0.0\n",
      "Rainfall_Status_Light Rain : 0.03471540321103195\n",
      "Rainfall_Status_No Rain : 0.005297379790016654\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Airport ATM\n",
      "Using Train-Test Split\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 122 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    3.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 8.286427728546842}\n",
      "\n",
      "Best CV RMSE: 174920.52500269053\n",
      "Best Training RMSE: 171726.11624543567\n",
      "Test RMSE: 168895.8449238915\n",
      "Weekday_SATURDAY : 0.0019302720997622647\n",
      "Weekday_THURSDAY : 0.03752063557629137\n",
      "Weekday_WEDNESDAY : 0.004650390594211462\n",
      "Month_3 : 0.018272809144738167\n",
      "Day_6 : 0.020263891475089668\n",
      "Day_7 : 0.015763564002986508\n",
      "Day_8 : 1.906161978815213e-05\n",
      "Day_11 : 0.018564893205397226\n",
      "Day_17 : 0.0258460856898437\n",
      "Day_24 : 0.015729542094147675\n",
      "Day_25 : 0.03836724022871163\n",
      "Day_31 : 0.04470981668048024\n",
      "Year_2012 : 2.4771296125436493e-12\n",
      "Year_2013 : 2.4424906541753444e-15\n",
      "Year_2014 : 2.7905877608702667e-09\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 1.1123990617534218e-11\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For KK Nagar ATM\n",
      "Using Train-Test Split\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    4.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 6.25055192527397}\n",
      "\n",
      "Best CV RMSE: 323715.8607767902\n",
      "Best Training RMSE: 322602.97428327886\n",
      "Test RMSE: 315513.52459795785\n",
      "Weekday_SATURDAY : 0.008045606420807427\n",
      "Weekday_SUNDAY : 0.0034115787216719706\n",
      "Weekday_THURSDAY : 0.018855015755100624\n",
      "Weekday_TUESDAY : 0.024492241286180327\n",
      "Weekday_WEDNESDAY : 2.4011322504069454e-05\n",
      "Month_7 : 0.0009923776706697307\n",
      "Month_8 : 0.03651133395293038\n",
      "Month_9 : 0.0007468138401964808\n",
      "Month_11 : 1.8664391374656475e-06\n",
      "Month_12 : 0.0001543697560721924\n",
      "Day_6 : 1.2354422476157367e-06\n",
      "Day_7 : 0.019207896861774154\n",
      "Day_10 : 0.0005996978302709177\n",
      "Day_18 : 0.0029905844350186506\n",
      "Day_19 : 0.007917694484409488\n",
      "Day_20 : 0.011078026648467576\n",
      "Day_21 : 0.005741642194189822\n",
      "Day_22 : 0.00163295009590958\n",
      "Day_23 : 0.000519967500271612\n",
      "Day_24 : 7.882057293162603e-05\n",
      "Day_25 : 0.02687782931691829\n",
      "Day_27 : 0.0007230754926275118\n",
      "Day_31 : 0.0031981616183138772\n",
      "Year_2012 : 0.0\n",
      "Year_2013 : 0.0\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 0.0\n",
      "Year_2016 : 1.1834977442504169e-13\n",
      "Year_2017 : 0.0\n",
      "Rainfall_Status_Light Rain : 0.033077671115747664\n",
      "Rainfall_Status_Moderate Rain : 0.01299849055575919\n",
      "Rainfall_Status_No Rain : 0.01976073347789198\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Christ College ATM\n",
      "Using Train-Test Split\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 0.655128556859551}\n",
      "\n",
      "Best CV RMSE: 203272.5315227703\n",
      "Best Training RMSE: 206082.6990991003\n",
      "Test RMSE: 219264.76451274348\n",
      "Weekday_SATURDAY : 4.884073145916545e-10\n",
      "Weekday_THURSDAY : 0.00959369625474471\n",
      "Weekday_WEDNESDAY : 0.01672158817963787\n",
      "Working Day_W : 0.005384478808145188\n",
      "Month_7 : 0.01769265942129805\n",
      "Month_11 : 0.00031452328913328387\n",
      "Month_12 : 4.602299286116107e-07\n",
      "Day_8 : 0.02264200096501101\n",
      "Day_9 : 1.7088065991544e-05\n",
      "Day_10 : 0.00011355113301947384\n",
      "Day_14 : 0.00017648007671833277\n",
      "Day_15 : 0.005133536617766721\n",
      "Day_16 : 5.2974284897810975e-05\n",
      "Day_17 : 0.00036652115305813027\n",
      "Day_18 : 1.0475835625634033e-06\n",
      "Day_19 : 1.4187753669236969e-05\n",
      "Day_20 : 0.0019027745324438072\n",
      "Day_21 : 2.8607070415187508e-05\n",
      "Day_22 : 2.2737647593640276e-06\n",
      "Day_23 : 7.732451612341151e-08\n",
      "Day_24 : 1.45296905618153e-08\n",
      "Day_25 : 9.97953291337339e-07\n",
      "Day_26 : 8.303547849308757e-08\n",
      "Day_27 : 1.0831885417506015e-06\n",
      "Day_28 : 6.266011489675094e-07\n",
      "Day_29 : 0.00024393670270939083\n",
      "Year_2012 : 0.0\n",
      "Year_2013 : 0.0\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 0.0\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 0.0\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ridge_param_grid = {'alpha':np.logspace(-3, 3, num=50)}\n",
    "grid_cv_ridge = GridSearchCV(Ridge(), ridge_param_grid, verbose=5, n_jobs=-1, scoring='neg_root_mean_squared_error'\n",
    "                            ,return_train_score=True)\n",
    "\n",
    "for atm_name in atm_names:\n",
    "    print(\"\\nFor\", atm_name)\n",
    "    model_training_hyperparam_per_atm(atm_name, combined_data, categorical_features_list, \n",
    "                                      grid_cv_ridge, tree_model=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Observations </h3>\n",
    "<p> Light Rain was important for Big Street, Light and No Rain were important for Mount Road, all values for KK Nagar </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Conclusions\n",
    "<p> The importance of each feature varies with each ATM and each model, so it is better to focus on a single ATM and try out various models on it but most importantly determine which features are actually important and have an impact on the RMSE </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So from now on, focus is only on Big Street ATM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"atm-correlation\"></a>\n",
    "<h3> Trying to find Correlated columns in the Actual Combined Dataset which has the Rainfall_Status column </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_list = ['Weekday', 'Festival Religion', 'Working Day', 'Holiday Sequence', \n",
    "                             'Month', 'Day', 'Year', 'Rainfall_Status']\n",
    "\n",
    "numerical_data = convert_categorical_to_numerical(combined_data, categorical_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same code block that was used for weather data, I kept the tolerance for correlation at 0.8 again\n",
    "max_correlation_allowed = 0.8\n",
    "correlated_columns = {}\n",
    "numerical_data_corr_df = numerical_data.corr()\n",
    "\n",
    "# For each column check which row indices are highly correlated\n",
    "for column in numerical_data_corr_df.columns:\n",
    "    # Note: name attribute for a row in apply() function returns index, but doesn't have much use elsewhere\n",
    "    correlated_columns[column] = numerical_data_corr_df[numerical_data_corr_df.apply(\n",
    "        lambda x: x[column] > max_correlation_allowed and column != x.name, axis=1)].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Total amount Withdrawn': [],\n",
       " 'Weekday_MONDAY': ['Holiday Sequence_HWW'],\n",
       " 'Weekday_SATURDAY': ['Holiday Sequence_WHH'],\n",
       " 'Weekday_SUNDAY': ['Holiday Sequence_HHW'],\n",
       " 'Weekday_THURSDAY': [],\n",
       " 'Weekday_TUESDAY': [],\n",
       " 'Weekday_WEDNESDAY': [],\n",
       " 'Festival Religion_H': [],\n",
       " 'Festival Religion_M': [],\n",
       " 'Festival Religion_N': [],\n",
       " 'Festival Religion_NH': [],\n",
       " 'Working Day_W': [],\n",
       " 'Holiday Sequence_HHW': ['Weekday_SUNDAY'],\n",
       " 'Holiday Sequence_HWH': [],\n",
       " 'Holiday Sequence_HWW': ['Weekday_MONDAY'],\n",
       " 'Holiday Sequence_WHH': ['Weekday_SATURDAY'],\n",
       " 'Holiday Sequence_WHW': [],\n",
       " 'Holiday Sequence_WWH': [],\n",
       " 'Holiday Sequence_WWW': [],\n",
       " 'Month_2': [],\n",
       " 'Month_3': [],\n",
       " 'Month_4': [],\n",
       " 'Month_5': [],\n",
       " 'Month_6': [],\n",
       " 'Month_7': [],\n",
       " 'Month_8': [],\n",
       " 'Month_9': [],\n",
       " 'Month_10': [],\n",
       " 'Month_11': [],\n",
       " 'Month_12': [],\n",
       " 'Day_2': [],\n",
       " 'Day_3': [],\n",
       " 'Day_4': [],\n",
       " 'Day_5': [],\n",
       " 'Day_6': [],\n",
       " 'Day_7': [],\n",
       " 'Day_8': [],\n",
       " 'Day_9': [],\n",
       " 'Day_10': [],\n",
       " 'Day_11': [],\n",
       " 'Day_12': [],\n",
       " 'Day_13': [],\n",
       " 'Day_14': [],\n",
       " 'Day_15': [],\n",
       " 'Day_16': [],\n",
       " 'Day_17': [],\n",
       " 'Day_18': [],\n",
       " 'Day_19': [],\n",
       " 'Day_20': [],\n",
       " 'Day_21': [],\n",
       " 'Day_22': [],\n",
       " 'Day_23': [],\n",
       " 'Day_24': [],\n",
       " 'Day_25': [],\n",
       " 'Day_26': [],\n",
       " 'Day_27': [],\n",
       " 'Day_28': [],\n",
       " 'Day_29': [],\n",
       " 'Day_30': [],\n",
       " 'Day_31': [],\n",
       " 'Year_2012': [],\n",
       " 'Year_2013': [],\n",
       " 'Year_2014': [],\n",
       " 'Year_2015': [],\n",
       " 'Year_2016': [],\n",
       " 'Year_2017': [],\n",
       " 'Rainfall_Status_Light Rain': [],\n",
       " 'Rainfall_Status_Moderate Rain': [],\n",
       " 'Rainfall_Status_No Rain': []}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlated_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Findings </h3>\n",
    "<p> MONDAY is correlated with Holiday Sequence HWW, SATURDAY with WHH and SUNDAY with HHW, which makes sense </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Running Lasso & Random Forest without Holiday Sequence Column </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Train-Test Split\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:    5.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 184.20699693267164}\n",
      "\n",
      "Best CV RMSE: 113650.0510421977\n",
      "Best Training RMSE: 110470.33079291307\n",
      "Test RMSE: 117487.72436469642\n",
      "Month_10 : 0.006799132397100394\n",
      "Day_6 : 0.0014500756873467857\n",
      "Day_8 : 0.0008477839448495228\n",
      "Day_9 : 4.568752633993256e-07\n",
      "Day_11 : 0.0005685346117938472\n",
      "Day_12 : 2.5008005632987107e-06\n",
      "Day_17 : 0.008002605300741816\n",
      "Day_23 : 0.02022501218991768\n",
      "Day_24 : 0.0016342921167289415\n",
      "Day_25 : 0.019030759955407595\n",
      "Day_27 : 0.023322055844974265\n",
      "Day_31 : 0.008029629167880525\n",
      "Year_2012 : 0.0\n",
      "Year_2013 : 0.0\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 0.0\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 0.0\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:    6.1s finished\n"
     ]
    }
   ],
   "source": [
    "lasso_param_grid = {'alpha':np.logspace(-3, 3, num=50)}\n",
    "grid_cv_lasso = GridSearchCV(Lasso(max_iter=2000), lasso_param_grid, verbose=2, n_jobs=-1, \n",
    "                             scoring='neg_root_mean_squared_error', cv=10, return_train_score=True)\n",
    "\n",
    "categorical_features_list = ['Weekday', 'Festival Religion', 'Working Day', 'Month', 'Day', 'Year', 'Rainfall_Status']\n",
    "model_training_hyperparam_per_atm(\"Big Street ATM\", combined_data.drop('Holiday Sequence', axis=1), categorical_features_list, \n",
    "                                      grid_cv_lasso, tree_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Train-Test Split\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  9.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'n_estimators': 1800, 'min_samples_split': 28, 'min_samples_leaf': 4}\n",
      "\n",
      "Best CV RMSE: 113580.25674585943\n",
      "Best Training RMSE: 107620.5425864286\n",
      "Test RMSE: 111173.60247345203\n",
      "Year_2016: 0.579 +/- 0.041\n",
      "Year_2015: 0.514 +/- 0.045\n",
      "Year_2014: 0.388 +/- 0.035\n",
      "Year_2013: 0.267 +/- 0.021\n",
      "Year_2017: 0.192 +/- 0.020\n",
      "Year_2012: 0.098 +/- 0.015\n",
      "Month_11: 0.042 +/- 0.014\n",
      "Day_12  : 0.023 +/- 0.005\n",
      "Day_6   : 0.015 +/- 0.004\n",
      "Day_11  : 0.014 +/- 0.004\n",
      "Day_8   : 0.010 +/- 0.004\n",
      "Month_7 : 0.010 +/- 0.004\n",
      "Day_3   : 0.007 +/- 0.003\n",
      "Day_2   : 0.005 +/- 0.002\n",
      "Weekday_MONDAY: 0.005 +/- 0.002\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rforest_param_grid = {'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)], \n",
    "                      'min_samples_split': list(range(1,40)), 'min_samples_leaf': list(range(1,25))}\n",
    "                      \n",
    "random_cv_rforest = RandomizedSearchCV(RandomForestRegressor(), rforest_param_grid, n_iter=25, n_jobs=-1, \n",
    "                                      scoring='neg_root_mean_squared_error', verbose=2, cv=10, return_train_score=True)\n",
    "\n",
    "categorical_features_list = ['Weekday', 'Festival Religion', 'Working Day', \n",
    "                             'Month', 'Day', 'Year', 'Rainfall_Status']\n",
    "\n",
    "model_training_hyperparam_per_atm(\"Big Street ATM\", combined_data.drop('Holiday Sequence', axis=1), categorical_features_list, \n",
    "                                      random_cv_rforest, tree_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Running Lasso & Random Forest with Holiday Sequence but removing correlated columns </h3>\n",
    "<h3> Basically WHH, HWW and HHW would be removed before training </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Train-Test Split\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 10.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'n_estimators': 200, 'min_samples_split': 37, 'min_samples_leaf': 3}\n",
      "\n",
      "Best CV RMSE: 111909.74617202181\n",
      "Best Training RMSE: 107523.91534339436\n",
      "Test RMSE: 107109.44399642665\n",
      "Year_2015: 0.702 +/- 0.056\n",
      "Year_2014: 0.428 +/- 0.036\n",
      "Year_2016: 0.409 +/- 0.030\n",
      "Year_2013: 0.293 +/- 0.020\n",
      "Year_2012: 0.184 +/- 0.025\n",
      "Year_2017: 0.136 +/- 0.021\n",
      "Day_12  : 0.026 +/- 0.007\n",
      "Day_8   : 0.017 +/- 0.004\n",
      "Day_11  : 0.017 +/- 0.006\n",
      "Month_12: 0.014 +/- 0.003\n",
      "Month_7 : 0.010 +/- 0.005\n",
      "Day_10  : 0.006 +/- 0.003\n",
      "Month_10: 0.006 +/- 0.003\n",
      "Rainfall_Status_Light Rain: 0.004 +/- 0.001\n",
      "Day_31  : 0.003 +/- 0.001\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rforest_param_grid = {'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)], \n",
    "                      'min_samples_split': list(range(1,40)), 'min_samples_leaf': list(range(1,25))}\n",
    "                      \n",
    "random_cv_rforest = RandomizedSearchCV(RandomForestRegressor(), rforest_param_grid, n_iter=25, n_jobs=-1, \n",
    "                                      scoring='neg_root_mean_squared_error', verbose=2, cv=10, return_train_score=True)\n",
    "\n",
    "categorical_features_list = ['Weekday', 'Festival Religion', 'Holiday Sequence', 'Working Day', \n",
    "                             'Month', 'Day', 'Year', 'Rainfall_Status']\n",
    "\n",
    "model_training_hyperparam_per_atm(\"Big Street ATM\", combined_data, categorical_features_list, \n",
    "                                      random_cv_rforest, tree_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Train-Test Split\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:    6.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 59.636233165946365}\n",
      "\n",
      "Best CV RMSE: 114347.80070469141\n",
      "Best Training RMSE: 110611.76153603743\n",
      "Test RMSE: 114849.93045475856\n",
      "Weekday_MONDAY : 0.008454980871451578\n",
      "Weekday_SATURDAY : 0.01315996871574332\n",
      "Weekday_SUNDAY : 0.014185863667095955\n",
      "Weekday_THURSDAY : 2.6835645113187923e-05\n",
      "Weekday_TUESDAY : 6.770420119872611e-06\n",
      "Weekday_WEDNESDAY : 8.233155278469795e-05\n",
      "Festival Religion_M : 0.033245204509309234\n",
      "Festival Religion_N : 0.030094288136921943\n",
      "Holiday Sequence_WWH : 0.00016340306324846843\n",
      "Month_10 : 0.0011887538511705653\n",
      "Month_12 : 0.007962969131820596\n",
      "Day_6 : 3.490903290059855e-05\n",
      "Day_8 : 0.011363382781413245\n",
      "Day_9 : 1.1843586578130783e-07\n",
      "Day_10 : 0.003541507247133646\n",
      "Day_11 : 0.00021621546141736836\n",
      "Day_12 : 2.654353345188376e-05\n",
      "Day_17 : 0.009138231859655788\n",
      "Day_23 : 0.003979085945912564\n",
      "Day_24 : 0.0013670522925419704\n",
      "Day_25 : 0.016266649077111728\n",
      "Day_27 : 0.029021238981428166\n",
      "Day_28 : 0.04030663280724145\n",
      "Day_31 : 0.0022814487166471498\n",
      "Year_2012 : 0.0\n",
      "Year_2013 : 0.0\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 0.0\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 0.0\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:    8.4s finished\n"
     ]
    }
   ],
   "source": [
    "lasso_param_grid = {'alpha':np.logspace(-3, 3, num=50)}\n",
    "grid_cv_lasso = GridSearchCV(Lasso(max_iter=2000), lasso_param_grid, verbose=2, n_jobs=-1, \n",
    "                             scoring='neg_root_mean_squared_error', cv=10, return_train_score=True)\n",
    "\n",
    "categorical_features_list = ['Weekday', 'Festival Religion', 'Holiday Sequence', 'Working Day', \n",
    "                             'Month', 'Day', 'Year', 'Rainfall_Status']\n",
    "\n",
    "model_training_hyperparam_per_atm(\"Big Street ATM\", combined_data, categorical_features_list, \n",
    "                                      grid_cv_lasso, tree_model=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Conclusions </h3>\n",
    "\n",
    "<p> Pretty insignificant change in RMSE (Train, Test, CV) in both cases and also when compared to the original one which made no changes to the Holiday Sequence column, so we can infer two things, either drop the Holiday Sequences column entirely because it doesn't seem to help much with the training OR keep it because the RMSEs aren't really changing when dropped </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions:\n",
    "<p> Dropping Festival Religion also had insignificant changes to all the RMSEs in both cases, Lasso as well as Random Forest, so it looks like Festival Religion is a redundant column at this point and can strongly be considered as a candidate for getting dropped altogether from the working data </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Notes for Feature Selection </h3>\n",
    "\n",
    "<p> In our case of categorical column inputs and numerical output, it is suggested that we use the ANOVA F-Score but in reverse because that is usually used for numeric inputs and categorical output, so I have to figure that out. Also another way could be to bin our output (amount withdrawn) so that our problem becomes categorical input and categorical output and then we can use the standard Chi-Squared test to determine the K Best Features </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"categorical-output\"></a>\n",
    "## Starting work with Amount as a Categorical Column\n",
    "\n",
    "<p> This next cell is just re-reading and cleaning data again, so that there are no inconsistencies </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_csv('../data/aggregated_atm_data_with_weather_data.csv')\n",
    "combined_data.drop(['No Of Withdrawals', 'No Of XYZ Card Withdrawals', 'No Of Other Card Withdrawals', \n",
    "                    'Amount withdrawn XYZ Card', 'Amount withdrawn Other Card',\n",
    "                    'maxtempC', 'HeatIndexC', 'WindChillC', 'tempC', 'WindGustKmph', 'DewPointC'], axis=1, inplace=True)\n",
    "\n",
    "combined_data['Transaction Date'] = pd.to_datetime(combined_data['Transaction Date'])\n",
    "combined_data['Day'] = combined_data['Transaction Date'].dt.day\n",
    "combined_data['Month'] = combined_data['Transaction Date'].dt.month\n",
    "combined_data['Year'] = combined_data['Transaction Date'].dt.year\n",
    "combined_data.drop('Transaction Date', axis=1, inplace=True)\n",
    "\n",
    "combined_data.drop(['moonrise', 'moonset', 'sunrise', 'sunset', 'winddirDegree', \n",
    "                    'mintempC', 'uvIndex', 'sunHour', 'FeelsLikeC', 'cloudcover',\n",
    "                   'humidity', 'pressure', 'visibility', 'winddirDegree', \n",
    "                    'windspeedKmph', 'moon_illumination'], axis=1, inplace=True)\n",
    "\n",
    "def rainfall_status_check(value):\n",
    "    if value == 0:\n",
    "        return \"No Rain\"\n",
    "    elif value < 2.5:\n",
    "        return \"Light Rain\"\n",
    "    elif value <= 7.6:\n",
    "        return \"Moderate Rain\"\n",
    "    elif value <= 50:\n",
    "        return \"Heavy Rain\"\n",
    "    else:\n",
    "        return \"Violent Rain\"\n",
    "    \n",
    "combined_data['Rainfall_Status'] = combined_data['precipMM'].apply(rainfall_status_check)\n",
    "combined_data.drop('precipMM', axis=1, inplace=True)\n",
    "\n",
    "working_data = combined_data[combined_data['ATM Name'] == 'Big Street ATM'].drop('ATM Name', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning Withdrawal Amounts into bins of 50k\n",
    "\n",
    "<p> Logic: To bin we have to use pd.cut() function which requires us to specify number of bins to create. To find this, find Max Withdrawal Amount and because we want to divide into bins of size 50000, then divide Max by 50000 and then +1 to account for the last possible 50k range, so that is how you get number of bins. </p>\n",
    "\n",
    "<p> Multiply number of bins by 50000 to get the max possible bin value which will be the start of last range in the data </p>\n",
    "\n",
    "<p> cut() also requires us to specify the interval range which specifies the start of each interval (bin), for this the range() function is used, which starts from 0 and goes upto max_bin_value found above and goes in steps of 50000 </p>\n",
    "\n",
    "<p> Final parameter required is labels which specifies the label to be applied to each interval, for this you can just send range(1, num_bins + 1) </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Withdrawal Amount: 926100\n",
      "Number of Classes/Bins: 19\n"
     ]
    }
   ],
   "source": [
    "max_amount = max(working_data['Total amount Withdrawn'])\n",
    "num_bins = max_amount // 50000 + 1\n",
    "\n",
    "print(\"Max Withdrawal Amount:\", max_amount)\n",
    "print(\"Number of Classes/Bins:\", num_bins)\n",
    "\n",
    "max_bin_value = 50000 * num_bins\n",
    "working_data['Total_Amount_Bin'], bins = pd.cut(working_data['Total amount Withdrawn'], \n",
    "                       bins=range(0, max_bin_value + 1, 50000), labels=range(1,num_bins+1), retbins=True)\n",
    "\n",
    "working_data.drop('Total amount Withdrawn', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting basic classifcation models onto the new data and checking what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2050919377652051\n",
      "0.07231961564281786\n"
     ]
    }
   ],
   "source": [
    "categorical_features_list = ['Weekday', 'Festival Religion', 'Working Day', 'Holiday Sequence', \n",
    "                             'Month', 'Day', 'Year', 'Rainfall_Status']\n",
    "\n",
    "numeric_data = convert_categorical_to_numerical(working_data, categorical_features_list)\n",
    "\n",
    "X = numeric_data.drop('Total_Amount_Bin', axis=1)\n",
    "y = numeric_data['Total_Amount_Bin']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 16.69%\n",
    "# model = KNeighborsClassifier(n_neighbors=20, n_jobs=-1)\n",
    "\n",
    "# 20.51%\n",
    "model = LogisticRegression(max_iter=5000, n_jobs=-1)\n",
    "\n",
    "# 19.66%\n",
    "# model = SVC()\n",
    "\n",
    "# 21.1%\n",
    "# model = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "# 16.8%\n",
    "# model = MultinomialNB()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "bal_accuracy = balanced_accuracy_score(y_test, predictions, adjusted=True)\n",
    "\n",
    "print(accuracy)\n",
    "print(bal_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "<p> Accuracy remains pretty low, in the 17 to 20% range, we are not really measuring training score or anything of that sort or doing any hyperparameter tuning or any cross validation even so a lot can be done on this front </p>\n",
    "\n",
    "<p> Also since we have so many classes, 19 for Big Street ATM, it would be wise to devise our own error function, that determines error on the basis of how far predicted class is from the actual class </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"chi-squared\"></a>\n",
    "## Using Chi-Squared Test on the New Categorical Data\n",
    "\n",
    "<ul> \n",
    "    <li> Label Encode all columns (target column is already done before) </li>\n",
    "    <li> Use the chi2(X, y) sklearn function and obtain p-values </li>\n",
    "    <li> Set a significance level (0.05) and check whether column's p-value is lower than this, if it is then it is an important column, else it is not important </li>\n",
    "</ul>\n",
    "<a href=\"https://towardsdatascience.com/chi-square-test-for-feature-selection-in-machine-learning-206b1f0b8223\">Reference</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Festival Religion</th>\n",
       "      <th>Working Day</th>\n",
       "      <th>Holiday Sequence</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Rainfall_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Weekday  Festival Religion  Working Day  Holiday Sequence  Day  Month  \\\n",
       "0         2                  1            0                 4    0      0   \n",
       "5         3                  4            0                 1    0      1   \n",
       "10        1                  4            1                 7    0      2   \n",
       "15        5                  4            1                 7    0      3   \n",
       "20        6                  4            1                 7    0      4   \n",
       "\n",
       "    Year  Rainfall_Status  \n",
       "0      0                1  \n",
       "5      0                3  \n",
       "10     0                3  \n",
       "15     0                2  \n",
       "20     0                1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label Encoding all X-columns\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "X = working_data.drop('Total_Amount_Bin', axis=1)\n",
    "y = working_data['Total_Amount_Bin']\n",
    "\n",
    "for column in X.columns:\n",
    "    X[column] = label_encoder.fit_transform(X[column])\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Chi-Squared Test and storing p-values\n",
    "chi_scores = chi2(X, y)\n",
    "p_values = pd.Series(chi_scores[1], index = X.columns)\n",
    "p_values.sort_values(ascending = False , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19cc5635b80>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "p_values.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> As observed, it seems that Festival Religion, Rainfall_Status and Weekday are all rejected and not considered to be important features! </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to run basic models by dropping the above mentioned columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21074964639321075\n",
      "0.07653591311752307\n"
     ]
    }
   ],
   "source": [
    "categorical_features_list = ['Working Day', 'Holiday Sequence', 'Month', 'Day', 'Year', 'Weekday', 'Rainfall_Status']\n",
    "\n",
    "numeric_data = convert_categorical_to_numerical(working_data.drop(['Festival Religion'], axis=1), \n",
    "                                                categorical_features_list)\n",
    "\n",
    "X = numeric_data.drop('Total_Amount_Bin', axis=1)\n",
    "y = numeric_data['Total_Amount_Bin']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# model = KNeighborsClassifier(n_neighbors=20, n_jobs=-1)\n",
    "\n",
    "model = LogisticRegression(max_iter=5000, n_jobs=-1)\n",
    "\n",
    "# model = SVC()\n",
    "\n",
    "# model = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "# model = MultinomialNB()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "bal_accuracy = balanced_accuracy_score(y_test, predictions, adjusted=True)\n",
    "\n",
    "print(accuracy)\n",
    "print(bal_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Conclusions\n",
    "<p> The surprising thing is that this actually doesn't seem to affect the accuracy that much at all, it still pretty much hovers around the 18-22% ish mark and although our accuracy metric is not perfect and we are just measuring on the test set directly without any changes, this definitely is hinting to the fact that Festival Religion, Rainfall_Status and Weekday are not important at all </p>\n",
    "\n",
    "## Further Conclusions\n",
    "<p> I tried running the model with and without some of the features that were pointed out by the Chi-Squared Test and it turns out the model with no Festival Religion outperformed any model with any subset of the listed features, so basically it looks like Festival Religion can actually be dropped without worry of negatively affecting our model </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> All these results were obtained by using only LogisticRegression, keeping train_test_split with random_state=42 so there's no variation there and first number is the accuracy_score metric and the second number is the balanced_accuracy_score metric </p>\n",
    "\n",
    "<h3> For model with all features </h3>\n",
    "0.2051<br>\n",
    "0.07232\n",
    "\n",
    "<h3> For model with no Festival Religion, Weekday and Rainfall_Status </h3>\n",
    "0.1909<br>\n",
    "0.0599\n",
    "\n",
    "<h3>  For model with no Festival Religion and Rainfall_Status </h3>\n",
    "0.2023<br>\n",
    "0.0692\n",
    "\n",
    "<h3>  For model with no Festival Religion </h3>\n",
    "0.2107<br>\n",
    "0.0765\n",
    "\n",
    "<h3>  For model with no Weekday and Rainfall_Status </h3>\n",
    "0.1909<br>\n",
    "0.0599\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"rfe\"></a>\n",
    "## Trying to use Recursive Feature Elimination (RFE)\n",
    "<p> It is a greedy optimization algorithm which aims to find the best performing feature subset. It repeatedly creates models and keeps aside the best or the worst performing feature at each iteration. It constructs the next model with the left features until all the features are exhausted. It then ranks the features based on the order of their elimination. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting 30 Best Features from entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['Weekday_MONDAY', 'Festival Religion_M', 'Festival Religion_NH', 'Holiday Sequence_HWH', 'Holiday Sequence_WHW', 'Month_6', 'Month_10', 'Month_11', 'Month_12', 'Day_3', 'Day_4', 'Day_6', 'Day_7', 'Day_8', 'Day_9', 'Day_10', 'Day_11', 'Day_12', 'Day_17', 'Day_18', 'Day_20', 'Day_24', 'Day_25', 'Day_31', 'Year_2012', 'Year_2013', 'Year_2014', 'Year_2015', 'Year_2016', 'Year_2017']\n",
      "\n",
      "Accuracy: 0.21357850070721357\n",
      "Balanced Accuracy: 0.06891289964192623\n"
     ]
    }
   ],
   "source": [
    "estimator = LogisticRegression(max_iter=5000, n_jobs=-1)\n",
    "selector = RFE(estimator, n_features_to_select=30, step=1)\n",
    "\n",
    "categorical_features_list = ['Weekday', 'Festival Religion', 'Working Day', 'Holiday Sequence', \n",
    "                             'Month', 'Day', 'Year', 'Rainfall_Status']\n",
    "\n",
    "numeric_data = convert_categorical_to_numerical(working_data, categorical_features_list)\n",
    "\n",
    "X = numeric_data.drop('Total_Amount_Bin', axis=1)\n",
    "y = numeric_data['Total_Amount_Bin']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fits training data on the estimator by using only the best n_features provided (in our case, 30)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "\n",
    "predictions = selector.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "bal_accuracy = balanced_accuracy_score(y_test, predictions, adjusted=True)\n",
    "\n",
    "# selector.support_ is a Boolean Mask which tells you which columns were selected for fitting the data\n",
    "selected_features = []\n",
    "for feature, mask in zip(X.columns, selector.support_):\n",
    "    if mask == True:\n",
    "        selected_features.append(feature)\n",
    "\n",
    "print(\"Selected Features:\", selected_features)\n",
    "print(\"\\nAccuracy:\", accuracy)\n",
    "print(\"Balanced Accuracy:\", bal_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting 30 Best Features from dataset that has no Festival Religion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['Weekday_MONDAY', 'Holiday Sequence_HWH', 'Month_6', 'Month_9', 'Month_10', 'Month_11', 'Month_12', 'Day_3', 'Day_4', 'Day_6', 'Day_7', 'Day_8', 'Day_9', 'Day_10', 'Day_11', 'Day_12', 'Day_13', 'Day_15', 'Day_17', 'Day_18', 'Day_20', 'Day_24', 'Day_25', 'Day_31', 'Year_2012', 'Year_2013', 'Year_2014', 'Year_2015', 'Year_2016', 'Year_2017']\n",
      "\n",
      "Accuracy: 0.214992927864215\n",
      "Balanced Accuracy: 0.07102083897062214\n"
     ]
    }
   ],
   "source": [
    "estimator = LogisticRegression(max_iter=5000, n_jobs=-1)\n",
    "selector = RFE(estimator, n_features_to_select=30, step=1)\n",
    "\n",
    "categorical_features_list = ['Weekday', 'Working Day', 'Holiday Sequence', \n",
    "                             'Month', 'Day', 'Year', 'Rainfall_Status']\n",
    "\n",
    "numeric_data = convert_categorical_to_numerical(working_data.drop('Festival Religion', axis=1), categorical_features_list)\n",
    "\n",
    "X = numeric_data.drop('Total_Amount_Bin', axis=1)\n",
    "y = numeric_data['Total_Amount_Bin']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "selector = selector.fit(X_train, y_train)\n",
    "\n",
    "predictions = selector.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "bal_accuracy = balanced_accuracy_score(y_test, predictions, adjusted=True)\n",
    "\n",
    "selected_features = []\n",
    "for feature, mask in zip(X.columns, selector.support_):\n",
    "    if mask == True:\n",
    "        selected_features.append(feature)\n",
    "\n",
    "print(\"Selected Features:\", selected_features)\n",
    "print(\"\\nAccuracy:\", accuracy)\n",
    "print(\"Balanced Accuracy:\", bal_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> As expected, removing Festival Religion still has a marginal improvement on the overall accuracy and atleast noticeable improvement on the Balanced Accuracy which is a raw measure but still I think its indicative of the fact that Festival Religion doesn't really contribute much </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"categorical-hyperparameter-tuning\"></a>\n",
    "## Hyperparameter Tuning for Categorical Output Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Works for both RandomizedSearchCV() object and GridSearchCV() object\n",
    "def categorical_model_training_hyperparam(models, atm_data, categorical_features_list):\n",
    "    numeric_curr_atm_data = convert_categorical_to_numerical(atm_data, categorical_features_list)\n",
    "\n",
    "    X = numeric_curr_atm_data.drop('Total_Amount_Bin', axis=1)\n",
    "    y = numeric_curr_atm_data['Total_Amount_Bin']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    \n",
    "    for model in models:\n",
    "        print(\"For Model:\", model)\n",
    "        param_cv_obj = models[model]\n",
    "        param_cv_obj.fit(X_train, y_train)\n",
    "        print(\"Best Parameters:\\n\", param_cv_obj.best_params_)\n",
    "        print(\"\\nBest CV Score:\", param_cv_obj.best_score_)\n",
    "        if 'mean_train_score' in param_cv_obj.cv_results_:\n",
    "            # nanmean() is used here instead of mean() because for DecisionTree the mean_train_score actually contains nan\n",
    "            # for some reason, so nanmean() ignores it while computing mean\n",
    "            print(\"Best Training Score:\", np.nanmean(param_cv_obj.cv_results_['mean_train_score']))\n",
    "\n",
    "        best_model = param_cv_obj.best_estimator_\n",
    "        model_predictions = best_model.predict(X_test)\n",
    "        # model_rmse = np.sqrt(mean_squared_error(y_test, model_predictions))\n",
    "        model_accuracy = accuracy_score(y_test, model_predictions)\n",
    "\n",
    "        print(\"Test Accuracy:\", model_accuracy)\n",
    "        print(\"------------------------------------------------------------------------\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Parameter Grids and setting up the models dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_param_grid = {\n",
    "    'C': list(np.logspace(-3, 5, num=25)), \n",
    "}\n",
    "\n",
    "random_cv_svr = RandomizedSearchCV(SVC(), svr_param_grid, n_iter=50, cv=10, verbose=2, \n",
    "                                   n_jobs=-1, scoring='accuracy', return_train_score=True)\n",
    "\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': list(range(1,50)), \n",
    "    'leaf_size': list(range(1,50)), \n",
    "    'p': [1, 2]\n",
    "}\n",
    "                      \n",
    "random_cv_knn = RandomizedSearchCV(KNeighborsClassifier(), knn_param_grid, n_iter=25, n_jobs=-1, \n",
    "                                      scoring='accuracy', verbose=2, cv=10, return_train_score=True)\n",
    "\n",
    "rforest_param_grid = {\n",
    "    'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)], \n",
    "    'min_samples_split': list(range(1,40)), \n",
    "    'min_samples_leaf': list(range(1,25))\n",
    "}\n",
    "                      \n",
    "random_cv_rforest = RandomizedSearchCV(RandomForestClassifier(), rforest_param_grid, n_iter=25, n_jobs=-1, \n",
    "                                      scoring='accuracy', verbose=2, cv=10, return_train_score=True)\n",
    "\n",
    "lr_param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': np.logspace(-4, 4, 20),\n",
    "    'solver': ['liblinear', 'lbfgs']\n",
    "}\n",
    "\n",
    "random_cv_lr = RandomizedSearchCV(LogisticRegression(), lr_param_grid, n_iter=25, n_jobs=-1, \n",
    "                                      scoring='accuracy', verbose=2, cv=10, return_train_score=True)\n",
    "\n",
    "models = {\n",
    "    'K-Nearest Neighbours': random_cv_knn,\n",
    "    'Support Vector Regression': random_cv_svr, \n",
    "    'Random Forest Regression': random_cv_rforest, \n",
    "    'Logistic Regression': random_cv_lr\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running hyperparameter tuning for all above models with \"accuracy\" as the metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Model: K-Nearest Neighbours\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jasvin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_split.py:665: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   27.1s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   41.5s finished\n",
      "c:\\users\\jasvin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py:277: UserWarning: The total space of parameters 25 is smaller than n_iter=50. Running 25 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\users\\jasvin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_split.py:665: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'p': 2, 'n_neighbors': 19, 'leaf_size': 42}\n",
      "\n",
      "Best CV Score: 0.1590613451589061\n",
      "Best Training Score: 0.3117040211920433\n",
      "Test Accuracy: 0.15983026874115983\n",
      "------------------------------------------------------------------------\n",
      "For Model: Support Vector Regression\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   59.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'C': 1.0}\n",
      "\n",
      "Best CV Score: 0.19489652623798964\n",
      "Best Training Score: 0.6604870311574362\n",
      "Test Accuracy: 0.2248939179632249\n",
      "------------------------------------------------------------------------\n",
      "For Model: Random Forest Regression\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jasvin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_split.py:665: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   36.3s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'n_estimators': 400, 'min_samples_split': 15, 'min_samples_leaf': 17}\n",
      "\n",
      "Best CV Score: 0.20337028824833703\n",
      "Best Training Score: 0.4069570853842423\n",
      "Test Accuracy: 0.2347949080622348\n",
      "------------------------------------------------------------------------\n",
      "For Model: Logistic Regression\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jasvin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_split.py:665: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  92 tasks      | elapsed:    4.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.08858667904100823}\n",
      "\n",
      "Best CV Score: 0.2034109386548411\n",
      "Best Training Score: 0.296187069763036\n",
      "Test Accuracy: 0.2164073550212164\n",
      "------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   34.6s finished\n"
     ]
    }
   ],
   "source": [
    "categorical_features_list = ['Weekday', 'Festival Religion', 'Working Day', 'Holiday Sequence', \n",
    "                             'Month', 'Day', 'Year', 'Rainfall_Status']\n",
    "\n",
    "categorical_model_training_hyperparam(models, working_data, categorical_features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "## The class imbalance is way too strong such that we can't really solve it. So it is better to do regression first and then bin result into classes so that we can give it to bank "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to Regression!\n",
    "<a name=\"sequential-train-test\"></a>\n",
    "## Using Sequential Train Test Split instead of Randomized Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_csv('../data/aggregated_atm_data_with_weather_data.csv ')\n",
    "combined_data.drop(['No Of Withdrawals', 'No Of XYZ Card Withdrawals', 'No Of Other Card Withdrawals', \n",
    "                    'Amount withdrawn XYZ Card', 'Amount withdrawn Other Card',\n",
    "                    'maxtempC', 'HeatIndexC', 'WindChillC', 'tempC', 'WindGustKmph', 'DewPointC'], axis=1, inplace=True)\n",
    "\n",
    "combined_data['Transaction Date'] = pd.to_datetime(combined_data['Transaction Date'])\n",
    "combined_data['Day'] = combined_data['Transaction Date'].dt.day\n",
    "combined_data['Month'] = combined_data['Transaction Date'].dt.month\n",
    "combined_data['Year'] = combined_data['Transaction Date'].dt.year\n",
    "combined_data.drop('Transaction Date', axis=1, inplace=True)\n",
    "\n",
    "combined_data.drop(['moonrise', 'moonset', 'sunrise', 'sunset', 'winddirDegree', \n",
    "                    'mintempC', 'uvIndex', 'sunHour', 'FeelsLikeC', 'cloudcover',\n",
    "                   'humidity', 'pressure', 'visibility', 'winddirDegree', \n",
    "                    'windspeedKmph', 'moon_illumination'], axis=1, inplace=True)\n",
    "\n",
    "def rainfall_status_check(value):\n",
    "    if value == 0:\n",
    "        return \"No Rain\"\n",
    "    elif value < 2.5:\n",
    "        return \"Light Rain\"\n",
    "    elif value <= 7.6:\n",
    "        return \"Moderate Rain\"\n",
    "    elif value <= 50:\n",
    "        return \"Heavy Rain\"\n",
    "    else:\n",
    "        return \"Violent Rain\"\n",
    "    \n",
    "combined_data['Rainfall_Status'] = combined_data['precipMM'].apply(rainfall_status_check)\n",
    "combined_data.drop('precipMM', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Train-Test Split\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  8.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'n_estimators': 600, 'min_samples_split': 25, 'min_samples_leaf': 4}\n",
      "\n",
      "Best CV RMSE: 97959.82148385582\n",
      "Best Training RMSE: 83858.71997061197\n",
      "Test RMSE: 276759.81347742316\n",
      "Test MAPE: 222.10761981887487\n",
      "Year_2015: 0.255 +/- 0.055\n",
      "Month_5 : 0.016 +/- 0.006\n",
      "Month_6 : 0.006 +/- 0.001\n",
      "Day_9   : 0.004 +/- 0.001\n",
      "Day_4   : 0.004 +/- 0.001\n",
      "Day_6   : 0.003 +/- 0.000\n",
      "Holiday Sequence_WHH: 0.003 +/- 0.001\n",
      "Day_3   : 0.002 +/- 0.001\n",
      "Day_26  : 0.001 +/- 0.001\n",
      "Month_11: 0.001 +/- 0.001\n",
      "Weekday_SATURDAY: 0.001 +/- 0.000\n",
      "Day_31  : 0.000 +/- 0.000\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rforest_param_grid = {'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)], \n",
    "                      'min_samples_split': list(range(1,40)), 'min_samples_leaf': list(range(1,25))}\n",
    "\n",
    "random_cv_rforest = RandomizedSearchCV(RandomForestRegressor(), rforest_param_grid, n_iter=25, n_jobs=-1, \n",
    "                                      scoring='neg_root_mean_squared_error', verbose=2, cv=10, return_train_score=True)\n",
    "\n",
    "categorical_features_list = ['Weekday', 'Holiday Sequence', 'Working Day', 'Festival Religion',\n",
    "                             'Month', 'Day', 'Year', 'Rainfall_Status']\n",
    "\n",
    "model_training_hyperparam_per_atm(\"Big Street ATM\", combined_data, \n",
    "                                  categorical_features_list, random_cv_rforest, tree_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Festival Religion column and rerunning Lasso and Random Forest\n",
    "<p> The Chi-Squared Test indicated that Festival Religion was the least important column so more focus is on it here </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Train-Test Split\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  7.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'n_estimators': 200, 'min_samples_split': 38, 'min_samples_leaf': 5}\n",
      "\n",
      "Best CV RMSE: 97914.47364413763\n",
      "Best Training RMSE: 83503.04583525786\n",
      "Test RMSE: 277328.5040999877\n",
      "Test MAPE: 223.19753508063764\n",
      "Year_2015: 0.255 +/- 0.053\n",
      "Month_5 : 0.017 +/- 0.006\n",
      "Month_6 : 0.005 +/- 0.001\n",
      "Day_9   : 0.003 +/- 0.001\n",
      "Month_9 : 0.003 +/- 0.001\n",
      "Holiday Sequence_WHH: 0.003 +/- 0.000\n",
      "Day_4   : 0.002 +/- 0.001\n",
      "Month_11: 0.002 +/- 0.000\n",
      "Day_6   : 0.002 +/- 0.000\n",
      "Weekday_SATURDAY: 0.002 +/- 0.000\n",
      "Day_3   : 0.001 +/- 0.000\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rforest_param_grid = {'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)], \n",
    "                      'min_samples_split': list(range(1,40)), 'min_samples_leaf': list(range(1,25))}\n",
    "\n",
    "random_cv_rforest = RandomizedSearchCV(RandomForestRegressor(), rforest_param_grid, n_iter=25, n_jobs=-1, \n",
    "                                      scoring='neg_root_mean_squared_error', verbose=2, cv=10, return_train_score=True)\n",
    "\n",
    "categorical_features_list = ['Weekday', 'Holiday Sequence', 'Working Day', \n",
    "                             'Month', 'Day', 'Year', 'Rainfall_Status']\n",
    "\n",
    "model_training_hyperparam_per_atm(\"Big Street ATM\", combined_data.drop(\"Festival Religion\", axis=1), \n",
    "                                  categorical_features_list, random_cv_rforest, tree_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Train-Test Split\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:    8.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 244.205309454865}\n",
      "\n",
      "Best CV RMSE: 88456.27601575704\n",
      "Best Training RMSE: 78817.93813921516\n",
      "Test RMSE: 262201.0970369484\n",
      "Test MAPE: 523.3419229815353\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   14.5s finished\n"
     ]
    }
   ],
   "source": [
    "lasso_param_grid = {'alpha':np.logspace(-3, 3, num=50)}\n",
    "grid_cv_lasso = GridSearchCV(Lasso(max_iter=2000), lasso_param_grid, verbose=2, n_jobs=-1, \n",
    "                             scoring='neg_root_mean_squared_error', cv=10, return_train_score=True)\n",
    "\n",
    "categorical_features_list = ['Weekday', 'Holiday Sequence', 'Working Day', \n",
    "                             'Month', 'Day', 'Year', 'Rainfall_Status']\n",
    "\n",
    "model_training_hyperparam_per_atm(\"Big Street ATM\", combined_data.drop(\"Festival Religion\", axis=1), \n",
    "                                  categorical_features_list, grid_cv_lasso, tree_model=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions:\n",
    "<p> Quite low Training RMSE and not bad CV RMSE albeit seems quite close to overfitting, the problem lies with Test RMSE which is really, really high in comparison. So that is not optimal. </p>\n",
    "\n",
    "<p> Maybe this points towards using models that are only trained on recent data and doesn't give that much importance to past data or isn't even trained on past data because of how much the average withdrawal amount increases as the years go by </p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
