{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [Data Cleaning](#data-cleaning)\n",
    "2. [Custom One-Hot Encoding Function for Generated Data](#one-hot-enc)\n",
    "3. [Running All Regression Models on Data with Train-Test Split](#initial-regression-model-run)\n",
    "    1. [Compute RMSE Model List Function](#compute-rmse)\n",
    "4. [Model Training Per ATM](#model-training-per-atm)\n",
    "5. [Hyperparameter Tuning](#hyperparameter)\n",
    "    1. [For SVR](#hyperparameter-svr)\n",
    "    2. [For Lasso](#hyperparameter-lasso)\n",
    "    3. [For Ridge](#hyperparameter-ridge)\n",
    "    4. [For Elasticnet](#hyperparameter-enet)\n",
    "    5. [For Bayesian Ridge](#hyperparameter-bayes)\n",
    "    6. [For KNN](#hyperparameter-knn)\n",
    "    7. [For Decision Tree](#hyperparameter-dtree)\n",
    "    8. [For Random Forest](#hyperparameter-rforest)\n",
    "6. [Polynomial Regression with Hyperparameter Tuning](#polynomial)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, BayesianRidge, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, validation_curve, cross_val_score, train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# For measuring feature importance in tree based models like DTree and RandomForest\n",
    "from sklearn.inspection import permutation_importance \n",
    "# For measuring feature importance in linear_models like Lasso, Ridge, etc.\n",
    "from regressors.stats import coef_pval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"data-cleaning\"></a>\n",
    "## Data Import and Cleaning \n",
    "<p> The function performs the following tasks, </p>\n",
    "    <ol> \n",
    "        <li> Converts Weekday column to Uppercase because of format mismatch </li>\n",
    "        <li> Converts Transaction Date column to Date Time object </li>\n",
    "        <li> Removes the XYZ and Other Card Withdrawn Amounts columns target column (Total Amount Withdrawn) is the sum of these two columns </li>\n",
    "        <li> Removes the Number of XYZ and Other Card Withdrawal columns because we will not know these values for test data</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/aggregated_atm_data.csv\")\n",
    "\n",
    "def data_import_and_cleaning(data):\n",
    "    data['Weekday'] = data['Weekday'].str.upper()\n",
    "    data['Transaction Date'] = pd.to_datetime(data['Transaction Date']) \n",
    "    new_data = data.drop(['Transaction Date', 'Amount withdrawn Other Card', 'Amount withdrawn XYZ Card', \n",
    "                          'No Of Withdrawals', 'No Of XYZ Card Withdrawals', 'No Of Other Card Withdrawals'], \n",
    "                         axis=1)\n",
    "    \n",
    "    return new_data\n",
    "\n",
    "new_data = data_import_and_cleaning(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATM Name</th>\n",
       "      <th>Total amount Withdrawn</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Festival Religion</th>\n",
       "      <th>Working Day</th>\n",
       "      <th>Holiday Sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Big Street ATM</td>\n",
       "      <td>123800</td>\n",
       "      <td>SATURDAY</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>WHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mount Road ATM</td>\n",
       "      <td>767900</td>\n",
       "      <td>SATURDAY</td>\n",
       "      <td>C</td>\n",
       "      <td>H</td>\n",
       "      <td>WHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Airport ATM</td>\n",
       "      <td>503400</td>\n",
       "      <td>SATURDAY</td>\n",
       "      <td>C</td>\n",
       "      <td>H</td>\n",
       "      <td>WHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KK Nagar ATM</td>\n",
       "      <td>945300</td>\n",
       "      <td>SATURDAY</td>\n",
       "      <td>C</td>\n",
       "      <td>H</td>\n",
       "      <td>WHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Christ College ATM</td>\n",
       "      <td>287700</td>\n",
       "      <td>SATURDAY</td>\n",
       "      <td>C</td>\n",
       "      <td>H</td>\n",
       "      <td>WHH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ATM Name  Total amount Withdrawn   Weekday Festival Religion  \\\n",
       "0      Big Street ATM                  123800  SATURDAY                 H   \n",
       "1      Mount Road ATM                  767900  SATURDAY                 C   \n",
       "2         Airport ATM                  503400  SATURDAY                 C   \n",
       "3        KK Nagar ATM                  945300  SATURDAY                 C   \n",
       "4  Christ College ATM                  287700  SATURDAY                 C   \n",
       "\n",
       "  Working Day Holiday Sequence  \n",
       "0           H              WHH  \n",
       "1           H              WHH  \n",
       "2           H              WHH  \n",
       "3           H              WHH  \n",
       "4           H              WHH  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breaking Transaction Date into Day, Month and Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['Month'] = data['Transaction Date'].dt.month\n",
    "new_data['Day'] = data['Transaction Date'].dt.day\n",
    "new_data['Year'] = data['Transaction Date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"one-hot-enc\"></a>\n",
    "## Custom One-Hot Encoding Function for Generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_list = ['ATM Name', 'Weekday', 'Festival Religion', 'Working Day', 'Holiday Sequence', \n",
    "                             'Month', 'Day', 'Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all categorical columns to Dummy Data (One-Hot Encoding)\n",
    "# drop_first = True to avoid the first column of each dummy column's result\n",
    "# So if column = Gender and has two unique values Male and Female, get_dummies on this column creates two new columns\n",
    "# male and female, if person male that column is 1 and the other is 0 and same for female column, but we only just need\n",
    "# one of these columns, male or female, if male is 0 it guarantees person is female, for that reason drop_first=True\n",
    "def convert_categorical_to_numerical(data, column_list):\n",
    "    if 'ATM Name' in column_list:\n",
    "        column_list.remove('ATM Name')\n",
    "        temp_data = pd.get_dummies(data, columns=column_list , drop_first=True)\n",
    "    \n",
    "        # Do drop_first for all columns, except for ATM Name, because it becomes useful for accessing individual ATM test\n",
    "        # data later on\n",
    "        return pd.get_dummies(temp_data, columns=['ATM Name'])\n",
    "    else:\n",
    "        return pd.get_dummies(data, columns=column_list, drop_first=True)\n",
    "\n",
    "\n",
    "# One-Hot Encoding and then one of the ATM Name columns has to be dropped because of the way the function is written\n",
    "temp_numeric_data = convert_categorical_to_numerical(new_data, categorical_features_list)\n",
    "numeric_data = temp_numeric_data.drop('ATM Name_KK Nagar ATM', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total amount Withdrawn</th>\n",
       "      <th>Weekday_MONDAY</th>\n",
       "      <th>Weekday_SATURDAY</th>\n",
       "      <th>Weekday_SUNDAY</th>\n",
       "      <th>Weekday_THURSDAY</th>\n",
       "      <th>Weekday_TUESDAY</th>\n",
       "      <th>Weekday_WEDNESDAY</th>\n",
       "      <th>Festival Religion_H</th>\n",
       "      <th>Festival Religion_M</th>\n",
       "      <th>Festival Religion_N</th>\n",
       "      <th>...</th>\n",
       "      <th>Year_2012</th>\n",
       "      <th>Year_2013</th>\n",
       "      <th>Year_2014</th>\n",
       "      <th>Year_2015</th>\n",
       "      <th>Year_2016</th>\n",
       "      <th>Year_2017</th>\n",
       "      <th>ATM Name_Airport ATM</th>\n",
       "      <th>ATM Name_Big Street ATM</th>\n",
       "      <th>ATM Name_Christ College ATM</th>\n",
       "      <th>ATM Name_Mount Road ATM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123800</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>767900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>503400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>945300</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>287700</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total amount Withdrawn  Weekday_MONDAY  Weekday_SATURDAY  Weekday_SUNDAY  \\\n",
       "0                  123800               0                 1               0   \n",
       "1                  767900               0                 1               0   \n",
       "2                  503400               0                 1               0   \n",
       "3                  945300               0                 1               0   \n",
       "4                  287700               0                 1               0   \n",
       "\n",
       "   Weekday_THURSDAY  Weekday_TUESDAY  Weekday_WEDNESDAY  Festival Religion_H  \\\n",
       "0                 0                0                  0                    1   \n",
       "1                 0                0                  0                    0   \n",
       "2                 0                0                  0                    0   \n",
       "3                 0                0                  0                    0   \n",
       "4                 0                0                  0                    0   \n",
       "\n",
       "   Festival Religion_M  Festival Religion_N  ...  Year_2012  Year_2013  \\\n",
       "0                    0                    0  ...          0          0   \n",
       "1                    0                    0  ...          0          0   \n",
       "2                    0                    0  ...          0          0   \n",
       "3                    0                    0  ...          0          0   \n",
       "4                    0                    0  ...          0          0   \n",
       "\n",
       "   Year_2014  Year_2015  Year_2016  Year_2017  ATM Name_Airport ATM  \\\n",
       "0          0          0          0          0                     0   \n",
       "1          0          0          0          0                     0   \n",
       "2          0          0          0          0                     1   \n",
       "3          0          0          0          0                     0   \n",
       "4          0          0          0          0                     0   \n",
       "\n",
       "   ATM Name_Big Street ATM  ATM Name_Christ College ATM  \\\n",
       "0                        1                            0   \n",
       "1                        0                            0   \n",
       "2                        0                            0   \n",
       "3                        0                            0   \n",
       "4                        0                            1   \n",
       "\n",
       "   ATM Name_Mount Road ATM  \n",
       "0                        0  \n",
       "1                        1  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Note that since all columns are non-numeric, scaling is not required</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"initial-regression-model-run\"></a>\n",
    "## Running Each Regression Model to get summary of all RMSEs\n",
    "<b> One model for all ATMs </b>\n",
    "<h3> Models tested </h3>\n",
    "<ul>\n",
    "    <li> KNN </li>\n",
    "    <li> Linear Regression </li>\n",
    "    <li> Ridge </li>\n",
    "    <li> Elasticnet </li>\n",
    "    <li> Lasso </li>\n",
    "    <li> Bayesian Ridge </li>\n",
    "    <li> Support Vector Regression </li>\n",
    "    <li> Random Forest Regression </li>\n",
    "    <li> Decision Tree Regression </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'K-Nearest Neighbours': KNeighborsRegressor(n_neighbors=36, n_jobs=-1), 'Vanilla Linear Regression': LinearRegression(), \n",
    "          'Ridge Linear Regression': Ridge(), 'Elasticnet Linear Regression': ElasticNet(), \n",
    "          'Lasso Linear Regression': Lasso(max_iter=1100), 'Bayesian Ridge Linear Regression': BayesianRidge(), \n",
    "          'Support Vector Regression': SVR(), 'Random Forest Regression': RandomForestRegressor(), \n",
    "          'Decision Tree Regression': DecisionTreeRegressor()}\n",
    "\n",
    "atm_names = new_data['ATM Name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"compute-rmse\"></a>\n",
    "<h3> Compute RMSE function </h3>\n",
    "<p> It loops over all models given, fits train data and predicts on test data </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse_model_list(models, X_train, y_train, X_test, y_test):\n",
    "    print(\"RMSEs for each model\")\n",
    "\n",
    "    for model_name in models:\n",
    "        model = models[model_name]\n",
    "        model.fit(X_train, y_train)\n",
    "        model_predictions = model.predict(X_test)\n",
    "        model_rmse = np.sqrt(mean_squared_error(y_test, model_predictions))\n",
    "        model_mape = mean_absolute_percentage_error(y_test, model_predictions)\n",
    "        model_testing_score = model.score(X_test, y_test)\n",
    "        model_training_score = model.score(X_train, y_train)\n",
    "        print(\"For\", model_name)\n",
    "        print(\"\\tTesting RMSE = {}\".format(model_rmse))\n",
    "        print(\"\\tTesting MAPE = {}\".format(model_mape))\n",
    "        print(\"\\tTraining Score =\", model_training_score)\n",
    "        print(\"\\tTesting Score =\", model_testing_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Train Test Split, 70% Train, 30% Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSEs for each model\n",
      "For K-Nearest Neighbours\n",
      "\tTesting RMSE = 265378.33194243954\n",
      "\tTesting MAPE = 7.783304302433827\n",
      "\tTraining Score = 0.3819838460635303\n",
      "\tTesting Score = 0.34207226076275943\n",
      "For Vanilla Linear Regression\n",
      "\tTesting RMSE = 251419.8192235889\n",
      "\tTesting MAPE = 8.425937522756863\n",
      "\tTraining Score = 0.4013361571445506\n",
      "\tTesting Score = 0.40946411026285623\n",
      "For Ridge Linear Regression\n",
      "\tTesting RMSE = 251395.20976856566\n",
      "\tTesting MAPE = 8.426500618763466\n",
      "\tTraining Score = 0.401303262994798\n",
      "\tTesting Score = 0.4095797101802804\n",
      "For Elasticnet Linear Regression\n",
      "\tTesting RMSE = 309411.6362690149\n",
      "\tTesting MAPE = 8.526314975060792\n",
      "\tTraining Score = 0.10900893738529349\n",
      "\tTesting Score = 0.10562312336992907\n",
      "For Lasso Linear Regression\n",
      "\tTesting RMSE = 251416.0051469024\n",
      "\tTesting MAPE = 8.426030449489193\n",
      "\tTraining Score = 0.4013359781830569\n",
      "\tTesting Score = 0.40948202716449345\n",
      "For Bayesian Ridge Linear Regression\n",
      "\tTesting RMSE = 251414.41701770766\n",
      "\tTesting MAPE = 8.422080318276114\n",
      "\tTraining Score = 0.4009356351971535\n",
      "\tTesting Score = 0.40948948743632585\n",
      "For Support Vector Regression\n",
      "\tTesting RMSE = 330060.3547257065\n",
      "\tTesting MAPE = 7.88347145087977\n",
      "\tTraining Score = -0.02381723071492714\n",
      "\tTesting Score = -0.017733339289077277\n",
      "For Random Forest Regression\n",
      "\tTesting RMSE = 207638.54562306768\n",
      "\tTesting MAPE = 6.152287896007354\n",
      "\tTraining Score = 0.9387313685437062\n",
      "\tTesting Score = 0.597224325242893\n",
      "For Decision Tree Regression\n",
      "\tTesting RMSE = 255631.55799998363\n",
      "\tTesting MAPE = 6.0070410421463825\n",
      "\tTraining Score = 1.0\n",
      "\tTesting Score = 0.38951329389747513\n"
     ]
    }
   ],
   "source": [
    "X = numeric_data.drop('Total amount Withdrawn', axis=1)\n",
    "y = numeric_data['Total amount Withdrawn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "compute_rmse_model_list(models, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <th> Model </th>\n",
    "        <th> Test RMSE </th>\n",
    "        <th> Train Score </th>\n",
    "        <th> Test Score </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> K-Nearest Neighbours </td>\n",
    "        <td> 264286 </td>\n",
    "        <td> 0.3768 </td>\n",
    "        <td> 0.3474 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Linear Regression </td>\n",
    "        <td> 251419 </td>\n",
    "        <td> 0.4013 </td>\n",
    "        <td> 0.4094 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Ridge Linear Regression </td>\n",
    "        <td> 251395 </td>\n",
    "        <td> 0.4013 </td>\n",
    "        <td> 0.4095 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Elasticnet Linear Regression </td>\n",
    "        <td> 309411 </td>\n",
    "        <td> 0.1090 </td>\n",
    "        <td> 0.1056 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Lasso Linear Regression </td>\n",
    "        <td> 251416 </td>\n",
    "        <td> 0.4013 </td>\n",
    "        <td> 0.4094 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Bayesian Ridge Linear Regression </td>\n",
    "        <td> 251414 </td>\n",
    "        <td> 0.4009 </td>\n",
    "        <td> 0.4094 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Support Vector Regression </td>\n",
    "        <td> 330060 </td>\n",
    "        <td> -0.0238 </td>\n",
    "        <td> -0.0177 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> <b> Random Forest Regression </b> </td>\n",
    "        <td> <b> 208204 </b> </td>\n",
    "        <td> 0.9376 </td>\n",
    "        <td> 0.5950 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Decision Tree Regression </td>\n",
    "        <td> 256902 </td>\n",
    "        <td> 1.0 </td>\n",
    "        <td> 0.3834 </td>\n",
    "    </tr>  \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> After observing the testing and training scores, its clear that Random Forest Performed the Best and Decision Tree overfits, other than that all other algorithms perform not so great but there is no overfitting </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"model-training-per-atm\"></a>\n",
    "## Training all models for each ATM separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training_per_atm(atm_name):\n",
    "    models = {'K-Nearest Neighbours': KNeighborsRegressor(n_neighbors=37, n_jobs=-1), 'Vanilla Linear Regression': LinearRegression(), \n",
    "          'Ridge Linear Regression': Ridge(), 'Elasticnet Linear Regression': ElasticNet(), \n",
    "          'Lasso Linear Regression': Lasso(max_iter=1100), 'Bayesian Ridge Linear Regression': BayesianRidge(), \n",
    "          'Support Vector Regression': SVR(), 'Random Forest Regression': RandomForestRegressor(), \n",
    "          'Decision Tree Regression': DecisionTreeRegressor()}\n",
    "    \n",
    "    categorical_features_list = ['Weekday', 'Festival Religion', 'Working Day', 'Holiday Sequence', 'Month', 'Day', 'Year']\n",
    "    \n",
    "    curr_atm_data = new_data[new_data['ATM Name'] == atm_name].drop('ATM Name', axis=1)\n",
    "    numeric_curr_atm_data = convert_categorical_to_numerical(curr_atm_data, categorical_features_list)\n",
    "    \n",
    "    train_data = numeric_curr_atm_data[numeric_curr_atm_data['Year_2017'] == 0]\n",
    "    test_data = numeric_curr_atm_data[numeric_curr_atm_data['Year_2017'] == 1]\n",
    "    \n",
    "    print(\"\\nFor ATM:\", atm_name)\n",
    "    print(\"Number of training rows:\",len(train_data))\n",
    "    print(\"Number of testing rows:\", len(test_data))\n",
    "    print()\n",
    "\n",
    "    X_train = train_data.drop('Total amount Withdrawn', axis=1)\n",
    "    y_train = train_data['Total amount Withdrawn']\n",
    "\n",
    "    X_test = test_data.drop('Total amount Withdrawn', axis=1)\n",
    "    y_test = test_data['Total amount Withdrawn']\n",
    "    \n",
    "    compute_rmse_model_list(models, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For ATM: Big Street ATM\n",
      "Number of training rows: 2117\n",
      "Number of testing rows: 237\n",
      "\n",
      "RMSEs for each model\n",
      "For K-Nearest Neighbours\n",
      "\tTesting RMSE = 181461.59767223545\n",
      "\tTraining Score = 0.28999562819250424\n",
      "\tTesting Score = -0.36556725432459025\n",
      "For Vanilla Linear Regression\n",
      "\tTesting RMSE = 276512.2844681913\n",
      "\tTraining Score = 0.5444464813526175\n",
      "\tTesting Score = -2.1708266083172028\n",
      "For Ridge Linear Regression\n",
      "\tTesting RMSE = 273587.69620255945\n",
      "\tTraining Score = 0.5442115519020725\n",
      "\tTesting Score = -2.104107536431348\n",
      "For Elasticnet Linear Regression\n",
      "\tTesting RMSE = 160736.02690753856\n",
      "\tTraining Score = 0.13017936078590775\n",
      "\tTesting Score = -0.07144551642773656\n",
      "For Lasso Linear Regression\n",
      "\tTesting RMSE = 276469.1320024553\n",
      "\tTraining Score = 0.5444461398934355\n",
      "\tTesting Score = -2.169837008089656\n",
      "For Bayesian Ridge Linear Regression\n",
      "\tTesting RMSE = 270701.1207086409\n",
      "\tTraining Score = 0.5436357614309526\n",
      "\tTesting Score = -2.038951303826138\n",
      "For Support Vector Regression\n",
      "\tTesting RMSE = 158495.8194715498\n",
      "\tTraining Score = -0.0014462945200466315\n",
      "\tTesting Score = -0.04178777477528839\n",
      "For Random Forest Regression\n",
      "\tTesting RMSE = 274377.1040459948\n",
      "\tTraining Score = 0.929750968630442\n",
      "\tTesting Score = -2.122046515871918\n",
      "For Decision Tree Regression\n",
      "\tTesting RMSE = 273672.893231046\n",
      "\tTraining Score = 1.0\n",
      "\tTesting Score = -2.106041116919757\n",
      "\n",
      "For ATM: Mount Road ATM\n",
      "Number of training rows: 2021\n",
      "Number of testing rows: 235\n",
      "\n",
      "RMSEs for each model\n",
      "For K-Nearest Neighbours\n",
      "\tTesting RMSE = 343922.66193841596\n",
      "\tTraining Score = 0.3529602657639054\n",
      "\tTesting Score = -2.4281120216633076\n",
      "For Vanilla Linear Regression\n",
      "\tTesting RMSE = 322167.22468273697\n",
      "\tTraining Score = 0.5181025322944846\n",
      "\tTesting Score = -2.0081267367669327\n",
      "For Ridge Linear Regression\n",
      "\tTesting RMSE = 323206.278030127\n",
      "\tTraining Score = 0.5169168741625048\n",
      "\tTesting Score = -2.0275616405234143\n",
      "For Elasticnet Linear Regression\n",
      "\tTesting RMSE = 325292.86913239764\n",
      "\tTraining Score = 0.15649508138830026\n",
      "\tTesting Score = -2.0667791651930627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jasvin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:474: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 318209236896.22656, tolerance: 12393046096.022762\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Lasso Linear Regression\n",
      "\tTesting RMSE = 322203.5496961272\n",
      "\tTraining Score = 0.5181017969667947\n",
      "\tTesting Score = -2.0088051198912362\n",
      "For Bayesian Ridge Linear Regression\n",
      "\tTesting RMSE = 324014.4789707869\n",
      "\tTraining Score = 0.5135989086530637\n",
      "\tTesting Score = -2.0427218501556643\n",
      "For Support Vector Regression\n",
      "\tTesting RMSE = 322190.0963087881\n",
      "\tTraining Score = -0.00016256288294114185\n",
      "\tTesting Score = -2.0085538639651888\n",
      "For Random Forest Regression\n",
      "\tTesting RMSE = 330963.45681744564\n",
      "\tTraining Score = 0.9219291450813367\n",
      "\tTesting Score = -2.174632850965621\n",
      "For Decision Tree Regression\n",
      "\tTesting RMSE = 356024.4330009066\n",
      "\tTraining Score = 1.0\n",
      "\tTesting Score = -2.6736097999720623\n",
      "\n",
      "For ATM: Airport ATM\n",
      "Number of training rows: 2058\n",
      "Number of testing rows: 195\n",
      "\n",
      "RMSEs for each model\n",
      "For K-Nearest Neighbours\n",
      "\tTesting RMSE = 280998.75391993637\n",
      "\tTraining Score = 0.21011877894017894\n",
      "\tTesting Score = -0.320081646974691\n",
      "For Vanilla Linear Regression\n",
      "\tTesting RMSE = 270419.38396096433\n",
      "\tTraining Score = 0.32222981007075846\n",
      "\tTesting Score = -0.2225528522966016\n",
      "For Ridge Linear Regression\n",
      "\tTesting RMSE = 270340.7285163081\n",
      "\tTraining Score = 0.3217569895030462\n",
      "\tTesting Score = -0.22184176086544904\n",
      "For Elasticnet Linear Regression\n",
      "\tTesting RMSE = 274810.90552300756\n",
      "\tTraining Score = 0.09953188228525989\n",
      "\tTesting Score = -0.26258298215092557\n",
      "For Lasso Linear Regression\n",
      "\tTesting RMSE = 270427.41003619053\n",
      "\tTraining Score = 0.3222292592137085\n",
      "\tTesting Score = -0.22262542436323265\n",
      "For Bayesian Ridge Linear Regression\n",
      "\tTesting RMSE = 270597.6230639246\n",
      "\tTraining Score = 0.3157519731139333\n",
      "\tTesting Score = -0.2241650040142349\n",
      "For Support Vector Regression\n",
      "\tTesting RMSE = 277099.6585735705\n",
      "\tTraining Score = -0.00025917436172195885\n",
      "\tTesting Score = -0.2837013158547954\n",
      "For Random Forest Regression\n",
      "\tTesting RMSE = 276838.7798677631\n",
      "\tTraining Score = 0.8885742333469493\n",
      "\tTesting Score = -0.28128534250831727\n",
      "For Decision Tree Regression\n",
      "\tTesting RMSE = 281802.29749204475\n",
      "\tTraining Score = 1.0\n",
      "\tTesting Score = -0.3276422482720651\n",
      "\n",
      "For ATM: KK Nagar ATM\n",
      "Number of training rows: 2123\n",
      "Number of testing rows: 248\n",
      "\n",
      "RMSEs for each model\n",
      "For K-Nearest Neighbours\n",
      "\tTesting RMSE = 509357.0695052921\n",
      "\tTraining Score = 0.4036695621588333\n",
      "\tTesting Score = -0.8766772926341135\n",
      "For Vanilla Linear Regression\n",
      "\tTesting RMSE = 457547.2389128469\n",
      "\tTraining Score = 0.5157346139328643\n",
      "\tTesting Score = -0.5143170094807608\n",
      "For Ridge Linear Regression\n",
      "\tTesting RMSE = 452583.4106613807\n",
      "\tTraining Score = 0.5146716060699499\n",
      "\tTesting Score = -0.4816382614965147\n",
      "For Elasticnet Linear Regression\n",
      "\tTesting RMSE = 505898.64455021545\n",
      "\tTraining Score = 0.18357797183729763\n",
      "\tTesting Score = -0.8512793392665452\n",
      "For Lasso Linear Regression\n",
      "\tTesting RMSE = 457459.42343176226\n",
      "\tTraining Score = 0.5157343902470022\n",
      "\tTesting Score = -0.5137357898638595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jasvin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:474: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4886918595366.969, tolerance: 40041415972.54263\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Bayesian Ridge Linear Regression\n",
      "\tTesting RMSE = 449447.70286618423\n",
      "\tTraining Score = 0.5109456907699065\n",
      "\tTesting Score = -0.46117843124706037\n",
      "For Support Vector Regression\n",
      "\tTesting RMSE = 476342.10707451584\n",
      "\tTraining Score = -0.010162086368770362\n",
      "\tTesting Score = -0.641280726160238\n",
      "For Random Forest Regression\n",
      "\tTesting RMSE = 446472.98764000664\n",
      "\tTraining Score = 0.9283288998089103\n",
      "\tTesting Score = -0.44190052404055336\n",
      "For Decision Tree Regression\n",
      "\tTesting RMSE = 470676.8132168824\n",
      "\tTraining Score = 1.0\n",
      "\tTesting Score = -0.6024723009525013\n",
      "\n",
      "For ATM: Christ College ATM\n",
      "Number of training rows: 2115\n",
      "Number of testing rows: 240\n",
      "\n",
      "RMSEs for each model\n",
      "For K-Nearest Neighbours\n",
      "\tTesting RMSE = 454068.21878890437\n",
      "\tTraining Score = 0.2887955781878394\n",
      "\tTesting Score = -0.48406666444966473\n",
      "For Vanilla Linear Regression\n",
      "\tTesting RMSE = 563369.5987146889\n",
      "\tTraining Score = 0.4884805976915243\n",
      "\tTesting Score = -1.2845360365183236\n",
      "For Ridge Linear Regression\n",
      "\tTesting RMSE = 559635.1538683609\n",
      "\tTraining Score = 0.487886260442293\n",
      "\tTesting Score = -1.254349113835958\n",
      "For Elasticnet Linear Regression\n",
      "\tTesting RMSE = 437212.60466702207\n",
      "\tTraining Score = 0.15157031881129213\n",
      "\tTesting Score = -0.37593065437858364\n",
      "For Lasso Linear Regression\n",
      "\tTesting RMSE = 563333.8566610938\n",
      "\tTraining Score = 0.4884802021606778\n",
      "\tTesting Score = -1.2842461684834077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jasvin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:474: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 303677188912.1094, tolerance: 13354579722.531445\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Bayesian Ridge Linear Regression\n",
      "\tTesting RMSE = 554222.9690183143\n",
      "\tTraining Score = 0.48620201491936166\n",
      "\tTesting Score = -1.2109567113667454\n",
      "For Support Vector Regression\n",
      "\tTesting RMSE = 464427.1776615809\n",
      "\tTraining Score = -0.01517727140145797\n",
      "\tTesting Score = -0.552553057061139\n",
      "For Random Forest Regression\n",
      "\tTesting RMSE = 570587.0279230344\n",
      "\tTraining Score = 0.9148511753369539\n",
      "\tTesting Score = -1.3434461927554369\n",
      "For Decision Tree Regression\n",
      "\tTesting RMSE = 578248.1828044656\n",
      "\tTraining Score = 1.0\n",
      "\tTesting Score = -1.4067986082933648\n"
     ]
    }
   ],
   "source": [
    "for atm_name in new_data['ATM Name'].unique():\n",
    "    model_training_per_atm(atm_name)\n",
    "    \n",
    "# Note: Bayesian Ridge Linear Regression does not converge for the Mount Road and KK Nagar models and increasing n_iter\n",
    "# to even 5000 (default is 350) didn't change that at all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <th> ATM </th>\n",
    "        <th> Best Algorithm </th>\n",
    "        <th> Test RMSE </th>\n",
    "        <th> Train Score </th>\n",
    "        <th> Test Score </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Big Street ATM </td>\n",
    "        <td> Support Vector Regression </td>\n",
    "        <td> 158495 </td>\n",
    "        <td> -0.0014 </td>\n",
    "        <td> -0.0417 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Mount Road ATM </td>\n",
    "        <td> Linear Regression </td>\n",
    "        <td> 322167 </td>\n",
    "        <td> 0.5181 </td>\n",
    "        <td> -2.0081 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Airport ATM </td>\n",
    "        <td> Ridge Linear Regression </td>\n",
    "        <td> 270340 </td>\n",
    "        <td> 0.3217 </td>\n",
    "        <td> -0.2218 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> KK Nagar ATM </td>\n",
    "        <td> Random Forest Regression </td>\n",
    "        <td> 446472 </td>\n",
    "        <td> 0.9283 </td>\n",
    "        <td> -0.4419 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Christ College ATM </td>\n",
    "        <td> Elasticnet Linear Regression </td>\n",
    "        <td> 437212 </td>\n",
    "        <td> 0.1515 </td>\n",
    "        <td> -0.3759 </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions:\n",
    "<ul>\n",
    "    <li> Performance has drastically improved as a result of training on individual ATMs instead of a single model for all ATMs. </li>\n",
    "    <li> There is no clear \"best\" algorithm which performs the best on all ATMs instead each ATM has its own best algorithm if Test RMSE is to be considered as the evaluation metric. </li>\n",
    "    <li> The test RMSEs are also quite varied as KK Nagar, Christ College and Mount Road ATMs give quite high RMSEs as compared to the previous best of 2.7 lakhs, only Airport and Big Street give reasonable RMSEs </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Upto this point, removing outlier months from test set has had no effect, be it for the model with all ATMs or for individual ATMs, infact it made the RMSE worse at times, so the outlier month part is ignored for now </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"hyperparameter\"></a>\n",
    "## Hyperparameter Tuning (done for individual ATMs) with Train-Test Split with 10-fold Cross Validation\n",
    "\n",
    "<p> The function below this cell takes the atm_name and the random search or grid search object and does all the tasks of converting to numeric data, train test split using 2017 data or regular train_test_split and then does Cross Validation and then computes the RMSE on the best estimator found after hyperparameter search </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also find Feature Importance for important features\n",
    "<p> This is not doable for KNN and SVR </p>\n",
    "\n",
    "<h3> 1. For Tree Models, i.e., Random Forest and Decision Tree </h3>\n",
    "\n",
    "    Prints important features based on permutation_importance() function result\n",
    "    And only displays those features whose importance is atleast twice more than the standard deviation of the \n",
    "    entire importance array\n",
    "\n",
    "<h3> 2. For Linear Models, i.e., Elasticnet, Bayesian Ridge, Lasso, Ridge, etc. </h3>\n",
    "\n",
    "    Prints p-values of all features (can be filtered down later)\n",
    "    Significance level was set to 5%, so if p-value < 0.05, only then would a feature be considered as important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_list = ['Weekday', 'Festival Religion', 'Working Day', 'Holiday Sequence', 'Month', 'Day', 'Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Works for both RandomizedSearchCV() object and GridSearchCV() object\n",
    "def model_training_hyperparam_per_atm(atm_name, new_data, categorical_features_list, \n",
    "                                      param_cv_obj, tree_model='Invalid'):\n",
    "    \n",
    "    curr_atm_data = new_data[new_data['ATM Name'] == atm_name].drop('ATM Name', axis=1)\n",
    "    numeric_curr_atm_data = convert_categorical_to_numerical(curr_atm_data, categorical_features_list)\n",
    "    \n",
    "    X = numeric_curr_atm_data.drop('Total amount Withdrawn', axis=1)\n",
    "    y = numeric_curr_atm_data['Total amount Withdrawn']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    \n",
    "    param_cv_obj.fit(X_train, y_train)\n",
    "    print(\"Best Parameters:\\n\", param_cv_obj.best_params_)\n",
    "    print(\"\\nBest CV RMSE:\", -param_cv_obj.best_score_)\n",
    "    if 'mean_train_score' in param_cv_obj.cv_results_:\n",
    "        # nanmean() is used here instead of mean() because for DecisionTree the mean_train_score actually contains nan\n",
    "        # for some reason, so nanmean() ignores it while computing mean\n",
    "        print(\"Best Training RMSE:\", -np.nanmean(param_cv_obj.cv_results_['mean_train_score']))\n",
    "    \n",
    "    best_model = param_cv_obj.best_estimator_\n",
    "    model_predictions = best_model.predict(X_test)\n",
    "    model_rmse = np.sqrt(mean_squared_error(y_test, model_predictions))\n",
    "    \n",
    "    print(\"Test RMSE:\", model_rmse)\n",
    "    \n",
    "    column_names = X_train.columns\n",
    "    \n",
    "    if tree_model == False:\n",
    "        # p_val_array[1:] because 0-th index is reserved for intercept p-val which is not required for us\n",
    "        p_val_array = coef_pval(best_model, X_train, y_train)\n",
    "        [print(\"{} : {}\".format(x, y)) for x, y in zip(column_names, p_val_array[1:]) if y < 0.05]\n",
    "        \n",
    "    elif tree_model == True:\n",
    "        r = permutation_importance(best_model, X_test, y_test, n_repeats=30, random_state=0)\n",
    "        for i in r.importances_mean.argsort()[::-1]:\n",
    "            if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "                print(f\"{column_names[i]:<8}: \"\n",
    "                      f\"{r.importances_mean[i]:.3f}\"\n",
    "                      f\" +/- {r.importances_std[i]:.3f}\")\n",
    "        \n",
    "    print(\"------------------------------------------------------------------------\\n\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"hyperparameter-svr\"></a>\n",
    "## SVR Hyperparameter Tuning\n",
    "<b> Parameters tuned, C and epsilon </b>\n",
    "\n",
    "<p> <b> Doing only Random Search because Grid Search takes a very very long time </b> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For ATM: Big Street ATM\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   24.7s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:   56.6s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'epsilon': 31.622776601683793, 'C': 100000.0}\n",
      "\n",
      "Best CV RMSE: 117078.97246935354\n",
      "Best Training RMSE: 152787.39282150136\n",
      "Test RMSE: 110942.75941664934\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "For ATM: Mount Road ATM\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:   49.6s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'epsilon': 0.0017782794100389228, 'C': 100000.0}\n",
      "\n",
      "Best CV RMSE: 184928.2336764616\n",
      "Best Training RMSE: 245904.6915620005\n",
      "Test RMSE: 172948.16892758766\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "For ATM: Airport ATM\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   20.2s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:   46.9s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'epsilon': 177.82794100389228, 'C': 100000.0}\n",
      "\n",
      "Best CV RMSE: 174370.4068236465\n",
      "Best Training RMSE: 196896.4981433494\n",
      "Test RMSE: 175196.22234095153\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "For ATM: KK Nagar ATM\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:   50.4s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'epsilon': 0.5623413251903491, 'C': 21544.346900318822}\n",
      "\n",
      "Best CV RMSE: 353724.97533654666\n",
      "Best Training RMSE: 434567.0656866024\n",
      "Test RMSE: 354997.56093387585\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "For ATM: Christ College ATM\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:   48.2s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'epsilon': 0.1, 'C': 100000.0}\n",
      "\n",
      "Best CV RMSE: 218385.86763734784\n",
      "Best Training RMSE: 273135.22250586585\n",
      "Test RMSE: 203072.03789112024\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svr_param_grid = {'C': list(np.logspace(-3, 5, num=25)),\n",
    "                         'epsilon': list(np.logspace(-3, 3, num=25))}\n",
    "\n",
    "random_cv_svr = RandomizedSearchCV(SVR(), svr_param_grid, n_iter=50, cv=10, verbose=2, \n",
    "                                   n_jobs=-1, scoring='neg_root_mean_squared_error', return_train_score=True)\n",
    "\n",
    "for atm_name in atm_names:\n",
    "    print(\"For ATM:\", atm_name)\n",
    "    model_training_hyperparam_per_atm(atm_name, new_data, categorical_features_list, random_cv_svr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <th> ATM </th>\n",
    "        <th> Train RMSE </th>\n",
    "        <th> CV RMSE </th>\n",
    "        <th> Test RMSE </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Big Street ATM </td>\n",
    "        <td> 152787 </td>\n",
    "        <td> 117078 </td>\n",
    "        <td> 110942 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Mount Road ATM </td>\n",
    "        <td> 245904 </td>\n",
    "        <td> 184928 </td>\n",
    "        <td> 172948 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Airport ATM </td>\n",
    "        <td> 196896 </td>\n",
    "        <td> 174370 </td>\n",
    "        <td> 175196 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> KK Nagar ATM </td>\n",
    "        <td> 434567 </td>\n",
    "        <td> 353724 </td>\n",
    "        <td> 354997 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Christ College ATM </td>\n",
    "        <td> 273135 </td>\n",
    "        <td> 218385 </td>\n",
    "        <td> 203072 </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"hyperparameter-lasso\"></a>\n",
    "## Hyperparameter Tuning for Lasso\n",
    "<b> Alpha is the only tunable parameter here </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For Big Street ATM\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=-1)]: Done 358 tasks      | elapsed:   26.7s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   27.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 323.745754281764}\n",
      "\n",
      "Best CV RMSE: 115439.58205293913\n",
      "Best Training RMSE: 111188.4594907152\n",
      "Test RMSE: 113291.11172135144\n",
      "Month_10 : 0.026837121146669363\n",
      "Month_12 : 0.004204576685199246\n",
      "Day_6 : 2.929352309344324e-05\n",
      "Day_8 : 0.002935600260723703\n",
      "Day_9 : 0.00022062193685967735\n",
      "Day_11 : 0.00033683977118204034\n",
      "Day_12 : 1.7640814217179113e-05\n",
      "Day_31 : 0.03762929162671025\n",
      "Year_2012 : 5.329070518200751e-15\n",
      "Year_2013 : 0.0\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 0.0\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 0.0\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Mount Road ATM\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   26.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters:\n",
      " {'alpha': 44.98432668969444}\n",
      "\n",
      "Best CV RMSE: 178687.2089742815\n",
      "Best Training RMSE: 170956.18121349913\n",
      "Test RMSE: 179497.18959146913\n",
      "Weekday_MONDAY : 0.038391167839486595\n",
      "Weekday_SATURDAY : 6.870635615996434e-09\n",
      "Weekday_THURSDAY : 0.004829260299984206\n",
      "Weekday_TUESDAY : 0.046639527183068186\n",
      "Weekday_WEDNESDAY : 0.0004357559652794496\n",
      "Working Day_W : 0.025085983662012534\n",
      "Month_3 : 0.03759145155742449\n",
      "Month_4 : 0.018799665608438376\n",
      "Month_5 : 1.8784389252068934e-05\n",
      "Month_6 : 0.015869324383895433\n",
      "Month_8 : 0.009096804997042351\n",
      "Month_9 : 0.03176125876204394\n",
      "Month_10 : 0.0113916358342383\n",
      "Month_11 : 0.0021135383290171728\n",
      "Day_5 : 0.03125218549386011\n",
      "Day_10 : 0.00030167000055758564\n",
      "Day_13 : 7.255526739857743e-06\n",
      "Day_14 : 2.1116016430955398e-06\n",
      "Day_15 : 3.74298370076076e-11\n",
      "Day_16 : 8.036675769318435e-10\n",
      "Day_17 : 4.287333821295647e-09\n",
      "Day_18 : 2.1917787362824015e-08\n",
      "Day_19 : 3.4989327033496664e-05\n",
      "Day_20 : 6.727563184760754e-06\n",
      "Day_21 : 6.057119250613141e-10\n",
      "Day_22 : 8.600454792784262e-09\n",
      "Day_23 : 2.3869795029440866e-13\n",
      "Day_24 : 3.3694602663558726e-11\n",
      "Day_25 : 1.5954482179836305e-10\n",
      "Day_26 : 1.3320011760242778e-11\n",
      "Day_27 : 2.4821376509720494e-08\n",
      "Day_28 : 6.572520305780927e-12\n",
      "Day_29 : 5.235578637297067e-10\n",
      "Day_30 : 0.006557422856601436\n",
      "Year_2012 : 1.9984014443252818e-15\n",
      "Year_2013 : 0.03141371433173856\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 5.915954393032052e-10\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 0.0\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Airport ATM\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done 362 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   20.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 44.98432668969444}\n",
      "\n",
      "Best CV RMSE: 171317.82293216413\n",
      "Best Training RMSE: 164569.21262089518\n",
      "Test RMSE: 179650.32852592194\n",
      "Weekday_MONDAY : 0.010279150560478012\n",
      "Weekday_SATURDAY : 1.6122090351622376e-07\n",
      "Weekday_THURSDAY : 0.0029688044185867124\n",
      "Weekday_TUESDAY : 0.005772273121679605\n",
      "Weekday_WEDNESDAY : 0.00010943950572017691\n",
      "Working Day_W : 0.017366301099319914\n",
      "Holiday Sequence_HHW : 0.0020272703770798373\n",
      "Holiday Sequence_WHH : 0.009416795350812412\n",
      "Month_3 : 0.0090719248266935\n",
      "Month_8 : 0.0029529681239233163\n",
      "Month_9 : 0.01140996616543788\n",
      "Day_6 : 0.03907471811768626\n",
      "Day_8 : 0.029535134766829563\n",
      "Day_15 : 0.0010945947234946019\n",
      "Day_16 : 0.0038665675934155264\n",
      "Day_17 : 0.00027719482152277486\n",
      "Day_19 : 0.010941708333492617\n",
      "Day_21 : 0.0009104001049089483\n",
      "Day_22 : 0.014310959389650435\n",
      "Day_23 : 0.002097650126044792\n",
      "Day_24 : 0.002937376952317994\n",
      "Day_25 : 0.001586082507746056\n",
      "Day_26 : 0.0017991033375441834\n",
      "Day_27 : 0.03387313641825629\n",
      "Day_28 : 0.011855712947004049\n",
      "Day_29 : 0.014971154541455256\n",
      "Year_2012 : 3.3306690738754696e-14\n",
      "Year_2013 : 0.0\n",
      "Year_2014 : 2.570932296785955e-05\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 2.4444890556196697e-12\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For KK Nagar ATM\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:   29.9s\n",
      "[Parallel(n_jobs=-1)]: Done 493 out of 500 | elapsed:   32.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   32.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 1000.0}\n",
      "\n",
      "Best CV RMSE: 313189.34459445137\n",
      "Best Training RMSE: 300542.5505786474\n",
      "Test RMSE: 341981.8797105739\n",
      "Weekday_SUNDAY : 0.005647919591432515\n",
      "Festival Religion_H : 0.019874561974367433\n",
      "Month_11 : 0.02105705878183395\n",
      "Month_12 : 0.008888007788053764\n",
      "Day_4 : 0.006207220578884343\n",
      "Day_6 : 1.8214385555381796e-10\n",
      "Day_7 : 0.0034920144808363585\n",
      "Day_10 : 0.001158332058677214\n",
      "Day_24 : 0.004359224387390892\n",
      "Day_27 : 0.04653854414815184\n",
      "Year_2012 : 0.0\n",
      "Year_2013 : 0.0\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 4.246514251349254e-11\n",
      "Year_2016 : 4.131837094689672e-10\n",
      "Year_2017 : 2.220446049250313e-16\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Christ College ATM\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:   25.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 79.06043210907701}\n",
      "\n",
      "Best CV RMSE: 208506.62853769763\n",
      "Best Training RMSE: 200744.37831592732\n",
      "Test RMSE: 204298.34256045986\n",
      "Weekday_SATURDAY : 8.925062482401103e-07\n",
      "Weekday_THURSDAY : 0.04497853521227135\n",
      "Weekday_WEDNESDAY : 0.017121295137891623\n",
      "Working Day_W : 0.0003102233389082887\n",
      "Holiday Sequence_HHW : 0.030857140501935554\n",
      "Holiday Sequence_WHH : 0.04211190285355504\n",
      "Holiday Sequence_WHW : 0.018084666833941165\n",
      "Month_7 : 0.04559345501287959\n",
      "Month_11 : 0.0004190963555965599\n",
      "Month_12 : 0.0002430848936845198\n",
      "Day_7 : 0.027216083029303784\n",
      "Day_8 : 0.030515804807257796\n",
      "Day_9 : 0.0001638306559188507\n",
      "Day_10 : 1.7126346477214227e-05\n",
      "Day_14 : 0.001424308300719268\n",
      "Day_16 : 8.13315743803944e-05\n",
      "Day_17 : 0.012978797522592567\n",
      "Day_18 : 0.0002483764805449873\n",
      "Day_19 : 0.0015101872161811247\n",
      "Day_20 : 0.0021863290086976406\n",
      "Day_21 : 2.1451885238610302e-05\n",
      "Day_22 : 2.9172596240689685e-05\n",
      "Day_23 : 1.523509860490435e-07\n",
      "Day_24 : 8.805738360706528e-09\n",
      "Day_25 : 3.219974188617414e-06\n",
      "Day_26 : 1.8148381135674185e-06\n",
      "Day_27 : 0.00019910588291272013\n",
      "Day_28 : 4.842598799736919e-07\n",
      "Day_29 : 1.2175831663796544e-05\n",
      "Day_30 : 0.04171207860625192\n",
      "Year_2012 : 0.0\n",
      "Year_2013 : 0.0\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 0.0\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 0.0\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   27.2s finished\n"
     ]
    }
   ],
   "source": [
    "lasso_param_grid = {'alpha':np.logspace(-3, 3, num=50)}\n",
    "grid_cv_lasso = GridSearchCV(Lasso(max_iter=2000), lasso_param_grid, verbose=2, n_jobs=-1, \n",
    "                             scoring='neg_root_mean_squared_error', cv=10, return_train_score=True)\n",
    "\n",
    "for atm_name in atm_names:\n",
    "    print(\"\\nFor\", atm_name)\n",
    "    model_training_hyperparam_per_atm(atm_name, new_data, categorical_features_list, \n",
    "                                      grid_cv_lasso, tree_model=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <th> ATM </th>\n",
    "        <th> Train RMSE </th>\n",
    "        <th> CV RMSE </th>\n",
    "        <th> Test RMSE </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Big Street ATM </td>\n",
    "        <td> 111188 </td>\n",
    "        <td> 115439 </td>\n",
    "        <td> 113291 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Mount Road ATM </td>\n",
    "        <td> 170956 </td>\n",
    "        <td> 178687 </td>\n",
    "        <td> 179497 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Airport ATM </td>\n",
    "        <td> 164569 </td>\n",
    "        <td> 171317 </td>\n",
    "        <td> 179650 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> KK Nagar ATM </td>\n",
    "        <td> 300542 </td>\n",
    "        <td> 313189 </td>\n",
    "        <td> 341981 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Christ College ATM </td>\n",
    "        <td> 200744 </td>\n",
    "        <td> 208506 </td>\n",
    "        <td> 204298 </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"hyperparameter-ridge\"></a>\n",
    "## Hyperparameter Tuning for Ridge\n",
    "<b> Alpha is again the only tunable parameter here </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For Big Street ATM\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 1.5264179671752334}\n",
      "\n",
      "Best CV RMSE: 117935.23274571684\n",
      "Best Training RMSE: 120326.63005324436\n",
      "Test RMSE: 107950.65157317226\n",
      "Weekday_SATURDAY : 0.0019255040878563001\n",
      "Weekday_THURSDAY : 0.005441490658050885\n",
      "Weekday_TUESDAY : 0.0003432222142065733\n",
      "Weekday_WEDNESDAY : 0.009764274144803187\n",
      "Festival Religion_N : 0.02050332220477058\n",
      "Holiday Sequence_HHW : 0.018625236067314255\n",
      "Holiday Sequence_WHW : 0.009977674649686463\n",
      "Month_9 : 0.007779936370949203\n",
      "Month_10 : 0.0017335434558145568\n",
      "Month_12 : 0.003020051273987967\n",
      "Day_6 : 5.635946424220606e-06\n",
      "Day_8 : 5.7910894911694655e-05\n",
      "Day_9 : 1.1418972579946285e-05\n",
      "Day_11 : 0.0019256872223072374\n",
      "Day_12 : 0.0010461591957919847\n",
      "Day_17 : 0.004091033396562915\n",
      "Day_19 : 0.03453727952574437\n",
      "Day_23 : 0.014440801812289239\n",
      "Day_24 : 0.0037673924533676573\n",
      "Day_25 : 0.011093452306050189\n",
      "Day_27 : 0.029360069667329736\n",
      "Day_31 : 0.035154992587666634\n",
      "Year_2012 : 0.0\n",
      "Year_2013 : 0.0\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 0.0\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 0.0\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Mount Road ATM\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 236 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 0.49417133613238334}\n",
      "\n",
      "Best CV RMSE: 178445.2138392486\n",
      "Best Training RMSE: 180400.03880122502\n",
      "Test RMSE: 182349.69269470643\n",
      "Weekday_SATURDAY : 5.976634080973042e-07\n",
      "Month_2 : 0.002588927826562948\n",
      "Month_3 : 0.003029719510572848\n",
      "Month_4 : 0.0007585533726812699\n",
      "Month_5 : 6.462929363015846e-06\n",
      "Month_6 : 0.005812571826488755\n",
      "Month_7 : 0.009214509862349729\n",
      "Month_8 : 0.0051949263065940166\n",
      "Month_9 : 0.006030288947430185\n",
      "Month_10 : 0.015517771682045378\n",
      "Month_11 : 0.0012402022808886137\n",
      "Month_12 : 0.04440314872576878\n",
      "Day_10 : 1.1087848234003772e-05\n",
      "Day_13 : 0.0001999181988581178\n",
      "Day_14 : 1.5686166432438142e-07\n",
      "Day_15 : 2.9508300247726993e-09\n",
      "Day_16 : 5.481797238360286e-10\n",
      "Day_17 : 3.60037340727537e-05\n",
      "Day_18 : 5.797132835994034e-07\n",
      "Day_19 : 6.354993125068376e-07\n",
      "Day_20 : 3.4550124721199893e-06\n",
      "Day_21 : 3.3517433273289043e-09\n",
      "Day_22 : 2.095856821426878e-11\n",
      "Day_23 : 9.273914969298858e-12\n",
      "Day_24 : 2.535415013493747e-07\n",
      "Day_25 : 2.60840545607266e-07\n",
      "Day_26 : 1.8222090503172694e-11\n",
      "Day_27 : 1.2585255726449418e-08\n",
      "Day_28 : 4.374278717023117e-14\n",
      "Day_29 : 9.88051862549355e-11\n",
      "Day_30 : 0.0017534105119403343\n",
      "Year_2012 : 3.008704396734174e-13\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 3.354239483943644e-07\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 0.0\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Airport ATM\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 14.563484775012444}\n",
      "\n",
      "Best CV RMSE: 177446.78922084943\n",
      "Best Training RMSE: 172948.0539562998\n",
      "Test RMSE: 168899.60492751581\n",
      "Month_3 : 0.020514641884954887\n",
      "Day_6 : 0.04807798114195094\n",
      "Day_8 : 0.0025765350780135865\n",
      "Day_17 : 0.040893296891456155\n",
      "Day_24 : 0.03518572073715487\n",
      "Year_2012 : 4.743268888773855e-09\n",
      "Year_2013 : 2.220446049250313e-16\n",
      "Year_2014 : 5.245718897928242e-06\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 3.643920720719507e-10\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For KK Nagar ATM\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 6.25055192527397}\n",
      "\n",
      "Best CV RMSE: 321567.8501408209\n",
      "Best Training RMSE: 319819.20601955464\n",
      "Test RMSE: 327358.86961965245\n",
      "Weekday_SUNDAY : 0.008838963121154952\n",
      "Weekday_THURSDAY : 0.04229494843367321\n",
      "Weekday_WEDNESDAY : 0.0009947555940106323\n",
      "Festival Religion_H : 0.033166024261570115\n",
      "Month_7 : 0.0194804695711579\n",
      "Month_8 : 0.037136068789373144\n",
      "Month_9 : 0.0009921283659906077\n",
      "Month_11 : 9.937531668091637e-05\n",
      "Month_12 : 3.043468878249911e-06\n",
      "Day_4 : 0.009332562966821722\n",
      "Day_6 : 8.028000963999915e-06\n",
      "Day_7 : 0.022629873557510782\n",
      "Day_10 : 0.0019855269660331576\n",
      "Day_16 : 0.022180178011782292\n",
      "Day_18 : 0.0024682648887968117\n",
      "Day_19 : 0.002611729423841025\n",
      "Day_20 : 0.03699405720190496\n",
      "Day_21 : 0.044902757008916216\n",
      "Day_22 : 0.003356431227035772\n",
      "Day_23 : 0.00018263433276355379\n",
      "Day_24 : 4.44611197736311e-05\n",
      "Day_27 : 0.02544351907150766\n",
      "Year_2012 : 0.0\n",
      "Year_2013 : 0.0\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 0.0\n",
      "Year_2016 : 3.777231860624397e-10\n",
      "Year_2017 : 9.769962616701378e-15\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Christ College ATM\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best Parameters:\n",
      " {'alpha': 0.868511373751352}\n",
      "\n",
      "Best CV RMSE: 210213.5106098162\n",
      "Best Training RMSE: 210913.71476066601\n",
      "Test RMSE: 202712.73250601377\n",
      "Weekday_SATURDAY : 8.655167871296499e-06\n",
      "Weekday_WEDNESDAY : 0.031867178371785876\n",
      "Working Day_W : 0.013287199676927708\n",
      "Month_11 : 0.01063239945739669\n",
      "Month_12 : 2.3879099157131378e-05\n",
      "Day_8 : 0.005110034693174947\n",
      "Day_9 : 0.0004556681670000451\n",
      "Day_10 : 0.0034986028863570606\n",
      "Day_13 : 0.0011335959771920923\n",
      "Day_14 : 0.001093719922976577\n",
      "Day_15 : 0.003958946249277062\n",
      "Day_16 : 6.792401914679225e-05\n",
      "Day_17 : 0.00014643146808213103\n",
      "Day_18 : 6.27356217242081e-06\n",
      "Day_19 : 0.0001065787569938248\n",
      "Day_20 : 0.0006238275403169791\n",
      "Day_21 : 4.539798760339053e-05\n",
      "Day_22 : 2.614570990600029e-06\n",
      "Day_23 : 1.903443247464054e-08\n",
      "Day_24 : 1.1261438448428862e-09\n",
      "Day_25 : 1.684556583114727e-08\n",
      "Day_26 : 2.3188610365210138e-08\n",
      "Day_27 : 9.475626765920175e-05\n",
      "Day_28 : 4.707125611513874e-07\n",
      "Day_29 : 4.427136062479242e-05\n",
      "Day_30 : 0.025880260988073722\n",
      "Year_2012 : 0.0\n",
      "Year_2013 : 0.0\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 0.0\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 0.0\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "ridge_param_grid = {'alpha':np.logspace(-3, 3, num=50)}\n",
    "grid_cv_ridge = GridSearchCV(Ridge(), ridge_param_grid, verbose=5, n_jobs=-1, scoring='neg_root_mean_squared_error'\n",
    "                            ,return_train_score=True)\n",
    "\n",
    "for atm_name in atm_names:\n",
    "    print(\"\\nFor\", atm_name)\n",
    "    model_training_hyperparam_per_atm(atm_name, new_data, categorical_features_list, \n",
    "                                      grid_cv_ridge, tree_model=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <th> ATM </th>\n",
    "        <th> Train RMSE </th>\n",
    "        <th> CV RMSE </th>\n",
    "        <th> Test RMSE </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Big Street ATM </td>\n",
    "        <td> 120326 </td>\n",
    "        <td> 117935 </td>\n",
    "        <td> 107950 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Mount Road ATM </td>\n",
    "        <td> 180400 </td>\n",
    "        <td> 178445 </td>\n",
    "        <td> 182349 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Airport ATM </td>\n",
    "        <td> 172948 </td>\n",
    "        <td> 177446 </td>\n",
    "        <td> 168899 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> KK Nagar ATM </td>\n",
    "        <td> 319819 </td>\n",
    "        <td> 321567 </td>\n",
    "        <td> 327358 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Christ College ATM </td>\n",
    "        <td> 210913 </td>\n",
    "        <td> 210213 </td>\n",
    "        <td> 202712 </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Relatively worse results than Lasso, also often has CV RMSEs lower than Training RMSEs </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"hyperparameter-enet\"></a>\n",
    "## Hyperparameter tuning for Elasticnet\n",
    "<b> Parameters tuned, l1_ratio and alpha </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For Big Street ATM\n",
      "Fitting 10 folds for each of 350 candidates, totalling 3500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done 706 tasks      | elapsed:   28.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1520 tasks      | elapsed:   41.7s\n",
      "[Parallel(n_jobs=-1)]: Done 3500 out of 3500 | elapsed:   53.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 0.016768329368110083, 'l1_ratio': 0.95}\n",
      "\n",
      "Best CV RMSE: 114146.27041476921\n",
      "Best Training RMSE: 131044.92562240835\n",
      "Test RMSE: 114079.44083638032\n",
      "Weekday_MONDAY : 0.007935497624020016\n",
      "Weekday_SATURDAY : 0.02126410049094596\n",
      "Weekday_SUNDAY : 0.036483947066974665\n",
      "Weekday_THURSDAY : 0.0005448645188794732\n",
      "Weekday_TUESDAY : 0.000108254578542466\n",
      "Weekday_WEDNESDAY : 0.00012778111037015094\n",
      "Festival Religion_M : 0.028431867577812575\n",
      "Festival Religion_N : 0.015405532512669406\n",
      "Holiday Sequence_WHW : 0.007327172433438722\n",
      "Month_9 : 0.04981956493270112\n",
      "Month_10 : 0.002804583024861529\n",
      "Month_12 : 0.005851401350503993\n",
      "Day_6 : 0.0012609602841469059\n",
      "Day_8 : 0.00943888407855753\n",
      "Day_9 : 0.00012083073714985737\n",
      "Day_11 : 5.737755549084511e-05\n",
      "Day_12 : 0.00026211776245621543\n",
      "Day_17 : 0.0007893788755022335\n",
      "Day_19 : 0.028838734386153586\n",
      "Day_21 : 0.04470207668928472\n",
      "Day_22 : 0.03598474611131941\n",
      "Day_23 : 0.0017296723169926143\n",
      "Day_24 : 0.0008820447372788198\n",
      "Day_25 : 0.0006550626164745221\n",
      "Day_27 : 0.048033823414839416\n",
      "Day_28 : 0.032018936564302436\n",
      "Day_31 : 0.04546356986242528\n",
      "Year_2012 : 0.0\n",
      "Year_2013 : 0.0\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 0.0\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 0.0\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Mount Road ATM\n",
      "Fitting 10 folds for each of 350 candidates, totalling 3500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 414 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1076 tasks      | elapsed:   35.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2764 tasks      | elapsed:   50.0s\n",
      "[Parallel(n_jobs=-1)]: Done 3500 out of 3500 | elapsed:   52.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 59.636233165946365, 'l1_ratio': 1}\n",
      "\n",
      "Best CV RMSE: 180778.66874773614\n",
      "Best Training RMSE: 207301.4769847062\n",
      "Test RMSE: 175042.8377539548\n",
      "Weekday_SATURDAY : 0.0009703989116847112\n",
      "Weekday_WEDNESDAY : 0.03266851893251532\n",
      "Month_2 : 0.011860163963003378\n",
      "Month_3 : 0.01931627359280097\n",
      "Month_4 : 0.030418686612891266\n",
      "Month_5 : 6.795116080926533e-07\n",
      "Month_6 : 0.0026671537060170003\n",
      "Month_7 : 0.03135663277303902\n",
      "Month_8 : 0.01600779192547752\n",
      "Month_9 : 0.030421262629498624\n",
      "Month_10 : 0.020046691100722436\n",
      "Month_11 : 0.0034517591547076343\n",
      "Day_10 : 0.0004351654154437501\n",
      "Day_12 : 0.027693302169760514\n",
      "Day_13 : 5.391214213568141e-05\n",
      "Day_14 : 3.6470026658630417e-06\n",
      "Day_15 : 1.1231328089778003e-07\n",
      "Day_16 : 3.7960087073685145e-08\n",
      "Day_17 : 5.96829208943106e-07\n",
      "Day_18 : 1.1351533046877194e-09\n",
      "Day_19 : 2.6190376571921803e-05\n",
      "Day_20 : 6.161795340631215e-08\n",
      "Day_21 : 1.4757196937775774e-06\n",
      "Day_22 : 6.4496852303364e-11\n",
      "Day_23 : 5.551115123125783e-14\n",
      "Day_24 : 1.786182313168183e-10\n",
      "Day_25 : 4.140513281125635e-07\n",
      "Day_26 : 1.6502674782259419e-09\n",
      "Day_27 : 1.937872973201138e-09\n",
      "Day_28 : 5.56347412583591e-10\n",
      "Day_29 : 3.122424541146529e-10\n",
      "Day_30 : 0.00046039325039526346\n",
      "Year_2012 : 2.2115642650533118e-13\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 1.5417478405055363e-09\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 0.0\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Airport ATM\n",
      "Fitting 10 folds for each of 350 candidates, totalling 3500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1080 tasks      | elapsed:   34.8s\n",
      "[Parallel(n_jobs=-1)]: Done 3160 tasks      | elapsed:   52.0s\n",
      "[Parallel(n_jobs=-1)]: Done 3500 out of 3500 | elapsed:   53.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 0.0517947467923121, 'l1_ratio': 0.9}\n",
      "\n",
      "Best CV RMSE: 174762.3165165636\n",
      "Best Training RMSE: 181845.52494540656\n",
      "Test RMSE: 172143.94029904684\n",
      "Weekday_SATURDAY : 0.01659835809787058\n",
      "Holiday Sequence_WHH : 0.017045586221744236\n",
      "Month_3 : 0.008287527095655278\n",
      "Day_6 : 0.02079057005304641\n",
      "Day_8 : 0.0007218499980414794\n",
      "Day_17 : 0.009416372141454632\n",
      "Day_25 : 0.008284602016779274\n",
      "Day_26 : 0.010650927924362064\n",
      "Year_2012 : 1.2353196243708453e-09\n",
      "Year_2013 : 5.329070518200751e-15\n",
      "Year_2014 : 9.580107076523348e-07\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 2.240341245851596e-11\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For KK Nagar ATM\n",
      "Fitting 10 folds for each of 350 candidates, totalling 3500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done 706 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1584 tasks      | elapsed:   42.3s\n",
      "[Parallel(n_jobs=-1)]: Done 3500 out of 3500 | elapsed:   54.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 0.012648552168552958, 'l1_ratio': 0.7}\n",
      "\n",
      "Best CV RMSE: 319457.99141757085\n",
      "Best Training RMSE: 358609.6183091785\n",
      "Test RMSE: 325347.27314054396\n",
      "Weekday_SATURDAY : 0.024149053589428204\n",
      "Weekday_SUNDAY : 0.006487644534830528\n",
      "Weekday_WEDNESDAY : 0.0013471905378208415\n",
      "Festival Religion_H : 0.01921479914275248\n",
      "Month_7 : 0.0013259950113628793\n",
      "Month_9 : 0.01666990512008848\n",
      "Month_11 : 0.0002770763780048924\n",
      "Month_12 : 6.792533859267813e-05\n",
      "Day_4 : 0.04360020052914937\n",
      "Day_6 : 1.97445837768484e-06\n",
      "Day_10 : 0.01913622994849029\n",
      "Day_16 : 0.012752970550160114\n",
      "Day_18 : 0.006754297731055292\n",
      "Day_19 : 0.0032666263816722996\n",
      "Day_20 : 0.03930525812920882\n",
      "Day_21 : 0.0043153387585572744\n",
      "Day_22 : 0.0029570741212285867\n",
      "Day_23 : 0.00286932213520652\n",
      "Day_24 : 5.3703296603480055e-05\n",
      "Day_25 : 0.016264830986760348\n",
      "Day_27 : 0.0014626230233525384\n",
      "Year_2012 : 0.0\n",
      "Year_2013 : 0.0\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 0.0\n",
      "Year_2016 : 1.751621070411602e-11\n",
      "Year_2017 : 0.0\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Christ College ATM\n",
      "Fitting 10 folds for each of 350 candidates, totalling 3500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done 706 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1656 tasks      | elapsed:   43.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'alpha': 59.636233165946365, 'l1_ratio': 1}\n",
      "\n",
      "Best CV RMSE: 209106.93881861915\n",
      "Best Training RMSE: 234834.47527783667\n",
      "Test RMSE: 204999.30813885073\n",
      "Weekday_SATURDAY : 2.016198319410023e-10\n",
      "Weekday_THURSDAY : 0.003930932188116243\n",
      "Weekday_WEDNESDAY : 0.0006952300794276223\n",
      "Working Day_W : 0.0018840153702910367\n",
      "Month_11 : 0.02818867593109542\n",
      "Month_12 : 2.7763846426331895e-06\n",
      "Day_3 : 0.024983917525233323\n",
      "Day_9 : 8.571733518469848e-05\n",
      "Day_10 : 0.004580698685753504\n",
      "Day_13 : 0.0044248158717383745\n",
      "Day_14 : 8.165872047172229e-05\n",
      "Day_15 : 0.01774858344576158\n",
      "Day_16 : 5.325840032099904e-06\n",
      "Day_17 : 0.0036176388992186226\n",
      "Day_18 : 4.175190548849628e-08\n",
      "Day_19 : 0.00034152636480722087\n",
      "Day_20 : 0.0006418583855867244\n",
      "Day_21 : 6.7991748524676154e-06\n",
      "Day_22 : 5.781176750652151e-07\n",
      "Day_23 : 9.819014046286156e-09\n",
      "Day_24 : 4.63519156390646e-09\n",
      "Day_25 : 3.5719145875967584e-05\n",
      "Day_26 : 5.8116771395333444e-09\n",
      "Day_27 : 3.4876087811053225e-06\n",
      "Day_28 : 5.9970266359510305e-06\n",
      "Day_29 : 6.083605547102522e-06\n",
      "Year_2012 : 0.0\n",
      "Year_2013 : 0.0\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 0.0\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 0.0\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 3500 out of 3500 | elapsed:   55.9s finished\n"
     ]
    }
   ],
   "source": [
    "elastic_param_grid = {'l1_ratio': [.1, .5, .7, .9, .95, .99, 1], 'alpha': np.logspace(-3, 3, num=50)}\n",
    "                      \n",
    "grid_cv_elastic = GridSearchCV(ElasticNet(), elastic_param_grid, n_jobs=-1,\n",
    "                                       scoring='neg_root_mean_squared_error', verbose=2, cv=10, return_train_score=True)\n",
    "\n",
    "for atm_name in atm_names:\n",
    "    print(\"\\nFor\", atm_name)\n",
    "    model_training_hyperparam_per_atm(atm_name, new_data, categorical_features_list, \n",
    "                                      grid_cv_elastic, tree_model=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <th> ATM </th>\n",
    "        <th> Train RMSE </th>\n",
    "        <th> CV RMSE </th>\n",
    "        <th> Test RMSE </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Big Street ATM </td>\n",
    "        <td> 131044 </td>\n",
    "        <td> 114146 </td>\n",
    "        <td> 114079 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Mount Road ATM </td>\n",
    "        <td> 180400 </td>\n",
    "        <td> 178445 </td>\n",
    "        <td> 182349 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Airport ATM </td>\n",
    "        <td> 181845 </td>\n",
    "        <td> 174762 </td>\n",
    "        <td> 172143 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> KK Nagar ATM </td>\n",
    "        <td> 358609 </td>\n",
    "        <td> 319457 </td>\n",
    "        <td> 325347 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Christ College ATM </td>\n",
    "        <td> 234834 </td>\n",
    "        <td> 209106 </td>\n",
    "        <td> 204999 </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> A bit worse than Lasso and Ridge both, also shows the same behaviour of lower CV RMSEs than training </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"hyperparameter-bayes\"></a>\n",
    "\n",
    "## Hyperparameter Tuning for Bayesian Ridge Regression\n",
    "\n",
    "<b> Parameters tuned, alpha_1, alpha_2, lambda_1, lambda_2 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For Big Street ATM\n",
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1096 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:   13.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'lambda_2': 3.5564803062231287, 'lambda_1': 0.005428675439323859, 'alpha_2': 0.0017575106248547913, 'alpha_1': 244.205309454865}\n",
      "\n",
      "Best CV RMSE: 115811.80090594175\n",
      "Best Training RMSE: 151847.10720056025\n",
      "Test RMSE: 111834.65827364006\n",
      "Weekday_MONDAY : 0.04202731758688705\n",
      "Weekday_THURSDAY : 0.009171588906860872\n",
      "Weekday_TUESDAY : 0.0007467179513971356\n",
      "Weekday_WEDNESDAY : 0.0057123747323946095\n",
      "Festival Religion_M : 0.049748996776970866\n",
      "Festival Religion_N : 0.006377634983613323\n",
      "Month_2 : 0.0458166615323512\n",
      "Month_9 : 0.03309434128920352\n",
      "Month_10 : 0.015302152625542575\n",
      "Month_12 : 0.004373186551756669\n",
      "Day_6 : 0.00044235767927003344\n",
      "Day_8 : 0.020122268974851698\n",
      "Day_9 : 0.00011395784790368957\n",
      "Day_10 : 0.011407799937356966\n",
      "Day_11 : 0.04016256349735392\n",
      "Day_12 : 0.001206781384754052\n",
      "Day_17 : 0.0036170760065674656\n",
      "Day_19 : 0.0236236066342419\n",
      "Day_21 : 0.018946815242651738\n",
      "Day_22 : 0.010298473243874673\n",
      "Day_23 : 0.001013585686594931\n",
      "Day_24 : 7.089228904266776e-05\n",
      "Day_25 : 0.00020575362701125144\n",
      "Day_26 : 0.024336678606439177\n",
      "Day_27 : 0.0023913261518926365\n",
      "Day_31 : 0.03883934498541075\n",
      "Year_2012 : 0.0\n",
      "Year_2013 : 0.0\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 0.0\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 0.0\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Mount Road ATM\n",
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1096 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:   12.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'lambda_2': 323.745754281764, 'lambda_1': 0.022229964825261943, 'alpha_2': 244.205309454865, 'alpha_1': 323.745754281764}\n",
      "\n",
      "Best CV RMSE: 177595.313531177\n",
      "Best Training RMSE: 253171.98223946494\n",
      "Test RMSE: 184030.85557356616\n",
      "Weekday_SATURDAY : 2.951536793882603e-05\n",
      "Holiday Sequence_WHH : 0.012085411399415102\n",
      "Month_5 : 0.002139509666963413\n",
      "Month_6 : 0.005577300334672408\n",
      "Month_11 : 0.0003132127765095305\n",
      "Day_4 : 0.021234795228071812\n",
      "Day_7 : 0.02418835475469039\n",
      "Day_10 : 1.2213922832238211e-05\n",
      "Day_13 : 0.0008722873519246832\n",
      "Day_14 : 0.00026951879479031327\n",
      "Day_15 : 6.574190938968272e-06\n",
      "Day_16 : 5.85613491010939e-06\n",
      "Day_17 : 0.00011063413478606954\n",
      "Day_18 : 2.883521413843404e-05\n",
      "Day_19 : 0.0009042537762253833\n",
      "Day_20 : 0.0014466285561702819\n",
      "Day_21 : 0.0007258687892408577\n",
      "Day_22 : 1.362994084264102e-06\n",
      "Day_23 : 1.599227079984722e-05\n",
      "Day_24 : 1.0141776857874873e-05\n",
      "Day_25 : 2.7556775616943696e-07\n",
      "Day_26 : 0.0001118633013821313\n",
      "Day_27 : 2.4684043829603652e-05\n",
      "Day_28 : 6.571046053949203e-07\n",
      "Day_29 : 2.953253597226535e-08\n",
      "Year_2012 : 0.0\n",
      "Year_2013 : 0.02443296939782824\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 4.4361786666335945e-07\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 0.0\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Airport ATM\n",
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1096 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:   12.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'lambda_2': 184.20699693267164, 'lambda_1': 0.001, 'alpha_2': 1.5264179671752334, 'alpha_1': 138.9495494373136}\n",
      "\n",
      "Best CV RMSE: 174285.0214271081\n",
      "Best Training RMSE: 202133.19617706494\n",
      "Test RMSE: 172490.76122812627\n",
      "Weekday_SATURDAY : 0.015239079978811354\n",
      "Weekday_WEDNESDAY : 0.04900069782716843\n",
      "Holiday Sequence_WHH : 0.018683284795821598\n",
      "Month_3 : 0.01689217070890714\n",
      "Day_6 : 0.005021953148978131\n",
      "Day_7 : 0.02438467902338859\n",
      "Day_8 : 0.000492182740622571\n",
      "Day_15 : 0.026975345678500462\n",
      "Day_23 : 0.010069179578631182\n",
      "Day_25 : 0.018530022620332653\n",
      "Year_2012 : 1.4660606062477655e-10\n",
      "Year_2013 : 6.661338147750939e-16\n",
      "Year_2014 : 2.7603044894242146e-06\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 6.8833827526759706e-15\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For KK Nagar ATM\n",
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1096 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:   13.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'lambda_2': 754.3120063354608, 'lambda_1': 0.009540954763499945, 'alpha_2': 1.5264179671752334, 'alpha_1': 0.001}\n",
      "\n",
      "Best CV RMSE: 323776.6113030715\n",
      "Best Training RMSE: 426985.01097276434\n",
      "Test RMSE: 315454.8068249778\n",
      "Weekday_SATURDAY : 0.011463198784667394\n",
      "Weekday_SUNDAY : 0.004107927281259638\n",
      "Weekday_THURSDAY : 0.02494075201653634\n",
      "Weekday_WEDNESDAY : 0.00010848369761307097\n",
      "Festival Religion_H : 0.03051989602841365\n",
      "Month_9 : 0.011194583806019676\n",
      "Month_11 : 0.001293860149171877\n",
      "Day_6 : 2.6250054720788896e-05\n",
      "Day_10 : 0.011141016074434518\n",
      "Day_16 : 0.010622821569122198\n",
      "Day_17 : 0.0313112180984525\n",
      "Day_18 : 0.000986062393949716\n",
      "Day_19 : 0.02001502957018353\n",
      "Day_20 : 0.005459386965305679\n",
      "Day_22 : 0.0027752769415447798\n",
      "Day_23 : 0.0010485699449220842\n",
      "Day_24 : 2.419897792815817e-06\n",
      "Day_25 : 0.0026053019473506467\n",
      "Day_27 : 0.0012827159206350025\n",
      "Day_31 : 0.006009908410387066\n",
      "Year_2012 : 0.0\n",
      "Year_2013 : 0.0\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 1.4654943925052066e-14\n",
      "Year_2016 : 1.7594081747063228e-10\n",
      "Year_2017 : 5.329070518200751e-15\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Christ College ATM\n",
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1096 tasks      | elapsed:    7.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'lambda_2': 10.985411419875572, 'lambda_1': 0.016768329368110083, 'alpha_2': 0.012648552168552958, 'alpha_1': 1000.0}\n",
      "\n",
      "Best CV RMSE: 208420.8298252251\n",
      "Best Training RMSE: 267322.1627054598\n",
      "Test RMSE: 207321.76924605123\n",
      "Weekday_SATURDAY : 3.3839150193060163e-07\n",
      "Weekday_THURSDAY : 0.0439303250428158\n",
      "Weekday_WEDNESDAY : 0.03142288352535938\n",
      "Working Day_W : 0.0008160254348132945\n",
      "Holiday Sequence_WHH : 0.0037664108713622024\n",
      "Holiday Sequence_WHW : 0.016513655698416008\n",
      "Month_7 : 0.036814737463673364\n",
      "Month_11 : 0.0034816454622859094\n",
      "Month_12 : 6.003164915613368e-06\n",
      "Day_3 : 0.009852136483808449\n",
      "Day_7 : 0.026976995031774642\n",
      "Day_8 : 0.04477723227980013\n",
      "Day_9 : 5.5779492520002805e-05\n",
      "Day_10 : 0.00848112720142824\n",
      "Day_11 : 0.012628594360414747\n",
      "Day_14 : 0.0019368863068787157\n",
      "Day_16 : 7.79908423220732e-05\n",
      "Day_17 : 4.760603686038145e-05\n",
      "Day_18 : 2.416041482433684e-07\n",
      "Day_19 : 0.003510002192397721\n",
      "Day_20 : 0.0037958554061705563\n",
      "Day_21 : 9.376573749886319e-05\n",
      "Day_22 : 5.802438821200795e-06\n",
      "Day_23 : 6.963881647115144e-06\n",
      "Day_24 : 5.022664728571158e-09\n",
      "Day_25 : 3.122413189782236e-06\n",
      "Day_26 : 5.804769028783241e-06\n",
      "Day_27 : 1.5698883770509653e-05\n",
      "Day_28 : 1.2775851226942692e-05\n",
      "Day_29 : 0.00017375970928212858\n",
      "Day_30 : 0.006126659716603422\n",
      "Year_2012 : 0.0\n",
      "Year_2013 : 0.0\n",
      "Year_2014 : 0.0\n",
      "Year_2015 : 0.0\n",
      "Year_2016 : 0.0\n",
      "Year_2017 : 0.0\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:   13.1s finished\n"
     ]
    }
   ],
   "source": [
    "bayes_param_grid = {'alpha_1': np.logspace(-3, 3, num=50), 'alpha_2': np.logspace(-3, 3, num=50),\n",
    "                   'lambda_1': np.logspace(-3, 3, num=50), 'lambda_2': np.logspace(-3, 3, num=50)}\n",
    "                      \n",
    "random_cv_bayes = RandomizedSearchCV(BayesianRidge(), bayes_param_grid, n_iter=200, n_jobs=-1, \n",
    "                                      scoring='neg_root_mean_squared_error', verbose=2, cv=10, return_train_score=True)\n",
    "\n",
    "for atm_name in atm_names:\n",
    "    print(\"\\nFor\", atm_name)\n",
    "    model_training_hyperparam_per_atm(atm_name, new_data, categorical_features_list, \n",
    "                                      random_cv_bayes, tree_model=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <th> ATM </th>\n",
    "        <th> Train RMSE </th>\n",
    "        <th> CV RMSE </th>\n",
    "        <th> Test RMSE </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Big Street ATM </td>\n",
    "        <td> 151847 </td>\n",
    "        <td> 115811 </td>\n",
    "        <td> 111834 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Mount Road ATM </td>\n",
    "        <td> 253171 </td>\n",
    "        <td> 177595 </td>\n",
    "        <td> 184030 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Airport ATM </td>\n",
    "        <td> 202133 </td>\n",
    "        <td> 174285 </td>\n",
    "        <td> 172490 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> KK Nagar ATM </td>\n",
    "        <td> 426985 </td>\n",
    "        <td> 323776 </td>\n",
    "        <td> 315454 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Christ College ATM </td>\n",
    "        <td> 267322 </td>\n",
    "        <td> 208420 </td>\n",
    "        <td> 207321 </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Again Training RMSEs are higher than CV RMSEs, but still performance is good, although Elasticnet performs marginally better and Lasso performs way better, so not much point in using this </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"hyperparameter-knn\"></a>\n",
    "## Hyperparameter Tuning for KNN\n",
    "<b> n_neighbors, leaf_size and p (distance metric selection) are the tunable parameters here </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For Big Street ATM\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   40.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'p': 2, 'n_neighbors': 47, 'leaf_size': 13}\n",
      "\n",
      "Best CV RMSE: 137223.93079557377\n",
      "Best Training RMSE: 135572.51080622335\n",
      "Test RMSE: 134697.4374030493\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Mount Road ATM\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   30.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'p': 1, 'n_neighbors': 22, 'leaf_size': 31}\n",
      "\n",
      "Best CV RMSE: 207823.19105880384\n",
      "Best Training RMSE: 186913.11402831506\n",
      "Test RMSE: 212238.8687379486\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Airport ATM\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   31.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'p': 1, 'n_neighbors': 18, 'leaf_size': 1}\n",
      "\n",
      "Best CV RMSE: 182027.0822411015\n",
      "Best Training RMSE: 171969.9990011814\n",
      "Test RMSE: 187217.06310235272\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For KK Nagar ATM\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   28.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'p': 2, 'n_neighbors': 24, 'leaf_size': 24}\n",
      "\n",
      "Best CV RMSE: 344799.9406417206\n",
      "Best Training RMSE: 317543.31087899185\n",
      "Test RMSE: 355962.5758796952\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Christ College ATM\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   15.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'p': 2, 'n_neighbors': 44, 'leaf_size': 28}\n",
      "\n",
      "Best CV RMSE: 237546.83653303134\n",
      "Best Training RMSE: 216635.30965126475\n",
      "Test RMSE: 235123.5393551469\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   27.2s finished\n"
     ]
    }
   ],
   "source": [
    "knn_param_grid = {'n_neighbors': list(range(1,50)), 'leaf_size': list(range(1,50)), 'p': [1, 2]}\n",
    "                      \n",
    "random_cv_knn = RandomizedSearchCV(KNeighborsRegressor(), knn_param_grid, n_iter=25, n_jobs=-1, \n",
    "                                      scoring='neg_root_mean_squared_error', verbose=2, cv=10, return_train_score=True)\n",
    "\n",
    "for atm_name in atm_names:\n",
    "    print(\"\\nFor\", atm_name)\n",
    "    model_training_hyperparam_per_atm(atm_name, new_data, categorical_features_list, random_cv_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <th> ATM </th>\n",
    "        <th> Train RMSE </th>\n",
    "        <th> CV RMSE </th>\n",
    "        <th> Test RMSE </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Big Street ATM </td>\n",
    "        <td> 135572 </td>\n",
    "        <td> 137223 </td>\n",
    "        <td> 134697 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Mount Road ATM </td>\n",
    "        <td> 186913 </td>\n",
    "        <td> 207823 </td>\n",
    "        <td> 212238 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Airport ATM </td>\n",
    "        <td> 171969 </td>\n",
    "        <td> 182027 </td>\n",
    "        <td> 187217 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> KK Nagar ATM </td>\n",
    "        <td> 317543 </td>\n",
    "        <td> 344799 </td>\n",
    "        <td> 355962 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Christ College ATM </td>\n",
    "        <td> 216635 </td>\n",
    "        <td> 237546 </td>\n",
    "        <td> 235123 </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Not as good CV RMSEs as the above linear model ones, but here the CV RMSE is always higher than the Training RMSE so that is a plus, but still Lasso wins out</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"hyperparameter-dtree\"></a>\n",
    "##  Hyperparameter Tuning for Decision Tree\n",
    "\n",
    "<b> Parameters tuned, min_samples_split, min_samples_leaf </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For Big Street ATM\n",
      "Fitting 10 folds for each of 1131 candidates, totalling 11310 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1012 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 2636 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 4900 tasks      | elapsed:   27.2s\n",
      "[Parallel(n_jobs=-1)]: Done 7820 tasks      | elapsed:   40.0s\n",
      "[Parallel(n_jobs=-1)]: Done 11310 out of 11310 | elapsed:   53.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'min_samples_leaf': 6, 'min_samples_split': 16}\n",
      "\n",
      "Best CV RMSE: 116438.93309299198\n",
      "Best Training RMSE: 107746.12340204648\n",
      "Test RMSE: 120993.33125770367\n",
      "Year_2015: 0.504 +/- 0.034\n",
      "Year_2014: 0.465 +/- 0.033\n",
      "Year_2016: 0.434 +/- 0.032\n",
      "Year_2013: 0.266 +/- 0.025\n",
      "Year_2017: 0.205 +/- 0.016\n",
      "Year_2012: 0.060 +/- 0.006\n",
      "Day_12  : 0.017 +/- 0.006\n",
      "Day_11  : 0.016 +/- 0.006\n",
      "Month_7 : 0.014 +/- 0.006\n",
      "Month_9 : 0.013 +/- 0.003\n",
      "Day_6   : 0.013 +/- 0.002\n",
      "Day_8   : 0.009 +/- 0.002\n",
      "Month_12: 0.007 +/- 0.003\n",
      "Holiday Sequence_WHH: 0.007 +/- 0.003\n",
      "Weekday_MONDAY: 0.001 +/- 0.000\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Mount Road ATM\n",
      "Fitting 10 folds for each of 1131 candidates, totalling 11310 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1096 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2720 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=-1)]: Done 7904 tasks      | elapsed:   34.4s\n",
      "[Parallel(n_jobs=-1)]: Done 11310 out of 11310 | elapsed:   47.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'min_samples_leaf': 28, 'min_samples_split': 3}\n",
      "\n",
      "Best CV RMSE: 194810.5737775145\n",
      "Best Training RMSE: 179365.7213999431\n",
      "Test RMSE: 198427.35122008406\n",
      "Year_2016: 0.320 +/- 0.031\n",
      "Year_2017: 0.258 +/- 0.029\n",
      "Weekday_SUNDAY: 0.137 +/- 0.017\n",
      "Festival Religion_NH: 0.057 +/- 0.008\n",
      "Year_2014: 0.048 +/- 0.007\n",
      "Year_2012: 0.024 +/- 0.005\n",
      "Holiday Sequence_WHH: 0.011 +/- 0.005\n",
      "Year_2013: 0.006 +/- 0.002\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Airport ATM\n",
      "Fitting 10 folds for each of 1131 candidates, totalling 11310 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1096 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2720 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=-1)]: Done 7904 tasks      | elapsed:   34.3s\n",
      "[Parallel(n_jobs=-1)]: Done 11310 out of 11310 | elapsed:   46.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'min_samples_leaf': 27, 'min_samples_split': 2}\n",
      "\n",
      "Best CV RMSE: 179934.7183106889\n",
      "Best Training RMSE: 163787.7055553611\n",
      "Test RMSE: 184799.67409541932\n",
      "Year_2016: 0.165 +/- 0.026\n",
      "Weekday_SATURDAY: 0.068 +/- 0.017\n",
      "Year_2017: 0.067 +/- 0.023\n",
      "Year_2013: 0.066 +/- 0.013\n",
      "Year_2012: 0.039 +/- 0.007\n",
      "Working Day_W: 0.019 +/- 0.009\n",
      "Day_7   : 0.011 +/- 0.004\n",
      "Holiday Sequence_WWH: 0.002 +/- 0.001\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For KK Nagar ATM\n",
      "Fitting 10 folds for each of 1131 candidates, totalling 11310 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1068 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2692 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=-1)]: Done 4956 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=-1)]: Done 7876 tasks      | elapsed:   35.7s\n",
      "[Parallel(n_jobs=-1)]: Done 11310 out of 11310 | elapsed:   48.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'min_samples_leaf': 6, 'min_samples_split': 39}\n",
      "\n",
      "Best CV RMSE: 318032.9409083069\n",
      "Best Training RMSE: 297035.4601708347\n",
      "Test RMSE: 321600.5866065472\n",
      "Year_2014: 0.311 +/- 0.027\n",
      "Weekday_SUNDAY: 0.265 +/- 0.024\n",
      "Year_2013: 0.254 +/- 0.026\n",
      "Year_2012: 0.196 +/- 0.020\n",
      "Year_2017: 0.056 +/- 0.009\n",
      "Year_2015: 0.039 +/- 0.007\n",
      "Year_2016: 0.036 +/- 0.005\n",
      "Month_12: 0.023 +/- 0.007\n",
      "Day_6   : 0.022 +/- 0.006\n",
      "Day_2   : 0.021 +/- 0.006\n",
      "Month_11: 0.017 +/- 0.004\n",
      "Festival Religion_NH: 0.016 +/- 0.007\n",
      "Month_9 : 0.015 +/- 0.003\n",
      "Day_12  : 0.015 +/- 0.005\n",
      "Month_4 : 0.010 +/- 0.005\n",
      "Holiday Sequence_HHW: 0.009 +/- 0.002\n",
      "Month_8 : 0.007 +/- 0.003\n",
      "Festival Religion_H: 0.003 +/- 0.001\n",
      "Weekday_SATURDAY: 0.002 +/- 0.001\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Christ College ATM\n",
      "Fitting 10 folds for each of 1131 candidates, totalling 11310 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1096 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2720 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=-1)]: Done 7904 tasks      | elapsed:   35.3s\n",
      "[Parallel(n_jobs=-1)]: Done 11310 out of 11310 | elapsed:   47.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'min_samples_leaf': 23, 'min_samples_split': 2}\n",
      "\n",
      "Best CV RMSE: 230428.17247433276\n",
      "Best Training RMSE: 208079.9391330452\n",
      "Test RMSE: 225924.4704592382\n",
      "Year_2017: 0.347 +/- 0.022\n",
      "Year_2014: 0.291 +/- 0.026\n",
      "Weekday_SUNDAY: 0.201 +/- 0.034\n",
      "Year_2016: 0.181 +/- 0.014\n",
      "Year_2015: 0.142 +/- 0.009\n",
      "Year_2013: 0.099 +/- 0.011\n",
      "Weekday_SATURDAY: 0.028 +/- 0.009\n",
      "Year_2012: 0.026 +/- 0.004\n",
      "------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtree_param_grid = {'min_samples_split': list(range(1,40)), 'min_samples_leaf': list(range(1,30))}\n",
    "                      \n",
    "grid_cv_dtree = GridSearchCV(DecisionTreeRegressor(), dtree_param_grid, n_jobs=-1,\n",
    "                                       scoring='neg_root_mean_squared_error', verbose=2, cv=10, return_train_score=True)\n",
    "\n",
    "for atm_name in atm_names:\n",
    "    print(\"\\nFor\", atm_name)\n",
    "    model_training_hyperparam_per_atm(atm_name, new_data, categorical_features_list, \n",
    "                                      grid_cv_dtree, tree_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <th> ATM </th>\n",
    "        <th> Train RMSE </th>\n",
    "        <th> CV RMSE </th>\n",
    "        <th> Test RMSE </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Big Street ATM </td>\n",
    "        <td> 107746 </td>\n",
    "        <td> 116438 </td>\n",
    "        <td> 120993 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Mount Road ATM </td>\n",
    "        <td> 179365 </td>\n",
    "        <td> 194810 </td>\n",
    "        <td> 198427 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Airport ATM </td>\n",
    "        <td> 163787 </td>\n",
    "        <td> 179934 </td>\n",
    "        <td> 184799 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> KK Nagar ATM </td>\n",
    "        <td> 297035 </td>\n",
    "        <td> 318032 </td>\n",
    "        <td> 321600 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Christ College ATM </td>\n",
    "        <td> 208079 </td>\n",
    "        <td> 230428 </td>\n",
    "        <td> 225924 </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Not as good as the Lasso but still quite good results and Decision Tree doesn't show the weird behaviour of CV RMSE being greater than Training RMSE </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"hyperparameter-rforest\"></a>\n",
    "\n",
    "## Hyperparameter Tuning for Random Forest\n",
    "<b> Parameters tuned, n_estimators, min_samples_split, min_samples_leaf </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For Big Street ATM\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  9.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'n_estimators': 400, 'min_samples_split': 33, 'min_samples_leaf': 3}\n",
      "\n",
      "Best CV RMSE: 111101.46970646169\n",
      "Best Training RMSE: 104250.25653971334\n",
      "Test RMSE: 115292.68592106046\n",
      "Year_2015: 0.564 +/- 0.034\n",
      "Year_2016: 0.447 +/- 0.032\n",
      "Year_2014: 0.420 +/- 0.028\n",
      "Year_2013: 0.308 +/- 0.017\n",
      "Year_2017: 0.213 +/- 0.020\n",
      "Year_2012: 0.102 +/- 0.009\n",
      "Month_11: 0.026 +/- 0.011\n",
      "Day_6   : 0.021 +/- 0.006\n",
      "Day_11  : 0.019 +/- 0.005\n",
      "Day_9   : 0.015 +/- 0.007\n",
      "Month_12: 0.012 +/- 0.002\n",
      "Day_8   : 0.010 +/- 0.004\n",
      "Day_12  : 0.010 +/- 0.003\n",
      "Day_24  : 0.005 +/- 0.002\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Mount Road ATM\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   36.7s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  9.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'n_estimators': 800, 'min_samples_split': 10, 'min_samples_leaf': 2}\n",
      "\n",
      "Best CV RMSE: 188791.78164250223\n",
      "Best Training RMSE: 181766.1802498414\n",
      "Test RMSE: 173421.09880541897\n",
      "Year_2016: 0.445 +/- 0.042\n",
      "Year_2017: 0.388 +/- 0.038\n",
      "Weekday_SUNDAY: 0.125 +/- 0.020\n",
      "Holiday Sequence_HHW: 0.051 +/- 0.007\n",
      "Festival Religion_NH: 0.044 +/- 0.009\n",
      "Year_2014: 0.038 +/- 0.011\n",
      "Day_10  : 0.032 +/- 0.008\n",
      "Day_4   : 0.029 +/- 0.007\n",
      "Year_2012: 0.028 +/- 0.006\n",
      "Year_2015: 0.027 +/- 0.004\n",
      "Day_11  : 0.025 +/- 0.005\n",
      "Day_7   : 0.020 +/- 0.006\n",
      "Month_11: 0.017 +/- 0.005\n",
      "Day_3   : 0.011 +/- 0.004\n",
      "Day_5   : 0.011 +/- 0.003\n",
      "Day_9   : 0.010 +/- 0.005\n",
      "Day_2   : 0.009 +/- 0.003\n",
      "Day_6   : 0.008 +/- 0.004\n",
      "Year_2013: 0.005 +/- 0.001\n",
      "Holiday Sequence_WHH: 0.005 +/- 0.002\n",
      "Day_31  : 0.004 +/- 0.002\n",
      "Holiday Sequence_WWH: 0.002 +/- 0.001\n",
      "Day_29  : 0.001 +/- 0.001\n",
      "Festival Religion_N: 0.001 +/- 0.000\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Airport ATM\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   53.2s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  7.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'n_estimators': 400, 'min_samples_split': 16, 'min_samples_leaf': 4}\n",
      "\n",
      "Best CV RMSE: 175576.68225787647\n",
      "Best Training RMSE: 164774.20429220123\n",
      "Test RMSE: 170434.22891491957\n",
      "Year_2016: 0.234 +/- 0.021\n",
      "Year_2017: 0.147 +/- 0.019\n",
      "Day_8   : 0.054 +/- 0.008\n",
      "Year_2013: 0.048 +/- 0.010\n",
      "Year_2012: 0.029 +/- 0.006\n",
      "Month_9 : 0.024 +/- 0.007\n",
      "Year_2014: 0.022 +/- 0.005\n",
      "Weekday_SATURDAY: 0.019 +/- 0.008\n",
      "Working Day_W: 0.017 +/- 0.007\n",
      "Month_11: 0.010 +/- 0.004\n",
      "Day_5   : 0.007 +/- 0.002\n",
      "Day_3   : 0.006 +/- 0.002\n",
      "Day_6   : 0.005 +/- 0.002\n",
      "Month_8 : 0.004 +/- 0.002\n",
      "Month_4 : 0.004 +/- 0.002\n",
      "Day_9   : 0.003 +/- 0.001\n",
      "Day_25  : 0.003 +/- 0.001\n",
      "Day_23  : 0.001 +/- 0.000\n",
      "Day_24  : 0.001 +/- 0.000\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For KK Nagar ATM\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  8.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'n_estimators': 2000, 'min_samples_split': 37, 'min_samples_leaf': 2}\n",
      "\n",
      "Best CV RMSE: 293746.10272635485\n",
      "Best Training RMSE: 291098.4424834337\n",
      "Test RMSE: 315413.6836060787\n",
      "Year_2014: 0.332 +/- 0.029\n",
      "Year_2013: 0.289 +/- 0.028\n",
      "Weekday_SUNDAY: 0.245 +/- 0.027\n",
      "Year_2012: 0.213 +/- 0.022\n",
      "Year_2017: 0.048 +/- 0.008\n",
      "Year_2015: 0.039 +/- 0.005\n",
      "Day_11  : 0.028 +/- 0.007\n",
      "Month_12: 0.026 +/- 0.006\n",
      "Day_6   : 0.024 +/- 0.006\n",
      "Day_4   : 0.018 +/- 0.007\n",
      "Day_9   : 0.015 +/- 0.003\n",
      "Year_2016: 0.012 +/- 0.006\n",
      "Month_9 : 0.012 +/- 0.003\n",
      "Day_31  : 0.009 +/- 0.002\n",
      "Day_2   : 0.009 +/- 0.004\n",
      "Day_5   : 0.007 +/- 0.002\n",
      "Holiday Sequence_HHW: 0.007 +/- 0.003\n",
      "Month_7 : 0.006 +/- 0.002\n",
      "Month_6 : 0.003 +/- 0.001\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "For Christ College ATM\n",
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   55.2s\n"
     ]
    }
   ],
   "source": [
    "rforest_param_grid = {'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)], \n",
    "                      'min_samples_split': list(range(1,40)), 'min_samples_leaf': list(range(1,25))}\n",
    "                      \n",
    "random_cv_rforest = RandomizedSearchCV(RandomForestRegressor(), rforest_param_grid, n_iter=25, n_jobs=-1, \n",
    "                                      scoring='neg_root_mean_squared_error', verbose=2, cv=10, return_train_score=True)\n",
    "\n",
    "for atm_name in atm_names:\n",
    "    print(\"\\nFor\", atm_name)\n",
    "    model_training_hyperparam_per_atm(atm_name, new_data, categorical_features_list, \n",
    "                                      random_cv_rforest, tree_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <th> ATM </th>\n",
    "        <th> Train RMSE </th>\n",
    "        <th> CV RMSE </th>\n",
    "        <th> Test RMSE </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Big Street ATM </td>\n",
    "        <td> 104250 </td>\n",
    "        <td> 111101 </td>\n",
    "        <td> 115292 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Mount Road ATM </td>\n",
    "        <td> 181766 </td>\n",
    "        <td> 188791 </td>\n",
    "        <td> 173421 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Airport ATM </td>\n",
    "        <td> 164774 </td>\n",
    "        <td> 175576 </td>\n",
    "        <td> 170434 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> KK Nagar ATM </td>\n",
    "        <td> 291098 </td>\n",
    "        <td> 293746 </td>\n",
    "        <td> 315413 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Christ College ATM </td>\n",
    "        <td> 207308 </td>\n",
    "        <td> 210016 </td>\n",
    "        <td> 210450 </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Outperforms Lasso for all ATMs except Christ College but that's Random Search with just 25 iterations, increasing the iterations will definitely help find better results, so this means that Random Forest is the best model so far </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions from Hyperparameter Tuning\n",
    "\n",
    "<ul>\n",
    "    <li> Random Forest again performed the best </li>\n",
    "    <li> In terms of important features, the important features varies a lot depending on which ATM is being modelled and which algorithm is being used. </li>\n",
    "    <li> Because all we have are categorical columns, importance can only be found for single values of Categorical columns, so for example, we could have one model give \"Weekday_SUNDAY\" as important but all other Weekday values are not important for it, so it doesn't give a clear idea as to whether Weekday column is actually important for it or not </li>\n",
    "    <li> Limiting work to single ATM which we have chosen as Big Street ATM will help narrow search down and it already is giving quite good results </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"polynomial\"></a>\n",
    "## Polynomial Regression\n",
    "\n",
    "<p> Generate a new feature matrix consisting of all polynomial combinations of the features with degree less than or equal to the specified degree. For example, if an input sample is two dimensional and of the form [a, b], the degree-2 polynomial features are [1, a, b, a^2, ab, b^2] </p>\n",
    "\n",
    "<p> This is what the PolynomialFeatures() method does </p>\n",
    "\n",
    "<b> Running time is very very slow, around 30 minutes for just training one ATM for one algorithm </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions on Polynomial Regression\n",
    "<p> All the models that Polynomial Regression was tried upon (except for Elasticnet), performed significantly worse than their regular counterparts and whichever ones did manage to equal the performance, they ended up highly overfitting the data </p>\n",
    "<p> Possible reasons for this, the data consists of just categorical columns on which One-Hot Encoding was performed, so the only values present in each column is either a 0 or a 1, so it is quite possible that Polynomial Regression is not able to do much using Higher Order Features generated using such columns </p>\n",
    "<p> The best training RMSE using regular hypertuned models was still above 1 lakhs, so definitely the models have to be more complex, so maybe once we have generated some numeric columns we can start working for Polynomial Regression </p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
